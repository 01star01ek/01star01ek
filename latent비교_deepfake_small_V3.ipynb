{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/latent%EB%B9%84%EA%B5%90_deepfake_small_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dependency"
      ],
      "metadata": {
        "id": "An3Kh3m69Jqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.11\n",
        "!pip install opencv-contrib-python flatbuffers==23.5.26 sounddevice==0.4.6 attrs==23.1.0\n",
        "!pip install torch==2.1.0 torchvision==0.16.0\n",
        "!pip install dlib opencv-python scikit-image pillow matplotlib imageio gdown tqdm\n",
        "!pip install ninja tensorboard tensorboardX pyaml pyrallis ftfy\n",
        "!pip install face-alignment==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4vUmMoLXIo",
        "outputId": "39cfdcf9-b757-4e49-f254-abc3c2d25370"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.11 in /usr/local/lib/python3.11/dist-packages (0.10.11)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe==0.10.11) (12.4.127)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mediapipe==0.10.11) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mediapipe==0.10.11) (1.3.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.11/dist-packages (23.5.26)\n",
            "Requirement already satisfied: sounddevice==0.4.6 in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.11/dist-packages (23.1.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice==0.4.6) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice==0.4.6) (2.22)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.4)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (25.5.0)\n",
            "Requirement already satisfied: pyrallis in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyrallis) (0.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (4.14.0)\n",
            "Requirement already satisfied: face-alignment==1.3.5 in /usr/local/lib/python3.11/dist-packages (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.15.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment==1.3.5) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->face-alignment==1.3.5) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.3.5) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->face-alignment==1.3.5) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "j6kl565aMbdT",
        "outputId": "530aecfa-ce45-4c8e-f9d0-fe7bcd482c08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d85fe213035346f085390891f69fff5a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/extract_frames\n",
        "!mkdir -p /content/input_videos\n",
        "!mkdir -p /content/alignmented_frame\n",
        "!mkdir -p /content/alignmented_frame_aligned\n",
        "!mkdir -p /content/alignmented_frame_croped\n",
        "!mkdir -p /content/alignmented_frame_transforms"
      ],
      "metadata": {
        "id": "UlYQQ1my-rL-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#git hub & model install"
      ],
      "metadata": {
        "id": "Io1UJS2j-HYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/stylegan3-editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae5jdZJn-UUn",
        "outputId": "9b98ad1d-a683-4952-89e1-0c7056d06f51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan3-editing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "8gQABgnW-aOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -P /content/pretrained_models/\n",
        "!bzip2 -d /content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZNpi4s-HAa",
        "outputId": "4dc628fb-a852-433a-9462-6ca3ddfadccd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-18 21:29:01--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-06-18 21:29:01--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‚Äò/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.2‚Äô\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  9.24MB/s    in 8.1s    \n",
            "\n",
            "2025-06-18 21:29:10 (7.51 MB/s) - ‚Äò/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.2‚Äô saved [64040097/64040097]\n",
            "\n",
            "bzip2: Output file /content/pretrained_models/shape_predictor_68_face_landmarks.dat already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm -O /content/pretrained_models/restyle_e4e_sg3.pt\n",
        "!gdown --id 13q6m-bpe3Ws9en9y45JEx2PHQirStt8N -O /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
        "!gdown --id 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn -O /content/pretrained_models/model_ir_se50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntmFmSfd-ZiO",
        "outputId": "24ded2eb-094c-4f7a-8f62-ef6a1ac6497c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm\n",
            "From (redirected): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm&confirm=t&uuid=036df595-92e7-4297-8ca7-dda2c431accd\n",
            "To: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "100% 809M/809M [00:12<00:00, 63.7MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N\n",
            "From (redirected): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N&confirm=t&uuid=88e9e633-57b6-4c3f-951e-131aa7f35c95\n",
            "To: /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
            "100% 60.4M/60.4M [00:01<00:00, 42.2MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn\n",
            "From (redirected): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn&confirm=t&uuid=58b96949-4129-4405-891f-144dbc141d16\n",
            "To: /content/pretrained_models/model_ir_se50.pth\n",
            "100% 175M/175M [00:03<00:00, 44.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stylegan3-editing/pretrained_models\n",
        "!cp /content/pretrained_models/shape_predictor_68_face_landmarks.dat /content/stylegan3-editing/pretrained_models/"
      ],
      "metadata": {
        "id": "aCa0uxct-mxb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess frames"
      ],
      "metadata": {
        "id": "PBElw7K4_zJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Îã®Ïùº ÌîÑÎ°úÏÑ∏Ïä§ ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏΩîÎìú\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "video_dir = \"/content/input_videos\"  #@param {type:\"string\"}\n",
        "output_base = \"/content/extract_frames\"  #@param {type:\"string\"}\n",
        "extract_per_sec = 7  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "def extract_video_frames(video_path):\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    output_dir = os.path.join(output_base, video_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval = max(1, int(fps // extract_per_sec))\n",
        "\n",
        "    frame_idx = 0\n",
        "    frame_list = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % interval == 0:\n",
        "            frame_list.append(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Ïó¨Í∏∞ÏÑú Ìïú Î≤àÏóê Ï†ÄÏû•!\n",
        "    for saved_idx, frame in enumerate(frame_list):\n",
        "        frame_path = os.path.join(output_dir, f\"key_{saved_idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    return f\"{video_name}: {len(frame_list)} frames saved\"\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "video_paths = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "print(f\"üé¨ Ï¥ù {len(video_paths)}Í∞úÏùò ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\")\n",
        "\n",
        "for video_path in tqdm(video_paths, desc=\"üì¶ Processing videos\"):\n",
        "    msg = extract_video_frames(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3XEaKpDfN2",
        "outputId": "a3ed2195-5880-43b5-846f-4f4a6ac787e6",
        "cellView": "code"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ Ï¥ù 4Í∞úÏùò ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì¶ Processing videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ÌîºÏπò Ï†úÌïú Í∞ïÌôî + ÎààÎú∏ 50% Í∏∞Ï§Ä + KeyError Ìï¥Í≤∞ ÏΩîÎìú\n",
        "import cv2, os, math, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACE_MESH = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# Îàà Ï¢åÌëú Ïù∏Îç±Ïä§\n",
        "LEFT_EYE_IDX = [\n",
        "    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,\n",
        "    33, 173, 157, 158, 159, 160, 161, 246, 33\n",
        "]\n",
        "RIGHT_EYE_IDX = [\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382,\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 362\n",
        "]\n",
        "\n",
        "CORE_LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "CORE_RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_EYE_VERTICAL = [159, 145]\n",
        "RIGHT_EYE_VERTICAL = [386, 374]\n",
        "POSE_IDX = [1, 152, 33, 263, 61, 291]\n",
        "\n",
        "# ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï - ÌîºÏπò Ï†úÌïú Í∞ïÌôî, ÎààÎú∏ Í∏∞Ï§Ä ÏôÑÌôî\n",
        "YAW_T = 25\n",
        "PITCH_T = 25  # 35ÏóêÏÑú 25Î°ú Í∞ïÌôî (ÌîºÏπò Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "HEAD_DOWN_BONUS = 1  # Î≥¥ÎÑàÏä§ ÏµúÏÜåÌôî\n",
        "ENABLE_ADAPTIVE_EAR = True\n",
        "EAR_PERCENTILE_HIGH = 37 # ÏÉÅÏúÑ 50%Î•º ÎààÎú¨ ÏÉÅÌÉúÎ°ú ÌåêÏ†ï (Í∏∞Ï°¥ 40%ÏóêÏÑú ÏôÑÌôî)\n",
        "EAR_PERCENTILE_LOW = 10\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=\"double\")\n",
        "\n",
        "def get_mediapipe_landmarks(img):\n",
        "    h, w = img.shape[:2]\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = FACE_MESH.process(rgb)\n",
        "    if not res.multi_face_landmarks:\n",
        "        return None\n",
        "    lm = res.multi_face_landmarks[0]\n",
        "    coords = np.array([[p.x * w, p.y * h] for p in lm.landmark])\n",
        "    return coords\n",
        "\n",
        "def estimate_pose_mediapipe(landmarks, img_shape):\n",
        "    image_points = landmarks[POSE_IDX]\n",
        "    focal = img_shape[1]\n",
        "    center = (img_shape[1]/2, img_shape[0]/2)\n",
        "    cam = np.array([[focal, 0, center[0]], [0, focal, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "    dist = np.zeros((4,1))\n",
        "    success, rv, _ = cv2.solvePnP(model_points, image_points, cam, dist)\n",
        "    return rv if success else None\n",
        "\n",
        "def rotation_vector_to_euler(rv):\n",
        "    rmat, _ = cv2.Rodrigues(rv)\n",
        "    proj = np.hstack((rmat, np.zeros((3,1))))\n",
        "    angles = cv2.decomposeProjectionMatrix(proj)[6]\n",
        "    pitch = math.degrees(math.asin(math.sin(math.radians(angles[1][0]))))\n",
        "    yaw   = math.degrees(math.asin(math.sin(math.radians(angles[2][0]))))\n",
        "    roll  = -math.degrees(math.asin(math.sin(math.radians(angles[0][0]))))\n",
        "    return pitch, yaw, roll\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "def enhanced_eye_aspect_ratio(landmarks, is_left=True):\n",
        "    if is_left:\n",
        "        outer = landmarks[33]\n",
        "        inner = landmarks[133]\n",
        "        v1 = np.linalg.norm(landmarks[159] - landmarks[145])\n",
        "        v2 = np.linalg.norm(landmarks[158] - landmarks[153])\n",
        "        v3 = np.linalg.norm(landmarks[160] - landmarks[144])\n",
        "    else:\n",
        "        outer = landmarks[362]\n",
        "        inner = landmarks[263]\n",
        "        v1 = np.linalg.norm(landmarks[386] - landmarks[374])\n",
        "        v2 = np.linalg.norm(landmarks[385] - landmarks[373])\n",
        "        v3 = np.linalg.norm(landmarks[387] - landmarks[380])\n",
        "\n",
        "    horizontal = np.linalg.norm(outer - inner)\n",
        "    avg_vertical = (v1 + v2 + v3) / 3.0\n",
        "    return avg_vertical / horizontal\n",
        "\n",
        "def calculate_adaptive_ear_thresholds(all_ear_values):\n",
        "    \"\"\"ÏòÅÏÉÅÎ≥Ñ Ï†ÅÏùëÌòï EAR ÏûÑÍ≥ÑÍ∞í Í≥ÑÏÇ∞ - 50% Í∏∞Ï§Ä Ï†ÅÏö©\"\"\"\n",
        "    if len(all_ear_values) < 5:\n",
        "        return {\n",
        "            'high_threshold': 0.23,\n",
        "            'medium_threshold': 0.18,\n",
        "            'low_threshold': 0.15,\n",
        "            'min_threshold': 0.12\n",
        "        }\n",
        "\n",
        "    ear_array = np.array(all_ear_values)\n",
        "\n",
        "    # 50% Í∏∞Ï§ÄÏúºÎ°ú ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï\n",
        "    high_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH)  # ÏÉÅÏúÑ 50%\n",
        "    medium_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.2)  # ÏÉÅÏúÑ 60%\n",
        "    low_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.5)  # ÏÉÅÏúÑ 75%\n",
        "    min_threshold = np.percentile(ear_array, EAR_PERCENTILE_LOW)  # ÌïòÏúÑ 10%\n",
        "\n",
        "    # ÏµúÏÜåÍ∞í Î≥¥Ïû•\n",
        "    high_threshold = max(high_threshold, 0.16)  # Îçî Í¥ÄÎåÄÌïòÍ≤å\n",
        "    medium_threshold = max(medium_threshold, 0.13)\n",
        "    low_threshold = max(low_threshold, 0.10)\n",
        "    min_threshold = max(min_threshold, 0.07)\n",
        "\n",
        "    return {\n",
        "        'high_threshold': high_threshold,\n",
        "        'medium_threshold': medium_threshold,\n",
        "        'low_threshold': low_threshold,\n",
        "        'min_threshold': min_threshold,\n",
        "        'ear_stats': {\n",
        "            'mean': np.mean(ear_array),\n",
        "            'std': np.std(ear_array),\n",
        "            'min': np.min(ear_array),\n",
        "            'max': np.max(ear_array),\n",
        "            'count': len(ear_array)\n",
        "        }\n",
        "    }\n",
        "\n",
        "def is_eye_open_adaptive(landmarks, thresholds, pitch_angle=0):\n",
        "    \"\"\"Ï†ÅÏùëÌòï EAR Í∏∞Î∞ò ÎààÎú∏ ÌåêÏ†ï - ÌîºÏπò Ï°∞Ï†ï ÏµúÏÜåÌôî\"\"\"\n",
        "\n",
        "    left_eye_basic = landmarks[CORE_LEFT_EYE]\n",
        "    right_eye_basic = landmarks[CORE_RIGHT_EYE]\n",
        "\n",
        "    basic_left_ear = eye_aspect_ratio(left_eye_basic)\n",
        "    basic_right_ear = eye_aspect_ratio(right_eye_basic)\n",
        "    basic_avg_ear = (basic_left_ear + basic_right_ear) / 2.0\n",
        "\n",
        "    enhanced_left_ear = enhanced_eye_aspect_ratio(landmarks, True)\n",
        "    enhanced_right_ear = enhanced_eye_aspect_ratio(landmarks, False)\n",
        "    enhanced_avg_ear = (enhanced_left_ear + enhanced_right_ear) / 2.0\n",
        "\n",
        "    ear_difference = abs(basic_left_ear - basic_right_ear)\n",
        "\n",
        "    # ÌîºÏπò Ï°∞Ï†ï ÏµúÏÜåÌôî (Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "    pitch_factor = 1.0\n",
        "    if pitch_angle > 20:  # 20ÎèÑ Ïù¥ÏÉÅÏóêÏÑúÎßå ÏµúÏÜå Ï°∞Ï†ï\n",
        "        pitch_factor = max(0.95, 1.0 - (pitch_angle - 20) * 0.005)  # ÏµúÎåÄ 5%Îßå ÏôÑÌôî\n",
        "\n",
        "    # Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö©\n",
        "    adj_high = thresholds['high_threshold'] * pitch_factor\n",
        "    adj_medium = thresholds['medium_threshold'] * pitch_factor\n",
        "    adj_low = thresholds['low_threshold'] * pitch_factor\n",
        "    adj_min = thresholds['min_threshold'] * pitch_factor\n",
        "\n",
        "    # 4Îã®Í≥Ñ ÎààÎú∏ ÌåêÏ†ï\n",
        "    level_1 = (basic_avg_ear > adj_high and\n",
        "               enhanced_avg_ear > adj_high * 0.9 and\n",
        "               basic_left_ear > adj_medium and\n",
        "               basic_right_ear > adj_medium and\n",
        "               ear_difference < 0.08)\n",
        "\n",
        "    level_2 = (basic_avg_ear > adj_medium and\n",
        "               enhanced_avg_ear > adj_medium * 0.8 and\n",
        "               basic_left_ear > adj_low and\n",
        "               basic_right_ear > adj_low and\n",
        "               ear_difference < 0.12)\n",
        "\n",
        "    level_3 = (basic_avg_ear > adj_low and\n",
        "               basic_left_ear > adj_min and\n",
        "               basic_right_ear > adj_min and\n",
        "               ear_difference < 0.15)\n",
        "\n",
        "    level_4 = (basic_avg_ear > adj_min and\n",
        "               basic_left_ear > adj_min * 0.8 and\n",
        "               basic_right_ear > adj_min * 0.8)\n",
        "\n",
        "    # Î†àÎ≤®Î≥Ñ Ï†êÏàò Î∂ÄÏó¨\n",
        "    if level_1:\n",
        "        eye_level = 4\n",
        "    elif level_2:\n",
        "        eye_level = 3\n",
        "    elif level_3:\n",
        "        eye_level = 2\n",
        "    elif level_4:\n",
        "        eye_level = 1\n",
        "    else:\n",
        "        eye_level = 0\n",
        "\n",
        "    return eye_level, {\n",
        "        'basic_ear': basic_avg_ear,\n",
        "        'enhanced_ear': enhanced_avg_ear,\n",
        "        'left_ear': basic_left_ear,\n",
        "        'right_ear': basic_right_ear,\n",
        "        'ear_diff': ear_difference,\n",
        "        'eye_level': eye_level,\n",
        "        'pitch_factor': pitch_factor,\n",
        "        'thresholds_used': {\n",
        "            'high': adj_high,\n",
        "            'medium': adj_medium,\n",
        "            'low': adj_low,\n",
        "            'min': adj_min\n",
        "        }\n",
        "    }\n",
        "\n",
        "def frontal_score_strict_pitch(c):\n",
        "    \"\"\"ÌîºÏπò Ï†úÌïú Í∞ïÌôîÎêú Ï†ïÎ©¥ÏÑ± ÌèâÍ∞Ä Ìï®Ïàò\"\"\"\n",
        "\n",
        "    yaw_angle = abs(c['yaw'])\n",
        "    pitch_angle = c['pitch']\n",
        "\n",
        "    # ÏóÑÍ≤©Ìïú Í∞ÅÎèÑ Ï†úÌïú (ÌîºÏπò Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "    if yaw_angle > YAW_T:  # 25ÎèÑ\n",
        "        return -1000\n",
        "    if abs(pitch_angle) > PITCH_T:  # ¬±25ÎèÑ (ÏóÑÍ≤©)\n",
        "        return -1000\n",
        "\n",
        "    # Í∏∞Î≥∏ ÌéòÎÑêÌã∞ (ÌîºÏπòÏóê Îçî ÌÅ∞ Í∞ÄÏ§ëÏπò)\n",
        "    yaw_penalty = yaw_angle * 0.8\n",
        "    pitch_penalty = abs(pitch_angle) * 1.2  # ÌîºÏπò ÌéòÎÑêÌã∞ Ï¶ùÍ∞Ä\n",
        "\n",
        "    # Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§ ÏµúÏÜåÌôî\n",
        "    head_down_bonus = 0\n",
        "    if -15 <= pitch_angle <= -5:  # ÏïÑÏ£º Ï†úÌïúÏ†ÅÏù∏ Î≤îÏúÑÏóêÏÑúÎßå\n",
        "        head_down_bonus = HEAD_DOWN_BONUS * 0.5  # Î≥¥ÎÑàÏä§ÎèÑ Ï†àÎ∞òÏúºÎ°ú\n",
        "\n",
        "    # ÎààÎú∏ Î†àÎ≤® Î≥¥ÎÑàÏä§\n",
        "    eye_level = c.get('eye_level', 0)\n",
        "    eye_bonus = eye_level * 12  # ÎààÎú∏Ïù¥ Îçî Ï§ëÏöî\n",
        "\n",
        "    bonus = eye_bonus + (head_down_bonus if pitch_angle < 0 else 0)\n",
        "\n",
        "    return -(0.5 * yaw_penalty + 0.5 * pitch_penalty) + bonus\n",
        "\n",
        "def calculate_final_quality_score(pitch, yaw, eye_level, ear_details):\n",
        "    \"\"\"ÏµúÏ¢Ö ÌíàÏßà Ï†êÏàò Í≥ÑÏÇ∞ - ÌîºÏπò ÌéòÎÑêÌã∞ Í∞ïÌôî\"\"\"\n",
        "\n",
        "    # Í∞ÅÎèÑ Ï†êÏàò (ÌîºÏπòÏóê Îçî ÌÅ∞ ÌéòÎÑêÌã∞)\n",
        "    yaw_score = max(0, 100 - abs(yaw) * 2.0)\n",
        "    pitch_score = max(0, 100 - abs(pitch) * 2.5)  # ÌîºÏπò ÌéòÎÑêÌã∞ Ï¶ùÍ∞Ä\n",
        "    angle_score = (yaw_score + pitch_score) / 2\n",
        "\n",
        "    # ÎààÎú∏ Î†àÎ≤® Ï†êÏàò (50% Í∏∞Ï§ÄÏù¥ÎØÄÎ°ú Îçî Í¥ÄÎåÄ)\n",
        "    eye_score = eye_level * 25\n",
        "\n",
        "    # EAR ÌíàÏßà Ï†êÏàò\n",
        "    ear_quality = min(100, ear_details['basic_ear'] * 300)\n",
        "\n",
        "    # Ï¢ÖÌï© Ï†êÏàò (ÎààÎú∏ ÎπÑÏ§ë Ï¶ùÍ∞Ä)\n",
        "    total_score = (\n",
        "        angle_score * 0.3 +    # Í∞ÅÎèÑ 30%\n",
        "        eye_score * 0.5 +      # ÎààÎú∏ 50% (Ï¶ùÍ∞Ä)\n",
        "        ear_quality * 0.2      # EAR ÌíàÏßà 20%\n",
        "    )\n",
        "\n",
        "    return total_score\n",
        "\n",
        "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "INPUT_ROOT = \"/content/extract_frames\"\n",
        "OUTPUT_ROOT = \"/content/alignmented_frame\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "file_ext = \".jpg\"\n",
        "video_dirs = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
        "missing_videos = []\n",
        "detailed_log = []\n",
        "best_images = []\n",
        "best_names = []\n",
        "\n",
        "print(f\"üì¶ Ï¥ù {len(video_dirs)}Í∞ú ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\")\n",
        "print(f\"üéØ ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ {EAR_PERCENTILE_HIGH}% (50% Í∏∞Ï§ÄÏúºÎ°ú ÏôÑÌôî)\")\n",
        "print(f\"üìê Í∞ÅÎèÑ Ï†úÌïú: Yaw ¬±{YAW_T}¬∞, Pitch ¬±{PITCH_T}¬∞ (ÌîºÏπò Ï†úÌïú Í∞ïÌôî)\")\n",
        "print(f\"üéÅ Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: {HEAD_DOWN_BONUS}Ï†ê (ÏµúÏÜåÌôî)\")\n",
        "\n",
        "for video_name in tqdm(video_dirs, desc=\"üéØ Strict pitch + 50% eye threshold\"):\n",
        "    input_dir = os.path.join(INPUT_ROOT, video_name)\n",
        "\n",
        "    # 1Îã®Í≥Ñ: Î™®Îì† ÌîÑÎ†àÏûÑÏùò EAR Í∞í ÏàòÏßë\n",
        "    all_ear_values = []\n",
        "    frame_data = []\n",
        "\n",
        "    for f in sorted(os.listdir(input_dir)):\n",
        "        if not f.lower().endswith(file_ext):\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(input_dir, f)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        lm = get_mediapipe_landmarks(img)\n",
        "        if lm is None:\n",
        "            continue\n",
        "\n",
        "        rv = estimate_pose_mediapipe(lm, img.shape)\n",
        "        if rv is None:\n",
        "            continue\n",
        "\n",
        "        pitch, yaw, _ = rotation_vector_to_euler(rv)\n",
        "\n",
        "        # ÏóÑÍ≤©Ìïú Í∞ÅÎèÑ Ï†úÌïú\n",
        "        if abs(yaw) > YAW_T * 1.5 or abs(pitch) > PITCH_T * 1.5:\n",
        "            continue\n",
        "\n",
        "        # EAR Í≥ÑÏÇ∞\n",
        "        left_eye = lm[CORE_LEFT_EYE]\n",
        "        right_eye = lm[CORE_RIGHT_EYE]\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        all_ear_values.append(avg_ear)\n",
        "\n",
        "        # ÌîÑÎ†àÏûÑ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\n",
        "        x1, y1 = lm[:,0].min(), lm[:,1].min()\n",
        "        x2, y2 = lm[:,0].max(), lm[:,1].max()\n",
        "        face_area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "        frame_data.append({\n",
        "            'img': img,\n",
        "            'filename': f,\n",
        "            'landmarks': lm,\n",
        "            'pitch': pitch,\n",
        "            'yaw': yaw,\n",
        "            'avg_ear': avg_ear,\n",
        "            'cx': cx,\n",
        "            'cy': cy,\n",
        "            'face_area': face_area\n",
        "        })\n",
        "\n",
        "    if not all_ear_values:\n",
        "        missing_videos.append(video_name)\n",
        "        detailed_log.append({\n",
        "            'video_name': video_name,\n",
        "            'total_frames': 0,\n",
        "            'selected': False,\n",
        "            'selection_level': 0,  # KeyError Î∞©ÏßÄÎ•º ÏúÑÌï¥ Ï∂îÍ∞Ä\n",
        "            'reason': 'No valid frames found'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 2Îã®Í≥Ñ: Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Í≥ÑÏÇ∞ (50% Í∏∞Ï§Ä)\n",
        "    thresholds = calculate_adaptive_ear_thresholds(all_ear_values)\n",
        "\n",
        "    # 3Îã®Í≥Ñ: 4Îã®Í≥Ñ ÌõÑÎ≥¥ Î∂ÑÎ•ò\n",
        "    level_4_candidates = []\n",
        "    level_3_candidates = []\n",
        "    level_2_candidates = []\n",
        "    level_1_candidates = []\n",
        "\n",
        "    for frame in frame_data:\n",
        "        # ÏóÑÍ≤©Ìïú ÌîºÏπò Ï†úÌïú Ï†ÅÏö©\n",
        "        if abs(frame['pitch']) > PITCH_T:\n",
        "            continue\n",
        "\n",
        "        eye_level, eye_details = is_eye_open_adaptive(\n",
        "            frame['landmarks'], thresholds, abs(frame['pitch'])\n",
        "        )\n",
        "\n",
        "        if eye_level == 0:\n",
        "            continue\n",
        "\n",
        "        candidate = {\n",
        "            'img': frame['img'],\n",
        "            'filename': frame['filename'],\n",
        "            'pitch': frame['pitch'],\n",
        "            'yaw': frame['yaw'],\n",
        "            'cx': frame['cx'],\n",
        "            'cy': frame['cy'],\n",
        "            'face_area': frame['face_area'],\n",
        "            'w': frame['img'].shape[1],\n",
        "            'h': frame['img'].shape[0],\n",
        "            'eye_level': eye_level,\n",
        "            'eye_details': eye_details,\n",
        "            'quality_score': calculate_final_quality_score(\n",
        "                frame['pitch'], frame['yaw'], eye_level, eye_details\n",
        "            )\n",
        "        }\n",
        "\n",
        "        if eye_level == 4:\n",
        "            level_4_candidates.append(candidate)\n",
        "        elif eye_level == 3:\n",
        "            level_3_candidates.append(candidate)\n",
        "        elif eye_level == 2:\n",
        "            level_2_candidates.append(candidate)\n",
        "        else:\n",
        "            level_1_candidates.append(candidate)\n",
        "\n",
        "    # 4Îã®Í≥Ñ: ÏµúÏ†Å ÌîÑÎ†àÏûÑ ÏÑ†ÌÉù\n",
        "    best_img = None\n",
        "    best_filename = None\n",
        "    selection_reason = \"No suitable frames\"\n",
        "    selection_level = 0\n",
        "\n",
        "    if level_4_candidates:\n",
        "        best = max(level_4_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 4: Selected from {len(level_4_candidates)} highest quality candidates\"\n",
        "        selection_level = 4\n",
        "\n",
        "    elif level_3_candidates:\n",
        "        best = max(level_3_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 3: Selected from {len(level_3_candidates)} high quality candidates\"\n",
        "        selection_level = 3\n",
        "\n",
        "    elif level_2_candidates:\n",
        "        best = max(level_2_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 2: Selected from {len(level_2_candidates)} medium quality candidates\"\n",
        "        selection_level = 2\n",
        "\n",
        "    elif level_1_candidates:\n",
        "        best = max(level_1_candidates, key=lambda x: x['quality_score'])\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 1: Selected from {len(level_1_candidates)} minimum quality candidates\"\n",
        "        selection_level = 1\n",
        "\n",
        "    elif frame_data:\n",
        "        # ÏµúÌõÑÏùò ÏàòÎã®: Í∞ÄÏû• ÌíàÏßà Ï¢ãÏùÄ ÌîÑÎ†àÏûÑ Î¨¥Ï°∞Í±¥ ÏÑ†ÌÉù\n",
        "        best_frame = max(frame_data, key=lambda x: x['avg_ear'])\n",
        "        best_img = best_frame['img']\n",
        "        best_filename = best_frame['filename']\n",
        "        selection_reason = f\"Emergency: Selected best EAR frame ({best_frame['avg_ear']:.3f})\"\n",
        "        selection_level = 0\n",
        "\n",
        "    # KeyError Î∞©ÏßÄÎ•º ÏúÑÌïú ÏïàÏ†ÑÌïú Î°úÍ∑∏ Í∏∞Î°ù\n",
        "    detailed_log.append({\n",
        "        'video_name': video_name,\n",
        "        'total_frames': len(frame_data),\n",
        "        'level_4_candidates': len(level_4_candidates),\n",
        "        'level_3_candidates': len(level_3_candidates),\n",
        "        'level_2_candidates': len(level_2_candidates),\n",
        "        'level_1_candidates': len(level_1_candidates),\n",
        "        'selected': best_filename is not None,\n",
        "        'selection_level': selection_level,  # Ìï≠ÏÉÅ Ìè¨Ìï®\n",
        "        'best_filename': best_filename,\n",
        "        'reason': selection_reason,\n",
        "        'ear_thresholds': thresholds,\n",
        "        'quality_score': best.get('quality_score', 0) if 'best' in locals() else 0\n",
        "    })\n",
        "\n",
        "    # ÌîÑÎ†àÏûÑ Ï†ÄÏû•\n",
        "    if best_img is not None:\n",
        "        save_path = os.path.join(OUTPUT_ROOT, f\"{video_name}.jpg\")\n",
        "        cv2.imwrite(save_path, best_img)\n",
        "\n",
        "        if selection_level <= 1:\n",
        "            print(f\"‚ö†Ô∏è  {video_name}: Low quality selection (Level {selection_level})\")\n",
        "    else:\n",
        "        missing_videos.append(video_name)\n",
        "\n",
        "# Í≤∞Í≥º Ï†ÄÏû•\n",
        "if missing_videos:\n",
        "    df_missing = pd.DataFrame(missing_videos, columns=[\"video_name\"])\n",
        "    df_missing.to_csv(\"no_frame_found.csv\", index=False)\n",
        "    print(f\"‚ùó {len(missing_videos)}Í∞ú ÏòÅÏÉÅÏóêÏÑú ÌîÑÎ†àÏûÑÏùÑ Ï∞æÏßÄ Î™ªÌï®\")\n",
        "\n",
        "df_log = pd.DataFrame(detailed_log)\n",
        "df_log.to_csv(\"strict_pitch_50percent_eye_log.csv\", index=False)\n",
        "print(f\"üìä Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû•: strict_pitch_50percent_eye_log.csv\")\n",
        "\n",
        "# KeyError Î∞©ÏßÄÎêú ÏïàÏ†ÑÌïú ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
        "success_rate = (len(video_dirs) - len(missing_videos)) / len(video_dirs) * 100 if video_dirs else 0\n",
        "\n",
        "# .get() Î©îÏÑúÎìú ÏÇ¨Ïö©ÏúºÎ°ú KeyError Î∞©ÏßÄ\n",
        "level_4_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 4)\n",
        "level_3_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 3)\n",
        "level_2_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 2)\n",
        "level_1_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 1)\n",
        "emergency_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 0)\n",
        "\n",
        "print(f\"‚úÖ ÏÑ±Í≥µÎ•†: {success_rate:.1f}% ({len(video_dirs) - len(missing_videos)}/{len(video_dirs)})\")\n",
        "print(f\"üèÜ Level 4 (ÏµúÍ≥†ÌíàÏßà): {level_4_usage}Í∞ú\")\n",
        "print(f\"ü•à Level 3 (Í≥†ÌíàÏßà): {level_3_usage}Í∞ú\")\n",
        "print(f\"ü•â Level 2 (Ï§ëÌíàÏßà): {level_2_usage}Í∞ú\")\n",
        "print(f\"üìâ Level 1 (ÏµúÏÜåÌíàÏßà): {level_1_usage}Í∞ú\")\n",
        "print(f\"üö® Emergency (Í∞ïÏ†úÏÑ†ÌÉù): {emergency_usage}Í∞ú\")\n",
        "\n",
        "print(f\"\\nüìà ÌíàÏßà Î∂ÑÌè¨:\")\n",
        "print(f\"   - Í≥†ÌíàÏßà Ïù¥ÏÉÅ (Level 3+): {(level_4_usage + level_3_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - Ï§ëÌíàÏßà Ïù¥ÏÉÅ (Level 2+): {(level_4_usage + level_3_usage + level_2_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - ÏµúÏÜåÌíàÏßà Ïù¥ÏÉÅ (Level 1+): {(len(video_dirs) - emergency_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nüéØ ÏÑ§Ï†ï ÏöîÏïΩ:\")\n",
        "print(f\"   - ÌîºÏπò Ï†úÌïú: ¬±{PITCH_T}¬∞ (ÏóÑÍ≤©)\")\n",
        "print(f\"   - ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ {EAR_PERCENTILE_HIGH}% (Í¥ÄÎåÄ)\")\n",
        "print(f\"   - Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: {HEAD_DOWN_BONUS}Ï†ê (ÏµúÏÜå)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlELfbUkEFea",
        "outputId": "d31c2614-d3c1-4a0c-f3b3-dd7c4bce42b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Ï¥ù 4Í∞ú ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\n",
            "üéØ ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ 37% (50% Í∏∞Ï§ÄÏúºÎ°ú ÏôÑÌôî)\n",
            "üìê Í∞ÅÎèÑ Ï†úÌïú: Yaw ¬±25¬∞, Pitch ¬±25¬∞ (ÌîºÏπò Ï†úÌïú Í∞ïÌôî)\n",
            "üéÅ Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: 1Ï†ê (ÏµúÏÜåÌôî)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üéØ Strict pitch + 50% eye threshold: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:04<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû•: strict_pitch_50percent_eye_log.csv\n",
            "‚úÖ ÏÑ±Í≥µÎ•†: 100.0% (4/4)\n",
            "üèÜ Level 4 (ÏµúÍ≥†ÌíàÏßà): 2Í∞ú\n",
            "ü•à Level 3 (Í≥†ÌíàÏßà): 2Í∞ú\n",
            "ü•â Level 2 (Ï§ëÌíàÏßà): 0Í∞ú\n",
            "üìâ Level 1 (ÏµúÏÜåÌíàÏßà): 0Í∞ú\n",
            "üö® Emergency (Í∞ïÏ†úÏÑ†ÌÉù): 0Í∞ú\n",
            "\n",
            "üìà ÌíàÏßà Î∂ÑÌè¨:\n",
            "   - Í≥†ÌíàÏßà Ïù¥ÏÉÅ (Level 3+): 100.0%\n",
            "   - Ï§ëÌíàÏßà Ïù¥ÏÉÅ (Level 2+): 100.0%\n",
            "   - ÏµúÏÜåÌíàÏßà Ïù¥ÏÉÅ (Level 1+): 100.0%\n",
            "\n",
            "üéØ ÏÑ§Ï†ï ÏöîÏïΩ:\n",
            "   - ÌîºÏπò Ï†úÌïú: ¬±25¬∞ (ÏóÑÍ≤©)\n",
            "   - ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ 37% (Í¥ÄÎåÄ)\n",
            "   - Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: 1Ï†ê (ÏµúÏÜå)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "H_23qUpRqSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2bb6e9-f459-412c-aae6-efcabc321ce4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image crop"
      ],
      "metadata": {
        "id": "22A2atJxxcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan3-editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W19HlMQIxcMs",
        "outputId": "3862cc4a-ab2a-4f43-837b-066c8c08ec8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3-editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/stylegan3-editing')"
      ],
      "metadata": {
        "id": "UE0wMtQ79bS1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "base_raw_root = \"/content/alignmented_frame\"\n",
        "aligned_root = f\"{base_raw_root}_aligned\"\n",
        "cropped_root = f\"{base_raw_root}_croped\"\n",
        "transform_root = f\"{base_raw_root}_transforms\"\n",
        "\n",
        "print(\"üöÄ Aligning all images...\")\n",
        "# Ïã§Ìñâ Î™ÖÎ†πÏñ¥Ïóê PYTHONPATHÎ•º Ï∂îÍ∞ÄÌïòÏó¨ Î™®ÎìàÏùÑ Ï∞æÏùÑ Í≤ΩÎ°úÎ•º ÏïåÎ†§Ï§çÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode align \\\n",
        "    --root_path \"{base_raw_root}\"\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"üîÅ Cropping all images...\")\n",
        "# Ïó¨Í∏∞ÎèÑ ÎèôÏùºÌïòÍ≤å Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode crop \\\n",
        "    --root_path \"{base_raw_root}\" \\\n",
        "    --random_shift 0.05\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"üîÅ Computing transforms for all images...\")\n",
        "# Ïó¨Í∏∞ÎèÑ ÎèôÏùºÌïòÍ≤å Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/compute_landmarks_transforms.py \\\n",
        "    --raw_root \"{base_raw_root}\" \\\n",
        "    --aligned_root \"{aligned_root}\" \\\n",
        "    --cropped_root \"{cropped_root}\" \\\n",
        "    --output_root \"{transform_root}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kzg1k-FxgA2",
        "outputId": "938b7d96-f1fb-47c8-b6b3-cc46ef54f878"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Aligning all images...\n",
            "1\n",
            "Running on 4 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #4 images\n",
            "\tDone!\n",
            "Mischief managed in -2.17536997795105s\n",
            "üîÅ Cropping all images...\n",
            "1\n",
            "Running on 4 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #4 images\n",
            "\tDone!\n",
            "Mischief managed in -2.1390206813812256s\n",
            "üîÅ Computing transforms for all images...\n",
            "Computing landmarks transforms...\n",
            "100% 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
        "input_root = \"/content/alignmented_frame_croped\"\n",
        "transforms_root = \"/content/alignmented_frame_transforms/landmarks_transforms.npy\"\n",
        "output_root = \"/content/experiments/restyle_e4e_sg3\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "\n",
        "# output ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "print(\"üöÄ Inverting video\")\n",
        "\n",
        "!python {script_path} \\\n",
        "    --output_path \"{output_root}\" \\\n",
        "    --checkpoint_path \"{ckpt_path}\" \\\n",
        "    --data_path \"{input_root}\" \\\n",
        "    --test_batch_size 4 \\\n",
        "    --test_workers 4 \\\n",
        "    --n_iters_per_batch 3 \\\n",
        "    --landmarks_transforms_path \"{transforms_root}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdozUaBz7ja",
        "outputId": "3bbc52e1-2527-44ca-f507-dfe7e9368060"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Inverting video\n",
            "Loading ReStyle e4e from checkpoint: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "Loading StyleGAN3 generator from path: None\n",
            "Done!\n",
            "Model successfully loaded!\n",
            "Loading dataset for ffhq_encode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 1/1 [00:07<00:00,  7.11s/it]\n",
            "Runtime 6.2578+-0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save CSV"
      ],
      "metadata": {
        "id": "BAaQSZUwoGsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load latent dictionary\n",
        "latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "latent_dict = np.load(latent_path, allow_pickle=True).item()\n",
        "\n",
        "# 2. Ï†ïÎ†¨Îêú ÌååÏùº Î¶¨Ïä§Ìä∏ ÌôïÎ≥¥\n",
        "filenames = sorted(latent_dict.keys())\n",
        "\n",
        "# 3. Í∞Å latentÏóêÏÑú ÎßàÏßÄÎßâ step ‚Üí ÌèâÍ∑† ‚Üí (512,)\n",
        "latents = []\n",
        "for key in filenames:\n",
        "    latent = latent_dict[key][-1]  # ÎßàÏßÄÎßâ step (18, 512)\n",
        "    mean_latent = latent.mean(axis=0).astype('float32')  # (512,)\n",
        "    latents.append(mean_latent)\n",
        "\n",
        "latents = np.stack(latents)  # shape: (N, 512)\n",
        "\n",
        "# 4. cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(latents)  # shape: (N, N)\n",
        "\n",
        "# 5. Í∞Å query ÌååÏùºÎßàÎã§ top-3 Ïú†ÏÇ¨Ìïú match + score Ï†ÄÏû•\n",
        "rows = []\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    sims = sim_matrix[i].copy()\n",
        "    sims[i] = -np.inf  # ÏûêÍ∏∞ ÏûêÏã† Ï†úÏô∏\n",
        "    top3_idx = np.argsort(sims)[::-1][:3]\n",
        "    row = {\n",
        "        \"query\": filenames[i],\n",
        "        \"top1\": filenames[top3_idx[0]],\n",
        "        \"top2\": filenames[top3_idx[1]],\n",
        "        \"top3\": filenames[top3_idx[2]],\n",
        "        \"top1val\": round(float(sims[top3_idx[0]]), 6),\n",
        "        \"top2val\": round(float(sims[top3_idx[1]]), 6),\n",
        "        \"top3val\": round(float(sims[top3_idx[2]]), 6),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 6. Save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"video_similarity_top3_compact.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Saved to video_similarity_top3_compact.csv\")\n"
      ],
      "metadata": {
        "id": "WjMFJ5i2oE78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5054a632-00c8-4456-c8c9-ea549812d161"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved to video_similarity_top3_compact.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "original_latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "\n",
        "# Load\n",
        "latent_dict = np.load(original_latent_path, allow_pickle=True).item()\n",
        "print(f\"‚úÖ latent Í∞úÏàò: {len(latent_dict)}\")\n",
        "\n",
        "# Preview\n",
        "preview = []\n",
        "for k, v in latent_dict.items():\n",
        "    latent_array = np.array(v)\n",
        "    print(f\"üîπ {k} ‚Üí shape: {latent_array.shape}, ÎßàÏßÄÎßâ step: {latent_array[-1].shape}\")\n",
        "    preview.append(k)\n",
        "    if len(preview) >= 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sugcp8d_WFi",
        "outputId": "bab8f4af-9d74-4b6f-ad52-2c6555cf493d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ latent Í∞úÏàò: 4\n",
            "üîπ 0078.jpg ‚Üí shape: (3, 16, 512), ÎßàÏßÄÎßâ step: (16, 512)\n",
            "üîπ 0082.jpg ‚Üí shape: (3, 16, 512), ÎßàÏßÄÎßâ step: (16, 512)\n",
            "üîπ 0085.jpg ‚Üí shape: (3, 16, 512), ÎßàÏßÄÎßâ step: (16, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# Í≤ΩÎ°ú\n",
        "generated_image_dir = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "temp_input_dir = \"/content/temp_comparison/generated_input\"\n",
        "os.makedirs(temp_input_dir, exist_ok=True)\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄ Î≥µÏÇ¨ + Ïù¥Î¶Ñ Îß§Ìïë\n",
        "generated_images = sorted(glob(os.path.join(generated_image_dir, \"*.jpg\")) +\n",
        "                          glob(os.path.join(generated_image_dir, \"*.png\")))\n",
        "\n",
        "img_name_map = {}\n",
        "for img_path in generated_images:\n",
        "    original_name = os.path.basename(img_path)\n",
        "    name_wo_ext = os.path.splitext(original_name)[0]\n",
        "    target_name = f\"{name_wo_ext}.jpg\"  # ÌôïÏû•Ïûê ÌÜµÏùº\n",
        "    shutil.copy2(img_path, os.path.join(temp_input_dir, target_name))\n",
        "    img_name_map[target_name] = name_wo_ext  # '0078.jpg' : '0078'\n",
        "\n",
        "print(f\"‚úÖ Î≥µÏÇ¨ ÏôÑÎ£å: {len(img_name_map)}Í∞ú\")\n",
        "print(f\"ÏòàÏãú Îß§Ìïë: {list(img_name_map.items())[:3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oHhJRdRC3N7",
        "outputId": "fb896ebb-8145-47b1-d33e-248a858dacdf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Î≥µÏÇ¨ ÏôÑÎ£å: 4Í∞ú\n",
            "ÏòàÏãú Îß§Ìïë: [('0078.jpg', '0078'), ('0082.jpg', '0082'), ('0085.jpg', '0085')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "temp_output_dir = \"/content/temp_comparison/generated_output\"\n",
        "os.makedirs(temp_output_dir, exist_ok=True)\n",
        "\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "\n",
        "cmd = [\n",
        "    \"python\", script_path,\n",
        "    \"--output_path\", temp_output_dir,\n",
        "    \"--checkpoint_path\", ckpt_path,\n",
        "    \"--data_path\", temp_input_dir,\n",
        "    \"--test_batch_size\", \"4\",\n",
        "    \"--test_workers\", \"2\",\n",
        "    \"--n_iters_per_batch\", \"3\"\n",
        "]\n",
        "\n",
        "print(\"üöÄ Inverting generated images...\")\n",
        "subprocess.run(cmd, check=True, cwd=\"/content/stylegan3-editing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwCH8KNC5mM",
        "outputId": "999919f9-2d24-4e72-e6c3-5a29dae923d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Inverting generated images...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', '/content/stylegan3-editing/inversion/scripts/inference_iterative.py', '--output_path', '/content/temp_comparison/generated_output', '--checkpoint_path', '/content/pretrained_models/restyle_e4e_sg3.pt', '--data_path', '/content/temp_comparison/generated_input', '--test_batch_size', '4', '--test_workers', '2', '--n_iters_per_batch', '3'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "\n",
        "# üîß Í≤ΩÎ°ú\n",
        "original_latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "generated_latent_path = \"/content/temp_comparison/generated_output/latents.npy\"\n",
        "\n",
        "# ‚úÖ ÏõêÎ≥∏ latent Î°úÎìú\n",
        "original_latents_raw = np.load(original_latent_path, allow_pickle=True).item()\n",
        "original_latents = {}\n",
        "for k, v in original_latents_raw.items():\n",
        "    key = os.path.splitext(os.path.basename(k))[0]  # ex: '0078'\n",
        "    final_latent = v[-1]  # ÎßàÏßÄÎßâ step (16, 512)\n",
        "    original_latents[key] = {\n",
        "        \"mean\": final_latent.mean(axis=0).astype(\"float32\"),\n",
        "        \"full\": final_latent\n",
        "    }\n",
        "\n",
        "# ‚úÖ ÏÉùÏÑ±Îêú latent Î°úÎìú\n",
        "generated_latents_raw = np.load(generated_latent_path, allow_pickle=True).item()\n",
        "print(f\"üîç ÎπÑÍµê ÏãúÏûë: {len(generated_latents_raw)}Í∞ú latent\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for gen_fname, latent_seq in generated_latents_raw.items():\n",
        "    # ex: gen_fname = '0_0078.jpg'\n",
        "    if \"_\" in gen_fname:\n",
        "        _, clean_name = gen_fname.split(\"_\", 1)\n",
        "    else:\n",
        "        clean_name = gen_fname\n",
        "    base_name = os.path.splitext(clean_name)[0]  # '0078'\n",
        "\n",
        "    if base_name not in original_latents:\n",
        "        print(f\"‚ö†Ô∏è ÏõêÎ≥∏ latent ÏóÜÏùå: {base_name}\")\n",
        "        continue\n",
        "\n",
        "    gen_final = latent_seq[-1]\n",
        "    gen_mean = gen_final.mean(axis=0).astype(\"float32\")\n",
        "\n",
        "    orig = original_latents[base_name]\n",
        "    orig_mean = orig[\"mean\"]\n",
        "    orig_full = orig[\"full\"]\n",
        "\n",
        "    num_layers = gen_final.shape[0]  # ex: 16\n",
        "    layer_similarities = [\n",
        "        cosine_similarity([orig_full[i]], [gen_final[i]])[0][0]\n",
        "        for i in range(num_layers)\n",
        "    ]\n",
        "\n",
        "    results.append({\n",
        "        \"filename\": base_name,\n",
        "        \"cosine_similarity\": cosine_similarity([orig_mean], [gen_mean])[0][0],\n",
        "        \"euclidean_distance\": np.linalg.norm(orig_mean - gen_mean),\n",
        "        \"dot_product\": np.dot(orig_mean, gen_mean),\n",
        "        \"coarse_similarity\": np.mean(layer_similarities[:4]),\n",
        "        \"middle_similarity\": np.mean(layer_similarities[4:8]),\n",
        "        \"fine_similarity\": np.mean(layer_similarities[8:]),\n",
        "        \"overall_layer_similarity\": np.mean(layer_similarities)\n",
        "    })\n",
        "\n",
        "# ‚úÖ Í≤∞Í≥º Ï†ÄÏû•\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"original_vs_generated_latent_comparison.csv\", index=False)\n",
        "print(\"‚úÖ ÎπÑÍµê Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: original_vs_generated_latent_comparison.csv\")\n",
        "\n",
        "# ‚úÖ ÏöîÏïΩ Ï∂úÎ†•\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFGpSFBiC-sD",
        "outputId": "5c9d1df7-db41-43b4-84b3-0393bc454448"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç ÎπÑÍµê ÏãúÏûë: 16Í∞ú latent\n",
            "‚úÖ ÎπÑÍµê Í≤∞Í≥º Ï†ÄÏû• ÏôÑÎ£å: original_vs_generated_latent_comparison.csv\n",
            "  filename  cosine_similarity  euclidean_distance  dot_product  \\\n",
            "0     0078           0.993890            6.603614  1515.480469   \n",
            "1     0082           0.990977            5.524122  1344.796021   \n",
            "2     0085           0.986965            5.590951  1117.199463   \n",
            "3     0088           0.989110            6.591540  1331.661621   \n",
            "4     0078           0.993890            6.603614  1515.480469   \n",
            "\n",
            "   coarse_similarity  middle_similarity  fine_similarity  \\\n",
            "0           0.990240           0.960588         0.969627   \n",
            "1           0.975562           0.941908         0.956201   \n",
            "2           0.975146           0.900363         0.946926   \n",
            "3           0.977361           0.938678         0.955962   \n",
            "4           0.990240           0.960588         0.969627   \n",
            "\n",
            "   overall_layer_similarity  \n",
            "0                  0.972521  \n",
            "1                  0.957468  \n",
            "2                  0.942340  \n",
            "3                  0.956991  \n",
            "4                  0.972521  \n"
          ]
        }
      ]
    }
  ]
}