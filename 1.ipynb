{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로딩"
      ],
      "metadata": {
        "id": "FnfNNJz2BwN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data():\n",
        "    train_path = '/content/u.base'\n",
        "    test_path = '/content/u.test'\n",
        "\n",
        "    # Load training and testing data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Determine the number of users and movies\n",
        "    num_users = max(train_data['user_id'].max(), test_data['user_id'].max())\n",
        "    num_movies = max(train_data['item_id'].max(), test_data['item_id'].max())\n",
        "\n",
        "    # Convert to zero-based index\n",
        "    train_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['rating']] = 1 # NaN을 모두 1로 바꿔줌\n",
        "\n",
        "    train, valid = train_test_split(train_data, test_size=0.1, random_state = 1234)\n",
        "\n",
        "    # Create matrices\n",
        "    train_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "    valid_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "\n",
        "\n",
        "    for row in train.itertuples():\n",
        "        train_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "    for row in valid.itertuples():\n",
        "        valid_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "\n",
        "    return num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data\n"
      ],
      "metadata": {
        "id": "p2EvqZIaudah"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation 평가"
      ],
      "metadata": {
        "id": "DhrtYhPjB0yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation 평가\n",
        "def eval(model, train_data, valid_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = np.where(valid_data > 0)\n",
        "\n",
        "    # 예측값을 원래 스케일로 복원 (0-1 -> 1-5)\n",
        "    pred_original_scale = pred_u_score * 4.0 + 1.0\n",
        "    valid_original_scale = valid_data * 4.0 + 1.0\n",
        "\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(valid_original_scale[target_item], pred_original_scale[target_item]))\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "53KhetYhBsVP"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "3h2XEB-lB3NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx\n",
        "\n",
        "\n",
        "\n",
        "class MSELoss:\n",
        "    def __init__(self, weight_decay_lambda=0.01):\n",
        "        self.loss = None # 손실함수\n",
        "        self.y = None    # 출력\n",
        "        self.t = None    # 정답 레이블\n",
        "        self.t_mask = None   # 정답에서 0이 아닌 부분만 loss 계산\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "\n",
        "    def forward(self, x, t, params=None):\n",
        "        self.t = t\n",
        "        self.t_mask = np.where( t >= 0.5)\n",
        "        self.y = x\n",
        "        self.loss = (self.y - self.t)**2\n",
        "        loss = np.mean(self.loss[self.t_mask]) * 0.5\n",
        "\n",
        "        if params is not None and self.weight_decay_lambda > 0:\n",
        "            weight_decay = 0\n",
        "            for idx in range(1, len(params)//2 + 1):\n",
        "                weight_key = 'W' + str(idx)\n",
        "                if weight_key in params:\n",
        "                    W = params[weight_key]\n",
        "                    weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
        "            loss += weight_decay\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dx = ( self.y - self.t) / len(self.y[self.t_mask])\n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "GYuA47b3ZYej"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class MultiLayerNet:\n",
        "    \"\"\"완전연결 다층 신경망\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size_list, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size_list = hidden_size_list\n",
        "        self.hidden_layer_num = len(hidden_size_list)\n",
        "        self.params = {}\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self.__init_weight()\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        for idx in range(1, self.hidden_layer_num+1):\n",
        "            self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "                                                      self.params['b' + str(idx)])\n",
        "            self.layers['Activation_function' + str(idx)] =Relu()\n",
        "\n",
        "        idx = self.hidden_layer_num + 1\n",
        "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "            self.params['b' + str(idx)])\n",
        "\n",
        "        self.last_layer = MSELoss()\n",
        "\n",
        "    def __init_weight(self):\n",
        "      layer_sizes = [self.input_size]\n",
        "      for hidden_size in self.hidden_size_list:\n",
        "          layer_sizes.append(hidden_size)\n",
        "      layer_sizes.append(self.output_size)\n",
        "\n",
        "\n",
        "      for i in range(1, len(layer_sizes)):\n",
        "          prev_size = layer_sizes[i-1]\n",
        "          current_size = layer_sizes[i]\n",
        "\n",
        "          xavier_scale = np.sqrt(2.0 / (prev_size + current_size))\n",
        "\n",
        "          weight_key = 'W' + str(i)\n",
        "          self.params[weight_key] = xavier_scale * np.random.randn(prev_size, current_size)\n",
        "\n",
        "          bias_key = 'b' + str(i)\n",
        "          self.params[bias_key] = np.zeros(current_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        \"\"\"손실 함수를 구한다.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        손실 함수의 값\n",
        "        \"\"\"\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return self.last_layer.forward(y, t, self.params)\n",
        "\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        \"\"\"기울기를 구한다(오차역전파법).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        각 층의 기울기를 담은 딕셔너리(dictionary) 변수\n",
        "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
        "            grads['b1']、grads['b2']、... 각 층의 편향\n",
        "        \"\"\"\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        for idx in range(1, self.hidden_layer_num+2):\n",
        "            grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW\n",
        "            grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "tnhB1vd3CGIX"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ],
      "metadata": {
        "id": "sI6-Qu3JCP59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Adam:\n",
        "\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def update(self, params, grads):\n",
        "\n",
        "        if self.m is None or self.v is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key in params.keys():\n",
        "                self.m[key] = np.zeros_like(params[key])\n",
        "                self.v[key] = np.zeros_like(params[key])\n",
        "\n",
        "        self.iter += 1\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.m[key] = self.beta1 * self.m[key] + (1.0 - self.beta1) * grads[key]\n",
        "            self.v[key] = self.beta2 * self.v[key] + (1.0 - self.beta2) * (grads[key] ** 2)\n",
        "            m_corrected = self.m[key] / (1.0 - self.beta1 ** self.iter)\n",
        "            v_corrected = self.v[key] / (1.0 - self.beta2 ** self.iter)\n",
        "            params[key] -= self.lr * m_corrected / (np.sqrt(v_corrected) + self.epsilon)"
      ],
      "metadata": {
        "id": "vyN7VyTlCSo6"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission 만들기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pandas import DataFrame\n",
        "def make_submission(model, train_data, test_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = (test_data['user_id'].to_numpy(), test_data['item_id'].to_numpy())\n",
        "\n",
        "    pred_original_scale = pred_u_score[target_item] * 4.0 + 1.0\n",
        "    pred_original_scale = np.clip(pred_original_scale, 1.0, 5.0)\n",
        "\n",
        "    results = pd.DataFrame()\n",
        "    results[\"target_id\"] = test_data[\"target_id\"]\n",
        "    results[\"rating\"] = pred_original_scale\n",
        "    print(results.head())  # 결과 확인용\n",
        "    results.to_csv('/content/submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DgX4D_md-FwP"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "zcb7o5gbCjsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# colab에서 나오는 warning들을 무시\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 결과 재현을 위해 Seed를 고정\n",
        "def seed_everything(random_seed):\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "seed = 1\n",
        "seed_everything(seed)\n",
        "\n",
        "\n",
        "# 0. 데이터 읽기==========\n",
        "num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data = load_data()\n",
        "\n",
        "\n",
        "# 1. 실험용 설정==========\n",
        "train_size = num_users\n",
        "max_epochs = 30\n",
        "batch_size = 60\n",
        "initial_lr = 0.001\n",
        "decay_rate = 0.97\n",
        "patience = 10\n",
        "\n",
        "optimizers = Adam(lr=initial_lr, beta1=0.9, beta2=0.999)\n",
        "train_loss = []\n",
        "Model = MultiLayerNet(\n",
        "        input_size=num_movies, hidden_size_list=[40, 30],\n",
        "        output_size=num_movies)\n",
        "\n",
        "\n",
        "# 2. 훈련 시작==========\n",
        "best_rmse = float('inf')\n",
        "best_epoch = 0\n",
        "best_params = {}\n",
        "counter = 0\n",
        "\n",
        "for i in range(max_epochs):\n",
        "    if i > 10:\n",
        "      optimizers.lr = initial_lr * (decay_rate ** (i-10))\n",
        "\n",
        "    shuffled_user_index = np.asarray(range(num_users))\n",
        "    np.random.shuffle(shuffled_user_index)\n",
        "\n",
        "    batch_num = int(num_users / batch_size) + 1\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for b_idx in range(batch_num):\n",
        "        batch_idx = shuffled_user_index[b_idx*batch_size : (b_idx+1)*batch_size]\n",
        "        if len(batch_idx) == 0:\n",
        "            continue\n",
        "\n",
        "        x_batch = train_ratings_matrix[batch_idx]\n",
        "\n",
        "        grads = Model.gradient(x_batch, x_batch)\n",
        "        optimizers.update(Model.params, grads)\n",
        "\n",
        "        loss = Model.loss(x_batch, x_batch)\n",
        "        train_loss.append(loss)\n",
        "        epoch_loss += loss\n",
        "\n",
        "    avg_loss = epoch_loss / batch_num if batch_num > 0 else 0\n",
        "    print(\"epoch:\" + str(i+1) + \"  loss:\" + str(loss))\n",
        "\n",
        "    current_rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "    print(\"validation rmse:\", current_rmse)\n",
        "\n",
        "    if current_rmse < best_rmse:\n",
        "        print(f\"성능 good RMSE: {best_rmse:.4f} -> {current_rmse:.4f}\")\n",
        "        best_rmse = current_rmse\n",
        "        best_epoch = i\n",
        "\n",
        "        best_params = {}\n",
        "        for key, val in Model.params.items():\n",
        "            best_params[key] = val.copy()\n",
        "\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"성능 bad {counter}/{patience}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {i+1}!\")\n",
        "        print(f\"Best epoch was {best_epoch+1} with RMSE {best_rmse:.4f}\")\n",
        "        break\n",
        "\n",
        "if best_params:\n",
        "    print(f\"최고 성능 모델 복원(에폭 {best_epoch+1})\")\n",
        "    for key in Model.params:\n",
        "        Model.params[key] = best_params[key]\n",
        "\n",
        "# 3. 평가==========\n",
        "rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "print( \"============================\")\n",
        "print( \"=========== rmse ===========\")\n",
        "print(str(rmse))\n",
        "\n",
        "\n",
        "# # 4. submission만들기==========\n",
        "make_submission(Model, train_ratings_matrix, test_data)"
      ],
      "metadata": {
        "id": "3Te9mcuVBrNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ab358a-fcdc-4d6e-b24d-9e8922283e73"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1  loss:1.0909717404917734\n",
            "validation rmse: 2.6846313378974815\n",
            "성능 good RMSE: inf -> 2.6846\n",
            "epoch:2  loss:1.0251139942339604\n",
            "validation rmse: 2.3553341234570664\n",
            "성능 good RMSE: 2.6846 -> 2.3553\n",
            "epoch:3  loss:1.025515029700762\n",
            "validation rmse: 2.3180277440972374\n",
            "성능 good RMSE: 2.3553 -> 2.3180\n",
            "epoch:4  loss:0.9874023310431321\n",
            "validation rmse: 2.2991101320070793\n",
            "성능 good RMSE: 2.3180 -> 2.2991\n",
            "epoch:5  loss:0.9915306903050327\n",
            "validation rmse: 2.2676758256773453\n",
            "성능 good RMSE: 2.2991 -> 2.2677\n",
            "epoch:6  loss:1.025537606466178\n",
            "validation rmse: 2.234981878543166\n",
            "성능 good RMSE: 2.2677 -> 2.2350\n",
            "epoch:7  loss:0.9900088581258928\n",
            "validation rmse: 2.2038405564811687\n",
            "성능 good RMSE: 2.2350 -> 2.2038\n",
            "epoch:8  loss:0.9941871447801227\n",
            "validation rmse: 2.1755237621316357\n",
            "성능 good RMSE: 2.2038 -> 2.1755\n",
            "epoch:9  loss:1.0028538891764913\n",
            "validation rmse: 2.1636281431375943\n",
            "성능 good RMSE: 2.1755 -> 2.1636\n",
            "epoch:10  loss:0.9816106001923618\n",
            "validation rmse: 2.1532522960851854\n",
            "성능 good RMSE: 2.1636 -> 2.1533\n",
            "epoch:11  loss:0.9815530050994385\n",
            "validation rmse: 2.140140565643724\n",
            "성능 good RMSE: 2.1533 -> 2.1401\n",
            "epoch:12  loss:0.9931280651729276\n",
            "validation rmse: 2.138747933191458\n",
            "성능 good RMSE: 2.1401 -> 2.1387\n",
            "epoch:13  loss:0.9856406936522757\n",
            "validation rmse: 2.1308195059518247\n",
            "성능 good RMSE: 2.1387 -> 2.1308\n",
            "epoch:14  loss:0.9948794719926974\n",
            "validation rmse: 2.1226345537077465\n",
            "성능 good RMSE: 2.1308 -> 2.1226\n",
            "epoch:15  loss:0.9861998332701649\n",
            "validation rmse: 2.1228951105073834\n",
            "성능 bad 1/12\n",
            "epoch:16  loss:0.9970693812575833\n",
            "validation rmse: 2.1182188481651716\n",
            "성능 good RMSE: 2.1226 -> 2.1182\n",
            "epoch:17  loss:0.9970047237855618\n",
            "validation rmse: 2.117368529446865\n",
            "성능 good RMSE: 2.1182 -> 2.1174\n",
            "epoch:18  loss:1.009398979106237\n",
            "validation rmse: 2.1173613058466465\n",
            "성능 good RMSE: 2.1174 -> 2.1174\n",
            "epoch:19  loss:1.0081326065487572\n",
            "validation rmse: 2.11341811730034\n",
            "성능 good RMSE: 2.1174 -> 2.1134\n",
            "epoch:20  loss:1.0211686416224277\n",
            "validation rmse: 2.112594880487921\n",
            "성능 good RMSE: 2.1134 -> 2.1126\n",
            "epoch:21  loss:1.0180859050212543\n",
            "validation rmse: 2.1109805969991933\n",
            "성능 good RMSE: 2.1126 -> 2.1110\n",
            "epoch:22  loss:1.0126380251859208\n",
            "validation rmse: 2.110831813509812\n",
            "성능 good RMSE: 2.1110 -> 2.1108\n",
            "epoch:23  loss:1.0249320046155077\n",
            "validation rmse: 2.108032488883061\n",
            "성능 good RMSE: 2.1108 -> 2.1080\n",
            "epoch:24  loss:1.0215249859068163\n",
            "validation rmse: 2.108183588307812\n",
            "성능 bad 1/12\n",
            "epoch:25  loss:1.0185035333539822\n",
            "validation rmse: 2.1070850372082894\n",
            "성능 good RMSE: 2.1080 -> 2.1071\n",
            "epoch:26  loss:1.0253265488257426\n",
            "validation rmse: 2.1081569964913984\n",
            "성능 bad 1/12\n",
            "epoch:27  loss:1.006616324402476\n",
            "validation rmse: 2.1062293675195316\n",
            "성능 good RMSE: 2.1071 -> 2.1062\n",
            "epoch:28  loss:1.0281620244444925\n",
            "validation rmse: 2.1072190650497378\n",
            "성능 bad 1/12\n",
            "epoch:29  loss:1.025144228258074\n",
            "validation rmse: 2.1050456937145605\n",
            "성능 good RMSE: 2.1062 -> 2.1050\n",
            "epoch:30  loss:1.0038276871807792\n",
            "validation rmse: 2.105643938161681\n",
            "성능 bad 1/12\n",
            "최고 성능 모델 복원(에폭 29)\n",
            "============================\n",
            "=========== rmse ===========\n",
            "2.105643938161681\n",
            "   target_id    rating\n",
            "0          1  1.160315\n",
            "1          2  1.464725\n",
            "2          3  2.662843\n",
            "3          4  2.066667\n",
            "4          5  1.387409\n"
          ]
        }
      ]
    }
  ]
}