{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/deepfake_small_V3_gen_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dependency"
      ],
      "metadata": {
        "id": "An3Kh3m69Jqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.11\n",
        "!pip install opencv-contrib-python flatbuffers==23.5.26 sounddevice==0.4.6 attrs==23.1.0\n",
        "!pip install torch==2.1.0 torchvision==0.16.0\n",
        "!pip install dlib opencv-python scikit-image pillow matplotlib imageio gdown tqdm\n",
        "!pip install ninja tensorboard tensorboardX pyaml pyrallis ftfy\n",
        "!pip install face-alignment==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4vUmMoLXIo",
        "outputId": "3bb567dd-7e9b-43f2-ffda-1900815fc294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.11 in /usr/local/lib/python3.11/dist-packages (0.10.11)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe==0.10.11) (12.4.127)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mediapipe==0.10.11) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mediapipe==0.10.11) (1.3.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.11/dist-packages (23.5.26)\n",
            "Requirement already satisfied: sounddevice==0.4.6 in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.11/dist-packages (23.1.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice==0.4.6) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice==0.4.6) (2.22)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.4)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (25.5.0)\n",
            "Requirement already satisfied: pyrallis in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyrallis) (0.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (4.14.0)\n",
            "Requirement already satisfied: face-alignment==1.3.5 in /usr/local/lib/python3.11/dist-packages (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.15.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment==1.3.5) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->face-alignment==1.3.5) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.3.5) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->face-alignment==1.3.5) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "j6kl565aMbdT",
        "outputId": "2272f817-e48f-4dff-dfd0-28d076d3d2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c7763a8b64b249f081db207500e850a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/extract_frames\n",
        "!mkdir -p /content/input_videos\n",
        "!mkdir -p /content/alignmented_frame\n",
        "!mkdir -p /content/alignmented_frame_aligned\n",
        "!mkdir -p /content/alignmented_frame_croped\n",
        "!mkdir -p /content/alignmented_frame_transforms"
      ],
      "metadata": {
        "id": "UlYQQ1my-rL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#git hub & model install"
      ],
      "metadata": {
        "id": "Io1UJS2j-HYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/stylegan3-editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae5jdZJn-UUn",
        "outputId": "8e7c3e0d-9c8c-4cb8-c8b4-edd8320995d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan3-editing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "8gQABgnW-aOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -P /content/pretrained_models/\n",
        "!bzip2 -d /content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZNpi4s-HAa",
        "outputId": "94a776c3-85a7-49fe-8154-5c38fb117092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 12:40:07--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-06-20 12:40:07--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.1’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  43.6MB/s    in 1.4s    \n",
            "\n",
            "2025-06-20 12:40:09 (43.6 MB/s) - ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.1’ saved [64040097/64040097]\n",
            "\n",
            "bzip2: Output file /content/pretrained_models/shape_predictor_68_face_landmarks.dat already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm -O /content/pretrained_models/restyle_e4e_sg3.pt\n",
        "!gdown --id 13q6m-bpe3Ws9en9y45JEx2PHQirStt8N -O /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
        "!gdown --id 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn -O /content/pretrained_models/model_ir_se50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntmFmSfd-ZiO",
        "outputId": "3ba1560a-707e-4778-f6c9-bb3944362b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm\n",
            "From (redirected): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm&confirm=t&uuid=3061d757-5756-4f17-8058-681ae6ad092d\n",
            "To: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "100% 809M/809M [00:03<00:00, 244MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N\n",
            "From (redirected): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N&confirm=t&uuid=9909ac68-a1c5-4507-9fdb-b25294fc1085\n",
            "To: /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
            "100% 60.4M/60.4M [00:00<00:00, 73.1MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn\n",
            "From (redirected): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn&confirm=t&uuid=e2291894-3b73-46dc-a81d-a3748046b2e7\n",
            "To: /content/pretrained_models/model_ir_se50.pth\n",
            "100% 175M/175M [00:01<00:00, 93.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stylegan3-editing/pretrained_models\n",
        "!cp /content/pretrained_models/shape_predictor_68_face_landmarks.dat /content/stylegan3-editing/pretrained_models/"
      ],
      "metadata": {
        "id": "aCa0uxct-mxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess frames"
      ],
      "metadata": {
        "id": "PBElw7K4_zJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 단일 프로세스 프레임 추출 코드\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "video_dir = \"/content/input_videos\"  #@param {type:\"string\"}\n",
        "output_base = \"/content/extract_frames\"  #@param {type:\"string\"}\n",
        "extract_per_sec = 7  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "def extract_video_frames(video_path):\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    output_dir = os.path.join(output_base, video_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval = max(1, int(fps // extract_per_sec))\n",
        "\n",
        "    frame_idx = 0\n",
        "    frame_list = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % interval == 0:\n",
        "            frame_list.append(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # 여기서 한 번에 저장!\n",
        "    for saved_idx, frame in enumerate(frame_list):\n",
        "        frame_path = os.path.join(output_dir, f\"key_{saved_idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    return f\"{video_name}: {len(frame_list)} frames saved\"\n",
        "\n",
        "# 실행\n",
        "video_paths = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "print(f\"🎬 총 {len(video_paths)}개의 영상 처리 시작\")\n",
        "\n",
        "for video_path in tqdm(video_paths, desc=\"📦 Processing videos\"):\n",
        "    msg = extract_video_frames(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3XEaKpDfN2",
        "outputId": "fb855b92-eb67-4187-a354-dc12fc754f68",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 총 3개의 영상 처리 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📦 Processing videos: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 피치 제한 강화 + 눈뜸 50% 기준 + KeyError 해결 코드\n",
        "import cv2, os, math, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACE_MESH = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# 눈 좌표 인덱스\n",
        "LEFT_EYE_IDX = [\n",
        "    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,\n",
        "    33, 173, 157, 158, 159, 160, 161, 246, 33\n",
        "]\n",
        "RIGHT_EYE_IDX = [\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382,\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 362\n",
        "]\n",
        "\n",
        "CORE_LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "CORE_RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_EYE_VERTICAL = [159, 145]\n",
        "RIGHT_EYE_VERTICAL = [386, 374]\n",
        "POSE_IDX = [1, 152, 33, 263, 61, 291]\n",
        "\n",
        "# 파라미터 설정 - 피치 제한 강화, 눈뜸 기준 완화\n",
        "YAW_T = 25\n",
        "PITCH_T = 25  # 35에서 25로 강화 (피치 관대하게 하지 않음)\n",
        "HEAD_DOWN_BONUS = 1  # 보너스 최소화\n",
        "ENABLE_ADAPTIVE_EAR = True\n",
        "EAR_PERCENTILE_HIGH = 37 # 상위 50%를 눈뜬 상태로 판정 (기존 40%에서 완화)\n",
        "EAR_PERCENTILE_LOW = 10\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=\"double\")\n",
        "\n",
        "def get_mediapipe_landmarks(img):\n",
        "    h, w = img.shape[:2]\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = FACE_MESH.process(rgb)\n",
        "    if not res.multi_face_landmarks:\n",
        "        return None\n",
        "    lm = res.multi_face_landmarks[0]\n",
        "    coords = np.array([[p.x * w, p.y * h] for p in lm.landmark])\n",
        "    return coords\n",
        "\n",
        "def estimate_pose_mediapipe(landmarks, img_shape):\n",
        "    image_points = landmarks[POSE_IDX]\n",
        "    focal = img_shape[1]\n",
        "    center = (img_shape[1]/2, img_shape[0]/2)\n",
        "    cam = np.array([[focal, 0, center[0]], [0, focal, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "    dist = np.zeros((4,1))\n",
        "    success, rv, _ = cv2.solvePnP(model_points, image_points, cam, dist)\n",
        "    return rv if success else None\n",
        "\n",
        "def rotation_vector_to_euler(rv):\n",
        "    rmat, _ = cv2.Rodrigues(rv)\n",
        "    proj = np.hstack((rmat, np.zeros((3,1))))\n",
        "    angles = cv2.decomposeProjectionMatrix(proj)[6]\n",
        "    pitch = math.degrees(math.asin(math.sin(math.radians(angles[1][0]))))\n",
        "    yaw   = math.degrees(math.asin(math.sin(math.radians(angles[2][0]))))\n",
        "    roll  = -math.degrees(math.asin(math.sin(math.radians(angles[0][0]))))\n",
        "    return pitch, yaw, roll\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "def enhanced_eye_aspect_ratio(landmarks, is_left=True):\n",
        "    if is_left:\n",
        "        outer = landmarks[33]\n",
        "        inner = landmarks[133]\n",
        "        v1 = np.linalg.norm(landmarks[159] - landmarks[145])\n",
        "        v2 = np.linalg.norm(landmarks[158] - landmarks[153])\n",
        "        v3 = np.linalg.norm(landmarks[160] - landmarks[144])\n",
        "    else:\n",
        "        outer = landmarks[362]\n",
        "        inner = landmarks[263]\n",
        "        v1 = np.linalg.norm(landmarks[386] - landmarks[374])\n",
        "        v2 = np.linalg.norm(landmarks[385] - landmarks[373])\n",
        "        v3 = np.linalg.norm(landmarks[387] - landmarks[380])\n",
        "\n",
        "    horizontal = np.linalg.norm(outer - inner)\n",
        "    avg_vertical = (v1 + v2 + v3) / 3.0\n",
        "    return avg_vertical / horizontal\n",
        "\n",
        "def calculate_adaptive_ear_thresholds(all_ear_values):\n",
        "    \"\"\"영상별 적응형 EAR 임계값 계산 - 50% 기준 적용\"\"\"\n",
        "    if len(all_ear_values) < 5:\n",
        "        return {\n",
        "            'high_threshold': 0.23,\n",
        "            'medium_threshold': 0.18,\n",
        "            'low_threshold': 0.15,\n",
        "            'min_threshold': 0.12\n",
        "        }\n",
        "\n",
        "    ear_array = np.array(all_ear_values)\n",
        "\n",
        "    # 50% 기준으로 임계값 설정\n",
        "    high_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH)  # 상위 50%\n",
        "    medium_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.2)  # 상위 60%\n",
        "    low_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.5)  # 상위 75%\n",
        "    min_threshold = np.percentile(ear_array, EAR_PERCENTILE_LOW)  # 하위 10%\n",
        "\n",
        "    # 최소값 보장\n",
        "    high_threshold = max(high_threshold, 0.16)  # 더 관대하게\n",
        "    medium_threshold = max(medium_threshold, 0.13)\n",
        "    low_threshold = max(low_threshold, 0.10)\n",
        "    min_threshold = max(min_threshold, 0.07)\n",
        "\n",
        "    return {\n",
        "        'high_threshold': high_threshold,\n",
        "        'medium_threshold': medium_threshold,\n",
        "        'low_threshold': low_threshold,\n",
        "        'min_threshold': min_threshold,\n",
        "        'ear_stats': {\n",
        "            'mean': np.mean(ear_array),\n",
        "            'std': np.std(ear_array),\n",
        "            'min': np.min(ear_array),\n",
        "            'max': np.max(ear_array),\n",
        "            'count': len(ear_array)\n",
        "        }\n",
        "    }\n",
        "\n",
        "def is_eye_open_adaptive(landmarks, thresholds, pitch_angle=0):\n",
        "    \"\"\"적응형 EAR 기반 눈뜸 판정 - 피치 조정 최소화\"\"\"\n",
        "\n",
        "    left_eye_basic = landmarks[CORE_LEFT_EYE]\n",
        "    right_eye_basic = landmarks[CORE_RIGHT_EYE]\n",
        "\n",
        "    basic_left_ear = eye_aspect_ratio(left_eye_basic)\n",
        "    basic_right_ear = eye_aspect_ratio(right_eye_basic)\n",
        "    basic_avg_ear = (basic_left_ear + basic_right_ear) / 2.0\n",
        "\n",
        "    enhanced_left_ear = enhanced_eye_aspect_ratio(landmarks, True)\n",
        "    enhanced_right_ear = enhanced_eye_aspect_ratio(landmarks, False)\n",
        "    enhanced_avg_ear = (enhanced_left_ear + enhanced_right_ear) / 2.0\n",
        "\n",
        "    ear_difference = abs(basic_left_ear - basic_right_ear)\n",
        "\n",
        "    # 피치 조정 최소화 (관대하게 하지 않음)\n",
        "    pitch_factor = 1.0\n",
        "    if pitch_angle > 20:  # 20도 이상에서만 최소 조정\n",
        "        pitch_factor = max(0.95, 1.0 - (pitch_angle - 20) * 0.005)  # 최대 5%만 완화\n",
        "\n",
        "    # 적응형 임계값 적용\n",
        "    adj_high = thresholds['high_threshold'] * pitch_factor\n",
        "    adj_medium = thresholds['medium_threshold'] * pitch_factor\n",
        "    adj_low = thresholds['low_threshold'] * pitch_factor\n",
        "    adj_min = thresholds['min_threshold'] * pitch_factor\n",
        "\n",
        "    # 4단계 눈뜸 판정\n",
        "    level_1 = (basic_avg_ear > adj_high and\n",
        "               enhanced_avg_ear > adj_high * 0.9 and\n",
        "               basic_left_ear > adj_medium and\n",
        "               basic_right_ear > adj_medium and\n",
        "               ear_difference < 0.08)\n",
        "\n",
        "    level_2 = (basic_avg_ear > adj_medium and\n",
        "               enhanced_avg_ear > adj_medium * 0.8 and\n",
        "               basic_left_ear > adj_low and\n",
        "               basic_right_ear > adj_low and\n",
        "               ear_difference < 0.12)\n",
        "\n",
        "    level_3 = (basic_avg_ear > adj_low and\n",
        "               basic_left_ear > adj_min and\n",
        "               basic_right_ear > adj_min and\n",
        "               ear_difference < 0.15)\n",
        "\n",
        "    level_4 = (basic_avg_ear > adj_min and\n",
        "               basic_left_ear > adj_min * 0.8 and\n",
        "               basic_right_ear > adj_min * 0.8)\n",
        "\n",
        "    # 레벨별 점수 부여\n",
        "    if level_1:\n",
        "        eye_level = 4\n",
        "    elif level_2:\n",
        "        eye_level = 3\n",
        "    elif level_3:\n",
        "        eye_level = 2\n",
        "    elif level_4:\n",
        "        eye_level = 1\n",
        "    else:\n",
        "        eye_level = 0\n",
        "\n",
        "    return eye_level, {\n",
        "        'basic_ear': basic_avg_ear,\n",
        "        'enhanced_ear': enhanced_avg_ear,\n",
        "        'left_ear': basic_left_ear,\n",
        "        'right_ear': basic_right_ear,\n",
        "        'ear_diff': ear_difference,\n",
        "        'eye_level': eye_level,\n",
        "        'pitch_factor': pitch_factor,\n",
        "        'thresholds_used': {\n",
        "            'high': adj_high,\n",
        "            'medium': adj_medium,\n",
        "            'low': adj_low,\n",
        "            'min': adj_min\n",
        "        }\n",
        "    }\n",
        "\n",
        "def frontal_score_strict_pitch(c):\n",
        "    \"\"\"피치 제한 강화된 정면성 평가 함수\"\"\"\n",
        "\n",
        "    yaw_angle = abs(c['yaw'])\n",
        "    pitch_angle = c['pitch']\n",
        "\n",
        "    # 엄격한 각도 제한 (피치 관대하게 하지 않음)\n",
        "    if yaw_angle > YAW_T:  # 25도\n",
        "        return -1000\n",
        "    if abs(pitch_angle) > PITCH_T:  # ±25도 (엄격)\n",
        "        return -1000\n",
        "\n",
        "    # 기본 페널티 (피치에 더 큰 가중치)\n",
        "    yaw_penalty = yaw_angle * 0.8\n",
        "    pitch_penalty = abs(pitch_angle) * 1.2  # 피치 페널티 증가\n",
        "\n",
        "    # 고개 숙임 보너스 최소화\n",
        "    head_down_bonus = 0\n",
        "    if -15 <= pitch_angle <= -5:  # 아주 제한적인 범위에서만\n",
        "        head_down_bonus = HEAD_DOWN_BONUS * 0.5  # 보너스도 절반으로\n",
        "\n",
        "    # 눈뜸 레벨 보너스\n",
        "    eye_level = c.get('eye_level', 0)\n",
        "    eye_bonus = eye_level * 12  # 눈뜸이 더 중요\n",
        "\n",
        "    bonus = eye_bonus + (head_down_bonus if pitch_angle < 0 else 0)\n",
        "\n",
        "    return -(0.5 * yaw_penalty + 0.5 * pitch_penalty) + bonus\n",
        "\n",
        "def calculate_final_quality_score(pitch, yaw, eye_level, ear_details):\n",
        "    \"\"\"최종 품질 점수 계산 - 피치 페널티 강화\"\"\"\n",
        "\n",
        "    # 각도 점수 (피치에 더 큰 페널티)\n",
        "    yaw_score = max(0, 100 - abs(yaw) * 2.0)\n",
        "    pitch_score = max(0, 100 - abs(pitch) * 2.5)  # 피치 페널티 증가\n",
        "    angle_score = (yaw_score + pitch_score) / 2\n",
        "\n",
        "    # 눈뜸 레벨 점수 (50% 기준이므로 더 관대)\n",
        "    eye_score = eye_level * 25\n",
        "\n",
        "    # EAR 품질 점수\n",
        "    ear_quality = min(100, ear_details['basic_ear'] * 300)\n",
        "\n",
        "    # 종합 점수 (눈뜸 비중 증가)\n",
        "    total_score = (\n",
        "        angle_score * 0.3 +    # 각도 30%\n",
        "        eye_score * 0.5 +      # 눈뜸 50% (증가)\n",
        "        ear_quality * 0.2      # EAR 품질 20%\n",
        "    )\n",
        "\n",
        "    return total_score\n",
        "\n",
        "# 경로 설정\n",
        "INPUT_ROOT = \"/content/extract_frames\"\n",
        "OUTPUT_ROOT = \"/content/alignmented_frame\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "file_ext = \".jpg\"\n",
        "video_dirs = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
        "missing_videos = []\n",
        "detailed_log = []\n",
        "best_images = []\n",
        "best_names = []\n",
        "\n",
        "print(f\"📦 총 {len(video_dirs)}개 영상 처리 시작\")\n",
        "print(f\"🎯 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (50% 기준으로 완화)\")\n",
        "print(f\"📐 각도 제한: Yaw ±{YAW_T}°, Pitch ±{PITCH_T}° (피치 제한 강화)\")\n",
        "print(f\"🎁 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소화)\")\n",
        "\n",
        "for video_name in tqdm(video_dirs, desc=\"🎯 Strict pitch + 50% eye threshold\"):\n",
        "    input_dir = os.path.join(INPUT_ROOT, video_name)\n",
        "\n",
        "    # 1단계: 모든 프레임의 EAR 값 수집\n",
        "    all_ear_values = []\n",
        "    frame_data = []\n",
        "\n",
        "    for f in sorted(os.listdir(input_dir)):\n",
        "        if not f.lower().endswith(file_ext):\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(input_dir, f)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        lm = get_mediapipe_landmarks(img)\n",
        "        if lm is None:\n",
        "            continue\n",
        "\n",
        "        rv = estimate_pose_mediapipe(lm, img.shape)\n",
        "        if rv is None:\n",
        "            continue\n",
        "\n",
        "        pitch, yaw, _ = rotation_vector_to_euler(rv)\n",
        "\n",
        "        # 엄격한 각도 제한\n",
        "        if abs(yaw) > YAW_T * 1.5 or abs(pitch) > PITCH_T * 1.5:\n",
        "            continue\n",
        "\n",
        "        # EAR 계산\n",
        "        left_eye = lm[CORE_LEFT_EYE]\n",
        "        right_eye = lm[CORE_RIGHT_EYE]\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        all_ear_values.append(avg_ear)\n",
        "\n",
        "        # 프레임 데이터 저장\n",
        "        x1, y1 = lm[:,0].min(), lm[:,1].min()\n",
        "        x2, y2 = lm[:,0].max(), lm[:,1].max()\n",
        "        face_area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "        frame_data.append({\n",
        "            'img': img,\n",
        "            'filename': f,\n",
        "            'landmarks': lm,\n",
        "            'pitch': pitch,\n",
        "            'yaw': yaw,\n",
        "            'avg_ear': avg_ear,\n",
        "            'cx': cx,\n",
        "            'cy': cy,\n",
        "            'face_area': face_area\n",
        "        })\n",
        "\n",
        "    if not all_ear_values:\n",
        "        missing_videos.append(video_name)\n",
        "        detailed_log.append({\n",
        "            'video_name': video_name,\n",
        "            'total_frames': 0,\n",
        "            'selected': False,\n",
        "            'selection_level': 0,  # KeyError 방지를 위해 추가\n",
        "            'reason': 'No valid frames found'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 2단계: 적응형 임계값 계산 (50% 기준)\n",
        "    thresholds = calculate_adaptive_ear_thresholds(all_ear_values)\n",
        "\n",
        "    # 3단계: 4단계 후보 분류\n",
        "    level_4_candidates = []\n",
        "    level_3_candidates = []\n",
        "    level_2_candidates = []\n",
        "    level_1_candidates = []\n",
        "\n",
        "    for frame in frame_data:\n",
        "        # 엄격한 피치 제한 적용\n",
        "        if abs(frame['pitch']) > PITCH_T:\n",
        "            continue\n",
        "\n",
        "        eye_level, eye_details = is_eye_open_adaptive(\n",
        "            frame['landmarks'], thresholds, abs(frame['pitch'])\n",
        "        )\n",
        "\n",
        "        if eye_level == 0:\n",
        "            continue\n",
        "\n",
        "        candidate = {\n",
        "            'img': frame['img'],\n",
        "            'filename': frame['filename'],\n",
        "            'pitch': frame['pitch'],\n",
        "            'yaw': frame['yaw'],\n",
        "            'cx': frame['cx'],\n",
        "            'cy': frame['cy'],\n",
        "            'face_area': frame['face_area'],\n",
        "            'w': frame['img'].shape[1],\n",
        "            'h': frame['img'].shape[0],\n",
        "            'eye_level': eye_level,\n",
        "            'eye_details': eye_details,\n",
        "            'quality_score': calculate_final_quality_score(\n",
        "                frame['pitch'], frame['yaw'], eye_level, eye_details\n",
        "            )\n",
        "        }\n",
        "\n",
        "        if eye_level == 4:\n",
        "            level_4_candidates.append(candidate)\n",
        "        elif eye_level == 3:\n",
        "            level_3_candidates.append(candidate)\n",
        "        elif eye_level == 2:\n",
        "            level_2_candidates.append(candidate)\n",
        "        else:\n",
        "            level_1_candidates.append(candidate)\n",
        "\n",
        "    # 4단계: 최적 프레임 선택\n",
        "    best_img = None\n",
        "    best_filename = None\n",
        "    selection_reason = \"No suitable frames\"\n",
        "    selection_level = 0\n",
        "\n",
        "    if level_4_candidates:\n",
        "        best = max(level_4_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 4: Selected from {len(level_4_candidates)} highest quality candidates\"\n",
        "        selection_level = 4\n",
        "\n",
        "    elif level_3_candidates:\n",
        "        best = max(level_3_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 3: Selected from {len(level_3_candidates)} high quality candidates\"\n",
        "        selection_level = 3\n",
        "\n",
        "    elif level_2_candidates:\n",
        "        best = max(level_2_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 2: Selected from {len(level_2_candidates)} medium quality candidates\"\n",
        "        selection_level = 2\n",
        "\n",
        "    elif level_1_candidates:\n",
        "        best = max(level_1_candidates, key=lambda x: x['quality_score'])\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 1: Selected from {len(level_1_candidates)} minimum quality candidates\"\n",
        "        selection_level = 1\n",
        "\n",
        "    elif frame_data:\n",
        "        # 최후의 수단: 가장 품질 좋은 프레임 무조건 선택\n",
        "        best_frame = max(frame_data, key=lambda x: x['avg_ear'])\n",
        "        best_img = best_frame['img']\n",
        "        best_filename = best_frame['filename']\n",
        "        selection_reason = f\"Emergency: Selected best EAR frame ({best_frame['avg_ear']:.3f})\"\n",
        "        selection_level = 0\n",
        "\n",
        "    # KeyError 방지를 위한 안전한 로그 기록\n",
        "    detailed_log.append({\n",
        "        'video_name': video_name,\n",
        "        'total_frames': len(frame_data),\n",
        "        'level_4_candidates': len(level_4_candidates),\n",
        "        'level_3_candidates': len(level_3_candidates),\n",
        "        'level_2_candidates': len(level_2_candidates),\n",
        "        'level_1_candidates': len(level_1_candidates),\n",
        "        'selected': best_filename is not None,\n",
        "        'selection_level': selection_level,  # 항상 포함\n",
        "        'best_filename': best_filename,\n",
        "        'reason': selection_reason,\n",
        "        'ear_thresholds': thresholds,\n",
        "        'quality_score': best.get('quality_score', 0) if 'best' in locals() else 0\n",
        "    })\n",
        "\n",
        "    # 프레임 저장\n",
        "    if best_img is not None:\n",
        "        save_path = os.path.join(OUTPUT_ROOT, f\"{video_name}.jpg\")\n",
        "        cv2.imwrite(save_path, best_img)\n",
        "\n",
        "        if selection_level <= 1:\n",
        "            print(f\"⚠️  {video_name}: Low quality selection (Level {selection_level})\")\n",
        "    else:\n",
        "        missing_videos.append(video_name)\n",
        "\n",
        "# 결과 저장\n",
        "if missing_videos:\n",
        "    df_missing = pd.DataFrame(missing_videos, columns=[\"video_name\"])\n",
        "    df_missing.to_csv(\"no_frame_found.csv\", index=False)\n",
        "    print(f\"❗ {len(missing_videos)}개 영상에서 프레임을 찾지 못함\")\n",
        "\n",
        "df_log = pd.DataFrame(detailed_log)\n",
        "df_log.to_csv(\"strict_pitch_50percent_eye_log.csv\", index=False)\n",
        "print(f\"📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\")\n",
        "\n",
        "# KeyError 방지된 안전한 통계 출력\n",
        "success_rate = (len(video_dirs) - len(missing_videos)) / len(video_dirs) * 100 if video_dirs else 0\n",
        "\n",
        "# .get() 메서드 사용으로 KeyError 방지\n",
        "level_4_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 4)\n",
        "level_3_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 3)\n",
        "level_2_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 2)\n",
        "level_1_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 1)\n",
        "emergency_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 0)\n",
        "\n",
        "print(f\"✅ 성공률: {success_rate:.1f}% ({len(video_dirs) - len(missing_videos)}/{len(video_dirs)})\")\n",
        "print(f\"🏆 Level 4 (최고품질): {level_4_usage}개\")\n",
        "print(f\"🥈 Level 3 (고품질): {level_3_usage}개\")\n",
        "print(f\"🥉 Level 2 (중품질): {level_2_usage}개\")\n",
        "print(f\"📉 Level 1 (최소품질): {level_1_usage}개\")\n",
        "print(f\"🚨 Emergency (강제선택): {emergency_usage}개\")\n",
        "\n",
        "print(f\"\\n📈 품질 분포:\")\n",
        "print(f\"   - 고품질 이상 (Level 3+): {(level_4_usage + level_3_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 중품질 이상 (Level 2+): {(level_4_usage + level_3_usage + level_2_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 최소품질 이상 (Level 1+): {(len(video_dirs) - emergency_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\n🎯 설정 요약:\")\n",
        "print(f\"   - 피치 제한: ±{PITCH_T}° (엄격)\")\n",
        "print(f\"   - 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (관대)\")\n",
        "print(f\"   - 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlELfbUkEFea",
        "outputId": "c5a09ebb-e20a-4289-a593-e459bafeb9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 총 3개 영상 처리 시작\n",
            "🎯 눈뜸 기준: 상위 37% (50% 기준으로 완화)\n",
            "📐 각도 제한: Yaw ±25°, Pitch ±25° (피치 제한 강화)\n",
            "🎁 고개 숙임 보너스: 1점 (최소화)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🎯 Strict pitch + 50% eye threshold: 100%|██████████| 3/3 [00:04<00:00,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\n",
            "✅ 성공률: 100.0% (3/3)\n",
            "🏆 Level 4 (최고품질): 1개\n",
            "🥈 Level 3 (고품질): 0개\n",
            "🥉 Level 2 (중품질): 2개\n",
            "📉 Level 1 (최소품질): 0개\n",
            "🚨 Emergency (강제선택): 0개\n",
            "\n",
            "📈 품질 분포:\n",
            "   - 고품질 이상 (Level 3+): 33.3%\n",
            "   - 중품질 이상 (Level 2+): 100.0%\n",
            "   - 최소품질 이상 (Level 1+): 100.0%\n",
            "\n",
            "🎯 설정 요약:\n",
            "   - 피치 제한: ±25° (엄격)\n",
            "   - 눈뜸 기준: 상위 37% (관대)\n",
            "   - 고개 숙임 보너스: 1점 (최소)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "H_23qUpRqSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c98b584-3c45-4b67-93b6-a87574b5ae76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image crop"
      ],
      "metadata": {
        "id": "22A2atJxxcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan3-editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W19HlMQIxcMs",
        "outputId": "88eeaaa2-87d9-4a36-c4b0-5e383ebd40f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3-editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/stylegan3-editing')"
      ],
      "metadata": {
        "id": "UE0wMtQ79bS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "base_raw_root = \"/content/alignmented_frame\"\n",
        "aligned_root = f\"{base_raw_root}_aligned\"\n",
        "cropped_root = f\"{base_raw_root}_croped\"\n",
        "transform_root = f\"{base_raw_root}_transforms\"\n",
        "\n",
        "print(\"🚀 Aligning all images...\")\n",
        "# 실행 명령어에 PYTHONPATH를 추가하여 모듈을 찾을 경로를 알려줍니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode align \\\n",
        "    --root_path \"{base_raw_root}\"\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Cropping all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode crop \\\n",
        "    --root_path \"{base_raw_root}\" \\\n",
        "    --random_shift 0.05\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Computing transforms for all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/compute_landmarks_transforms.py \\\n",
        "    --raw_root \"{base_raw_root}\" \\\n",
        "    --aligned_root \"{aligned_root}\" \\\n",
        "    --cropped_root \"{cropped_root}\" \\\n",
        "    --output_root \"{transform_root}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kzg1k-FxgA2",
        "outputId": "933d5d2a-7ace-4104-e3f2-e0e44a6a1c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Aligning all images...\n",
            "1\n",
            "Running on 3 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #3 images\n",
            "\tDone!\n",
            "Mischief managed in -2.4075844287872314s\n",
            "🔁 Cropping all images...\n",
            "1\n",
            "Running on 3 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #3 images\n",
            "\tDone!\n",
            "Mischief managed in -2.117825984954834s\n",
            "🔁 Computing transforms for all images...\n",
            "Computing landmarks transforms...\n",
            "100% 3/3 [00:06<00:00,  2.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 설정\n",
        "input_root = \"/content/alignmented_frame_croped\"\n",
        "transforms_root = \"/content/alignmented_frame_transforms/landmarks_transforms.npy\"\n",
        "output_root = \"/content/experiments/restyle_e4e_sg3\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "\n",
        "# output 디렉토리 생성\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "print(\"🚀 Inverting video\")\n",
        "\n",
        "!python {script_path} \\\n",
        "    --output_path \"{output_root}\" \\\n",
        "    --checkpoint_path \"{ckpt_path}\" \\\n",
        "    --data_path \"{input_root}\" \\\n",
        "    --test_batch_size 4 \\\n",
        "    --test_workers 4 \\\n",
        "    --n_iters_per_batch 3 \\\n",
        "    --landmarks_transforms_path \"{transforms_root}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdozUaBz7ja",
        "outputId": "c9bc31eb-cfbe-4873-db7b-9aaac7ace668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Inverting video\n",
            "Loading ReStyle e4e from checkpoint: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "Loading StyleGAN3 generator from path: None\n",
            "Done!\n",
            "Model successfully loaded!\n",
            "Loading dataset for ffhq_encode\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "100% 1/1 [00:01<00:00,  1.72s/it]\n",
            "Runtime 1.0465+-0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save CSV"
      ],
      "metadata": {
        "id": "BAaQSZUwoGsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load latent dictionary\n",
        "latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "latent_dict = np.load(latent_path, allow_pickle=True).item()\n",
        "\n",
        "# 2. 정렬된 파일 리스트 확보\n",
        "filenames = sorted(latent_dict.keys())\n",
        "\n",
        "# 3. 각 latent에서 마지막 step → 평균 → (512,)\n",
        "latents = []\n",
        "for key in filenames:\n",
        "    latent = latent_dict[key][-1]  # 마지막 step (18, 512)\n",
        "    mean_latent = latent.mean(axis=0).astype('float32')  # (512,)\n",
        "    latents.append(mean_latent)\n",
        "\n",
        "latents = np.stack(latents)  # shape: (N, 512)\n",
        "\n",
        "# 4. cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(latents)  # shape: (N, N)\n",
        "\n",
        "# 5. 각 query 파일마다 top-3 유사한 match + score 저장\n",
        "rows = []\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    sims = sim_matrix[i].copy()\n",
        "    sims[i] = -np.inf  # 자기 자신 제외\n",
        "    top3_idx = np.argsort(sims)[::-1][:3]\n",
        "    row = {\n",
        "        \"query\": filenames[i],\n",
        "        \"top1\": filenames[top3_idx[0]],\n",
        "        \"top2\": filenames[top3_idx[1]],\n",
        "        \"top3\": filenames[top3_idx[2]],\n",
        "        \"top1val\": round(float(sims[top3_idx[0]]), 6),\n",
        "        \"top2val\": round(float(sims[top3_idx[1]]), 6),\n",
        "        \"top3val\": round(float(sims[top3_idx[2]]), 6),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 6. Save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"video_similarity_top3_compact.csv\", index=False)\n",
        "\n",
        "print(\"✅ Saved to video_similarity_top3_compact.csv\")\n"
      ],
      "metadata": {
        "id": "WjMFJ5i2oE78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229ae341-9dac-45fe-8b67-8cbd0633170a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved to video_similarity_top3_compact.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "fdUFzopMZjug",
        "outputId": "3c5d8525-0195-48e3-9056-ab3462639b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e9085cb761924200a42f4abaf57e6913"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone -q https://github.com/woctezuma/SimSwap.git SimSwap\n",
        "\n",
        "!pip install -q torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q insightface==0.7.3 onnxruntime moviepy opencv-python imageio==2.34.0\n",
        "!pip install scikit-video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCFEDIxZmkq",
        "outputId": "b812735a-663c-4d98-bca7-f72a8dc9ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m983.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 6.31.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.31.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-video) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from scikit-video) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from scikit-video) (1.15.3)\n",
            "Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SimSwap 설정 확인 및 수정\n",
        "\n",
        "import os\n",
        "\n",
        "def check_and_fix_simswap():\n",
        "    \"\"\"SimSwap 설정 확인 및 수정\"\"\"\n",
        "    print(\"🔧 SimSwap 설정 확인 중...\")\n",
        "\n",
        "    # 1. 디렉토리 확인\n",
        "    required_dirs = [\n",
        "        '/content/SimSwap',\n",
        "        '/content/arcface_model',\n",
        "        '/content/SimSwap/checkpoints',\n",
        "        '/content/SimSwap/parsing_model/checkpoint'\n",
        "    ]\n",
        "\n",
        "    for dir_path in required_dirs:\n",
        "        if os.path.exists(dir_path):\n",
        "            print(f\"✅ {dir_path} 존재\")\n",
        "        else:\n",
        "            print(f\"❌ {dir_path} 없음\")\n",
        "\n",
        "    # 2. 파일 확인\n",
        "    required_files = [\n",
        "        '/content/arcface_model/arcface_checkpoint.tar',\n",
        "        '/content/SimSwap/parsing_model/checkpoint/79999_iter.pth'\n",
        "    ]\n",
        "\n",
        "    for file_path in required_files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"✅ {file_path} 존재\")\n",
        "        else:\n",
        "            print(f\"❌ {file_path} 없음\")\n",
        "\n",
        "    # 3. checkpoints 디렉토리 내용 확인\n",
        "    checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "    if os.path.exists(checkpoints_dir):\n",
        "        files = os.listdir(checkpoints_dir)\n",
        "        print(f\"📁 checkpoints 디렉토리 내용: {files}\")\n",
        "\n",
        "        # people 폴더 확인\n",
        "        people_dir = os.path.join(checkpoints_dir, 'people')\n",
        "        if os.path.exists(people_dir):\n",
        "            people_files = os.listdir(people_dir)\n",
        "            print(f\"📁 people 폴더 내용: {people_files}\")\n",
        "        else:\n",
        "            print(\"❌ people 폴더가 없음\")\n",
        "\n",
        "    # 4. arcface 압축 해제 확인\n",
        "    arcface_tar = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "    if os.path.exists(arcface_tar):\n",
        "        print(\"🔧 arcface 압축 해제 중...\")\n",
        "        os.chdir('/content/arcface_model')\n",
        "        os.system('tar -xf arcface_checkpoint.tar')\n",
        "\n",
        "        # 압축 해제 후 파일 확인\n",
        "        extracted_files = os.listdir('/content/arcface_model')\n",
        "        print(f\"📁 압축 해제 후 arcface_model 내용: {extracted_files}\")\n",
        "\n",
        "def download_missing_models():\n",
        "    \"\"\"누락된 모델 다운로드\"\"\"\n",
        "    print(\"📥 누락된 모델 다운로드 중...\")\n",
        "\n",
        "    # 기본 디렉토리 생성\n",
        "    os.makedirs('/content/arcface_model', exist_ok=True)\n",
        "    os.makedirs('/content/SimSwap/parsing_model/checkpoint', exist_ok=True)\n",
        "    os.makedirs('/content/SimSwap/checkpoints', exist_ok=True)\n",
        "    os.makedirs('/content/insightface_func/models', exist_ok=True)\n",
        "\n",
        "    # 모델 다운로드\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/1.0/arcface_checkpoint.tar -O /content/arcface_model/arcface_checkpoint.tar')\n",
        "    os.system('wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip -O /content/checkpoints.zip')\n",
        "    os.system('wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth -O /content/SimSwap/parsing_model/checkpoint/79999_iter.pth')\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/antelope/antelope.zip -O /content/antelope.zip')\n",
        "\n",
        "    # 압축 해제\n",
        "    os.system('unzip -q /content/checkpoints.zip -d /content/SimSwap/checkpoints')\n",
        "    os.system('unzip -q /content/antelope.zip -d /content/insightface_func/models/')\n",
        "\n",
        "    print(\"✅ 모델 다운로드 완료\")\n",
        "\n",
        "def fix_simswap_compatibility():\n",
        "    \"\"\"SimSwap 호환성 수정\"\"\"\n",
        "    print(\"🔧 SimSwap 호환성 수정 중...\")\n",
        "\n",
        "    os.chdir('/content/SimSwap')\n",
        "\n",
        "    # PyTorch 호환성 수정\n",
        "    os.system(\"sed -i.bak 's/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"))/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"), weights_only=False)/' models/fs_model.py\")\n",
        "\n",
        "    # 감지 크기 수정\n",
        "    os.system(\"sed -i 's/det_size=(640,640)/det_size=(224,224)/' test_wholeimage_swapsingle.py\")\n",
        "\n",
        "    # NMS 임계값 수정\n",
        "    with open('test_wholeimage_swapsingle.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    if 'app.models[\"detection\"].nms_thresh' not in content:\n",
        "        new_lines = []\n",
        "        for line in content.splitlines():\n",
        "            new_lines.append(line)\n",
        "            if 'app.prepare(' in line:\n",
        "                new_lines.append('    if hasattr(app.models, \"detection\"):')\n",
        "                new_lines.append('        app.models[\"detection\"].nms_thresh = 0.3')\n",
        "                new_lines.append('        app.models[\"detection\"].det_thresh = 0.3')\n",
        "        with open('test_wholeimage_swapsingle.py', 'w') as f:\n",
        "            f.write('\\n'.join(new_lines))\n",
        "\n",
        "    print(\"✅ 호환성 수정 완료\")\n",
        "\n",
        "# 실행\n",
        "print(\"=== SimSwap 설정 진단 및 수정 ===\")\n",
        "check_and_fix_simswap()\n",
        "download_missing_models()\n",
        "check_and_fix_simswap()  # 다시 확인\n",
        "fix_simswap_compatibility()\n",
        "print(\"🎉 SimSwap 설정 완료!\")"
      ],
      "metadata": {
        "id": "Rd03Ysagf8gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6055c12-9254-4c84-ae25-7438368f70bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SimSwap 설정 진단 및 수정 ===\n",
            "🔧 SimSwap 설정 확인 중...\n",
            "✅ /content/SimSwap 존재\n",
            "❌ /content/arcface_model 없음\n",
            "❌ /content/SimSwap/checkpoints 없음\n",
            "❌ /content/SimSwap/parsing_model/checkpoint 없음\n",
            "❌ /content/arcface_model/arcface_checkpoint.tar 없음\n",
            "❌ /content/SimSwap/parsing_model/checkpoint/79999_iter.pth 없음\n",
            "📥 누락된 모델 다운로드 중...\n",
            "✅ 모델 다운로드 완료\n",
            "🔧 SimSwap 설정 확인 중...\n",
            "✅ /content/SimSwap 존재\n",
            "✅ /content/arcface_model 존재\n",
            "✅ /content/SimSwap/checkpoints 존재\n",
            "✅ /content/SimSwap/parsing_model/checkpoint 존재\n",
            "✅ /content/arcface_model/arcface_checkpoint.tar 존재\n",
            "✅ /content/SimSwap/parsing_model/checkpoint/79999_iter.pth 존재\n",
            "📁 checkpoints 디렉토리 내용: ['people']\n",
            "📁 people 폴더 내용: ['latest_net_G.pth', 'latest_net_D2.pth', 'latest_net_D1.pth', 'loss_log.txt', 'iter.txt', 'web', 'opt.txt']\n",
            "🔧 arcface 압축 해제 중...\n",
            "📁 압축 해제 후 arcface_model 내용: ['arcface_checkpoint.tar']\n",
            "🔧 SimSwap 호환성 수정 중...\n",
            "✅ 호환성 수정 완료\n",
            "🎉 SimSwap 설정 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# InsightFace 모델 문제 해결\n",
        "\n",
        "import os\n",
        "\n",
        "def fix_insightface_models():\n",
        "    \"\"\"InsightFace 모델 문제 해결\"\"\"\n",
        "    print(\"🔧 InsightFace 모델 문제 해결 중...\")\n",
        "\n",
        "    # 1. 현재 상황 확인\n",
        "    models_dir = '/content/SimSwap/insightface_func/models'\n",
        "    if os.path.exists(models_dir):\n",
        "        print(f\"📁 models 디렉토리 내용: {os.listdir(models_dir)}\")\n",
        "\n",
        "        antelope_dir = os.path.join(models_dir, 'antelope')\n",
        "        if os.path.exists(antelope_dir):\n",
        "            print(f\"📁 antelope 디렉토리 내용: {os.listdir(antelope_dir)}\")\n",
        "        else:\n",
        "            print(\"❌ antelope 디렉토리 없음\")\n",
        "\n",
        "    # 2. antelope 모델 재다운로드 및 올바른 위치에 설치\n",
        "    print(\"📥 antelope 모델 재설치 중...\")\n",
        "\n",
        "    antelope_dir = '/content/SimSwap/insightface_func/models/antelope'\n",
        "\n",
        "    # 기존 파일 정리\n",
        "    os.system('rm -rf /content/SimSwap/insightface_func/models/antelope')\n",
        "    os.system('rm -f /content/antelope.zip')\n",
        "\n",
        "    # 올바른 antelope 모델 다운로드\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/antelope/antelope.zip -O /content/antelope.zip')\n",
        "\n",
        "    # 압축 해제\n",
        "    os.system('unzip -q /content/antelope.zip -d /content/SimSwap/insightface_func/models/')\n",
        "\n",
        "    # 3. 다시 확인\n",
        "    if os.path.exists(antelope_dir):\n",
        "        files = os.listdir(antelope_dir)\n",
        "        print(f\"📁 설치 후 antelope 내용: {files}\")\n",
        "\n",
        "        # 필수 파일들 확인\n",
        "        required_files = ['glintr100.onnx', 'scrfd_10g_bnkps.onnx']\n",
        "        for req_file in required_files:\n",
        "            if req_file in files:\n",
        "                print(f\"✅ {req_file} 존재\")\n",
        "            else:\n",
        "                print(f\"❌ {req_file} 없음\")\n",
        "\n",
        "    print(\"✅ InsightFace 모델 재설치 완료\")\n",
        "\n",
        "def alternative_download():\n",
        "    \"\"\"대안 다운로드 방법\"\"\"\n",
        "    print(\"🔄 대안 방법으로 모델 다운로드 중...\")\n",
        "\n",
        "    # 개별 파일 다운로드\n",
        "    antelope_dir = '/content/SimSwap/insightface_func/models/antelope'\n",
        "    os.makedirs(antelope_dir, exist_ok=True)\n",
        "\n",
        "    # 필수 모델 파일들 개별 다운로드\n",
        "    models = {\n",
        "        'glintr100.onnx': 'https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip',\n",
        "        'scrfd_10g_bnkps.onnx': 'https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip'\n",
        "    }\n",
        "\n",
        "    # buffalo_l 모델 다운로드 (더 안정적)\n",
        "    print(\"📥 buffalo_l 모델 다운로드 중...\")\n",
        "    os.system('wget -q https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip -O /content/buffalo_l.zip')\n",
        "    os.system(f'unzip -q /content/buffalo_l.zip -d {antelope_dir}')\n",
        "\n",
        "    # 파일 확인\n",
        "    if os.path.exists(antelope_dir):\n",
        "        files = os.listdir(antelope_dir)\n",
        "        print(f\"📁 buffalo_l 설치 후: {files}\")\n",
        "\n",
        "# 실행\n",
        "fix_insightface_models()\n",
        "\n",
        "# 실패시 대안 방법\n",
        "if not os.path.exists('/content/SimSwap/insightface_func/models/antelope/glintr100.onnx'):\n",
        "    print(\"\\n🔄 기본 방법 실패, 대안 방법 시도...\")\n",
        "    alternative_download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKyxMFQOgeo0",
        "outputId": "58513377-4d99-44b6-86f9-f597f77909b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 InsightFace 모델 문제 해결 중...\n",
            "📥 antelope 모델 재설치 중...\n",
            "📁 설치 후 antelope 내용: ['glintr100.onnx', 'scrfd_10g_bnkps.onnx']\n",
            "✅ glintr100.onnx 존재\n",
            "✅ scrfd_10g_bnkps.onnx 존재\n",
            "✅ InsightFace 모델 재설치 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생성 및 보간"
      ],
      "metadata": {
        "id": "KrMwYq9k3ZfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1단계 프레임 추출"
      ],
      "metadata": {
        "id": "QlQtGSs23feG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"파일명에서 숫자 추출 (영상과 이미지 매칭용)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "def extract_frames_all_videos(\n",
        "    video_dir=\"/content/input_videos\",\n",
        "    output_base_dir=\"/content/simswap_results\",\n",
        "    interval=5\n",
        "):\n",
        "    # 모든 mp4 파일 검색\n",
        "    video_files = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "    print(f\"총 {len(video_files)}개 mp4 영상에서 프레임 추출 시작!\")\n",
        "\n",
        "    for video_path in video_files:\n",
        "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        number = extract_number_from_filename(video_name)\n",
        "        if number is None:\n",
        "            print(f\"  {video_path}: 숫자 미포함, 스킵\")\n",
        "            continue\n",
        "\n",
        "        # 디렉토리 구조: /content/simswap_results/pair_XXX_xxxx/extracted_frames/\n",
        "        pair_name = f\"pair_{number:03d}_{video_name}\"\n",
        "        pair_output_dir = os.path.join(output_base_dir, pair_name, \"extracted_frames\")\n",
        "        os.makedirs(pair_output_dir, exist_ok=True)\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"  {video_path}: 오픈 실패, 스킵\")\n",
        "            continue\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(f\"  {video_name}({number}): {total_frames}프레임 중 interval={interval}마다 추출\")\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "        with tqdm(total=total_frames, desc=f\"    {pair_name} 프레임 추출\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                if frame_count % interval == 0:\n",
        "                    cv2.imwrite(os.path.join(pair_output_dir, f'frame_{saved_count:04d}.jpg'), frame)\n",
        "                    saved_count += 1\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"    >> 저장: {saved_count}장 완료 ({pair_output_dir})\")\n",
        "    print(\"모든 mp4 프레임 추출 완료.\")\n",
        "\n",
        "# 실제 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    VIDEO_DIR = \"/content/input_videos\"\n",
        "    OUTPUT_DIR = \"/content/simswap_results\"\n",
        "    INTERVAL = 5\n",
        "    extract_frames_all_videos(VIDEO_DIR, OUTPUT_DIR, INTERVAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCmYO0Am3Qfr",
        "outputId": "748fa329-8977-431a-fa10-b5c95ee1b568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 3개 mp4 영상에서 프레임 추출 시작!\n",
            "  0555(555): 460프레임 중 interval=5마다 추출\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_555_0555 프레임 추출: 100%|██████████| 460/460 [00:00<00:00, 1252.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> 저장: 92장 완료 (/content/simswap_results/pair_555_0555/extracted_frames)\n",
            "  0556(556): 582프레임 중 interval=5마다 추출\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_556_0556 프레임 추출: 100%|██████████| 582/582 [00:00<00:00, 1315.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> 저장: 117장 완료 (/content/simswap_results/pair_556_0556/extracted_frames)\n",
            "  0554(554): 457프레임 중 interval=5마다 추출\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_554_0554 프레임 추출: 100%|██████████| 457/457 [00:00<00:00, 1164.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> 저장: 92장 완료 (/content/simswap_results/pair_554_0554/extracted_frames)\n",
            "모든 mp4 프레임 추출 완료.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2단계 SimSwap 얼굴 교체"
      ],
      "metadata": {
        "id": "BqHzGI2a5A67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"파일명에서 숫자 추출 (영상과 이미지 매칭용)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_video_image_pairs(frame_base_dir, image_dir):\n",
        "    \"\"\"추출된 프레임과 이미지 파일들을 번호로 매칭\"\"\"\n",
        "    # 프레임 디렉토리들 검색 (pair_XXX_xxxx 형태)\n",
        "    pair_dirs = glob(os.path.join(frame_base_dir, \"pair_*\"))\n",
        "\n",
        "    # 이미지 파일들 검색\n",
        "    image_files = glob(os.path.join(image_dir, \"*.jpg\")) + glob(os.path.join(image_dir, \"*.png\"))\n",
        "\n",
        "    # 이미지를 번호별로 딕셔너리 생성\n",
        "    image_dict = {}\n",
        "    for image_path in image_files:\n",
        "        filename = os.path.basename(image_path)\n",
        "        number = extract_number_from_filename(filename)\n",
        "        if number is not None:\n",
        "            image_dict[number] = image_path\n",
        "\n",
        "    # 매칭되는 쌍 찾기\n",
        "    pairs = []\n",
        "    for pair_dir in pair_dirs:\n",
        "        # pair_XXX_xxxx에서 번호 추출\n",
        "        pair_name = os.path.basename(pair_dir)\n",
        "        number = extract_number_from_filename(pair_name)\n",
        "\n",
        "        if number is not None and number in image_dict:\n",
        "            frame_dir = os.path.join(pair_dir, \"extracted_frames\")\n",
        "            if os.path.exists(frame_dir):\n",
        "                pairs.append({\n",
        "                    'number': number,\n",
        "                    'pair_name': pair_name,\n",
        "                    'frame_dir': frame_dir,\n",
        "                    'image_path': image_dict[number],\n",
        "                    'swap_dir': os.path.join(pair_dir, \"swapped_frames\")\n",
        "                })\n",
        "\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def run_simswap_single_frame(source_img, target_img, result_subdir):\n",
        "    \"\"\"단일 프레임에 대한 SimSwap 처리\"\"\"\n",
        "    # SimSwap 경로 설정\n",
        "    arcface_path = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "    checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "\n",
        "    # 결과 디렉토리 생성\n",
        "    os.makedirs(result_subdir, exist_ok=True)\n",
        "\n",
        "    # SimSwap 실행 명령\n",
        "    cmd = [\n",
        "        'python', 'test_wholeimage_swapsingle.py',\n",
        "        '--crop_size', '224',\n",
        "        '--use_mask',\n",
        "        '--no_simswaplogo',\n",
        "        '--name', 'people',\n",
        "        '--Arc_path', arcface_path,\n",
        "        '--pic_a_path', source_img,\n",
        "        '--pic_b_path', target_img,\n",
        "        '--pic_specific_path', target_img,\n",
        "        '--output_path', result_subdir,\n",
        "        '--checkpoints_dir', checkpoints_dir\n",
        "    ]\n",
        "\n",
        "    # 원래 디렉토리 저장\n",
        "    original_cwd = os.getcwd()\n",
        "\n",
        "    try:\n",
        "        # SimSwap 디렉토리로 이동\n",
        "        os.chdir('/content/SimSwap')\n",
        "\n",
        "        # SimSwap 실행\n",
        "        result = subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # 결과 파일 확인\n",
        "        result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "        return len(result_files) > 0\n",
        "\n",
        "    except Exception as e:\n",
        "        return False\n",
        "    finally:\n",
        "        # 원래 디렉토리로 복귀\n",
        "        os.chdir(original_cwd)\n",
        "\n",
        "\n",
        "def process_single_pair_no_progress(pair_info, max_workers=4):\n",
        "    \"\"\"단일 쌍의 모든 프레임을 진행바 없이 병렬 처리\"\"\"\n",
        "    source_img = pair_info['image_path']\n",
        "    frame_dir = pair_info['frame_dir']\n",
        "    swap_dir = pair_info['swap_dir']\n",
        "\n",
        "    # 프레임 파일들 가져오기\n",
        "    frames = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "    total_frames = len(frames)\n",
        "\n",
        "    if total_frames == 0:\n",
        "        return False, 0, total_frames\n",
        "\n",
        "    # 작업 목록 생성\n",
        "    tasks = []\n",
        "    for i, frame_name in enumerate(frames):\n",
        "        target_img = os.path.join(frame_dir, frame_name)\n",
        "        result_subdir = os.path.join(swap_dir, f'frame_{i:04d}')\n",
        "        tasks.append((source_img, target_img, result_subdir, i))\n",
        "\n",
        "    # 병렬 처리 (진행바 완전 제거)\n",
        "    success_count = 0\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # 작업 제출\n",
        "        futures = [executor.submit(run_simswap_single_frame, task[0], task[1], task[2]) for task in tasks]\n",
        "\n",
        "        # 결과 수집 (진행바 없이)\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                success = future.result()\n",
        "                if success:\n",
        "                    success_count += 1\n",
        "            except Exception:\n",
        "                pass  # 에러도 조용히 무시\n",
        "\n",
        "    return success_count > 0, success_count, total_frames\n",
        "\n",
        "\n",
        "def simswap_all_pairs_parallel(\n",
        "    frame_base_dir=\"/content/simswap_results\",\n",
        "    image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "    max_workers_per_pair=4,\n",
        "    max_concurrent_pairs=2\n",
        "):\n",
        "    \"\"\"모든 쌍에 대해 병렬 SimSwap 처리 - 전체 진행상황만 표시\"\"\"\n",
        "\n",
        "    # tqdm 전역 비활성화 (혹시 모를 다른 진행바들까지 차단)\n",
        "    import tqdm as tqdm_module\n",
        "    original_tqdm = tqdm_module.tqdm\n",
        "\n",
        "    def disabled_tqdm(*args, **kwargs):\n",
        "        kwargs['disable'] = True\n",
        "        return original_tqdm(*args, **kwargs)\n",
        "\n",
        "    tqdm_module.tqdm = disabled_tqdm\n",
        "\n",
        "    try:\n",
        "        # SimSwap 환경 확인\n",
        "        if not os.path.exists('/content/SimSwap'):\n",
        "            print(\"❌ SimSwap이 설치되지 않았습니다. 먼저 SimSwap을 설치해주세요.\")\n",
        "            return\n",
        "\n",
        "        # 매칭되는 쌍 찾기\n",
        "        pairs = get_video_image_pairs(frame_base_dir, image_dir)\n",
        "\n",
        "        if not pairs:\n",
        "            print(\"❌ 매칭되는 프레임-이미지 쌍을 찾을 수 없습니다!\")\n",
        "            return\n",
        "\n",
        "        # 초기 정보만 출력\n",
        "        print(f\"🎯 총 {len(pairs)}개 쌍 처리 시작 (쌍당 {max_workers_per_pair}워커, 동시 {max_concurrent_pairs}쌍)\")\n",
        "\n",
        "        # 전체 진행상황을 위한 변수들\n",
        "        completed_pairs = 0\n",
        "        total_pairs = len(pairs)\n",
        "        lock = threading.Lock()\n",
        "\n",
        "        # 전체 진행바 생성 (원래 tqdm 사용)\n",
        "        overall_pbar = original_tqdm(total=total_pairs, desc=\"🔄 SimSwap 처리\", unit=\"쌍\")\n",
        "\n",
        "        def process_pair_with_progress(pair):\n",
        "            \"\"\"쌍 처리 후 전체 진행바 업데이트\"\"\"\n",
        "            nonlocal completed_pairs\n",
        "\n",
        "            # 진행바 없는 함수 사용\n",
        "            success, success_frames, total_frames = process_single_pair_no_progress(pair, max_workers_per_pair)\n",
        "\n",
        "            # 스레드 안전하게 진행바 업데이트\n",
        "            with lock:\n",
        "                completed_pairs += 1\n",
        "                # 진행바 정보 업데이트\n",
        "                overall_pbar.set_postfix({\n",
        "                    '완료': f\"{completed_pairs}/{total_pairs}\",\n",
        "                    '현재': pair['pair_name'][:12],  # 이름 길이 제한\n",
        "                    '성공': f\"{success_frames}/{total_frames}\" if total_frames > 0 else \"0/0\"\n",
        "                })\n",
        "                overall_pbar.update(1)\n",
        "\n",
        "            return success, pair\n",
        "\n",
        "        start_time = time.time()\n",
        "        success_count = 0\n",
        "\n",
        "        # 쌍별로 병렬 처리\n",
        "        with ThreadPoolExecutor(max_workers=max_concurrent_pairs) as executor:\n",
        "            # 모든 쌍에 대한 작업 제출\n",
        "            futures = [executor.submit(process_pair_with_progress, pair) for pair in pairs]\n",
        "\n",
        "            # 결과 수집 (조용히)\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    success, pair = future.result()\n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                except Exception:\n",
        "                    # 에러가 발생해도 진행바는 계속 업데이트\n",
        "                    with lock:\n",
        "                        completed_pairs += 1\n",
        "                        overall_pbar.set_postfix({\n",
        "                            '완료': f\"{completed_pairs}/{total_pairs}\",\n",
        "                            '상태': '에러'\n",
        "                        })\n",
        "                        overall_pbar.update(1)\n",
        "\n",
        "        # 진행바 닫기\n",
        "        overall_pbar.close()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_duration = end_time - start_time\n",
        "\n",
        "        # 최종 결과만 출력\n",
        "        print(f\"🎊 완료! 성공: {success_count}/{len(pairs)}개, 시간: {total_duration:.1f}초\")\n",
        "\n",
        "    finally:\n",
        "        # tqdm 원래대로 복구\n",
        "        tqdm_module.tqdm = original_tqdm\n",
        "\n",
        "\n",
        "# 개별 쌍만 처리하고 싶을 때 사용하는 함수\n",
        "def simswap_single_pair_only(pair_name, max_workers=4,\n",
        "                            frame_base_dir=\"/content/simswap_results\",\n",
        "                            image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\"):\n",
        "    \"\"\"특정 쌍만 병렬로 처리\"\"\"\n",
        "    pairs = get_video_image_pairs(frame_base_dir, image_dir)\n",
        "\n",
        "    target_pair = None\n",
        "    for pair in pairs:\n",
        "        if pair['pair_name'] == pair_name:\n",
        "            target_pair = pair\n",
        "            break\n",
        "\n",
        "    if target_pair is None:\n",
        "        print(f\"❌ '{pair_name}' 쌍을 찾을 수 없습니다!\")\n",
        "        return False\n",
        "\n",
        "    success, success_frames, total_frames = process_single_pair_no_progress(target_pair, max_workers)\n",
        "\n",
        "    if success:\n",
        "        print(f\"✅ [{pair_name}] 완료: {success_frames}/{total_frames} 프레임 성공\")\n",
        "    else:\n",
        "        print(f\"❌ [{pair_name}] 실패\")\n",
        "\n",
        "    return success\n",
        "\n",
        "\n",
        "# 실제 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    FRAME_BASE_DIR = \"/content/simswap_results\"\n",
        "    IMAGE_DIR = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "\n",
        "    simswap_all_pairs_parallel(\n",
        "        frame_base_dir=FRAME_BASE_DIR,\n",
        "        image_dir=IMAGE_DIR,\n",
        "        max_workers_per_pair=4,\n",
        "        max_concurrent_pairs=2\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a3hccpeB22m",
        "outputId": "5ba69d59-d361-459b-d39c-3c73731c7123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 총 3개 쌍 처리 시작 (쌍당 4워커, 동시 2쌍)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔄 SimSwap 처리: 100%|██████████| 3/3 [07:58<00:00, 159.60s/쌍, 완료=3/3, 현재=pair_556_055, 성공=117/117]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎊 완료! 성공: 3/3개, 시간: 478.8초\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3단계 영상생성"
      ],
      "metadata": {
        "id": "kcbawQB47hNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"파일명에서 숫자 추출 (영상과 이미지 매칭용)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_swapped_pairs_info(frame_base_dir=\"/content/simswap_results\"):\n",
        "    \"\"\"SimSwap 완료된 쌍들의 정보 가져오기\"\"\"\n",
        "    pair_dirs = glob(os.path.join(frame_base_dir, \"pair_*\"))\n",
        "    pairs_info = []\n",
        "\n",
        "    for pair_dir in pair_dirs:\n",
        "        pair_name = os.path.basename(pair_dir)\n",
        "        number = extract_number_from_filename(pair_name)\n",
        "\n",
        "        if number is not None:\n",
        "            swap_dir = os.path.join(pair_dir, \"swapped_frames\")\n",
        "            if os.path.exists(swap_dir):\n",
        "                # 스왑된 프레임 개수 확인\n",
        "                swap_subdirs = [d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))]\n",
        "                pairs_info.append({\n",
        "                    'number': number,\n",
        "                    'pair_name': pair_name,\n",
        "                    'pair_dir': pair_dir,\n",
        "                    'swap_dir': swap_dir,\n",
        "                    'frame_count': len(swap_subdirs)\n",
        "                })\n",
        "\n",
        "    return sorted(pairs_info, key=lambda x: x['number'])\n",
        "\n",
        "\n",
        "def create_video_from_swapped_frames(swap_dir, output_video, target_fps):\n",
        "    \"\"\"SimSwap 결과 프레임들을 비디오로 변환\"\"\"\n",
        "    if not os.path.exists(swap_dir):\n",
        "        return False, \"swap_dir이 존재하지 않음\"\n",
        "\n",
        "    # 결과 이미지들 수집\n",
        "    result_images = []\n",
        "    swap_subdirs = sorted([d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))])\n",
        "\n",
        "    if not swap_subdirs:\n",
        "        return False, \"스왑된 프레임 디렉토리가 없음\"\n",
        "\n",
        "    for subdir in swap_subdirs:\n",
        "        subdir_path = os.path.join(swap_dir, subdir)\n",
        "        result_files = [f for f in os.listdir(subdir_path) if f.endswith(('.jpg', '.png'))]\n",
        "        if result_files:\n",
        "            # 첫 번째 결과 파일 사용\n",
        "            result_images.append(os.path.join(subdir_path, result_files[0]))\n",
        "\n",
        "    if not result_images:\n",
        "        return False, \"결과 이미지가 없음\"\n",
        "\n",
        "    # 첫 번째 이미지로 비디오 크기 결정\n",
        "    first_img = cv2.imread(result_images[0])\n",
        "    if first_img is None:\n",
        "        return False, f\"첫 번째 이미지를 읽을 수 없음: {result_images[0]}\"\n",
        "\n",
        "    height, width, _ = first_img.shape\n",
        "\n",
        "    # 비디오 라이터 설정\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, target_fps, (width, height))\n",
        "\n",
        "    if not out.isOpened():\n",
        "        return False, f\"비디오 라이터를 열 수 없음: {output_video}\"\n",
        "\n",
        "    # 프레임들을 비디오로 작성\n",
        "    success_frames = 0\n",
        "    for img_path in result_images:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            out.write(img)\n",
        "            success_frames += 1\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    if success_frames > 0:\n",
        "        return True, f\"비디오 생성 완료: {success_frames}프레임\"\n",
        "    else:\n",
        "        return False, \"프레임을 읽을 수 없음\"\n",
        "\n",
        "\n",
        "def process_single_pair_video_creation(pair_info, original_fps=30.0, frame_interval=5):\n",
        "    \"\"\"단일 쌍의 기본 비디오 생성\"\"\"\n",
        "    swap_dir = pair_info['swap_dir']\n",
        "    pair_name = pair_info['pair_name']\n",
        "    pair_dir = pair_info['pair_dir']\n",
        "\n",
        "    # 프레임 간격에 따른 FPS 계산\n",
        "    base_fps = original_fps / frame_interval\n",
        "\n",
        "    # 기본 비디오 생성\n",
        "    base_video_path = os.path.join(pair_dir, f\"{pair_name}_base.mp4\")\n",
        "    success, message = create_video_from_swapped_frames(swap_dir, base_video_path, base_fps)\n",
        "\n",
        "    if success:\n",
        "        return True, f\"기본 비디오: {base_video_path}\"\n",
        "    else:\n",
        "        return False, f\"비디오 생성 실패: {message}\"\n",
        "\n",
        "\n",
        "def create_videos_all_pairs_parallel(\n",
        "    frame_base_dir=\"/content/simswap_results\",\n",
        "    original_fps=30.0,\n",
        "    frame_interval=5,\n",
        "    max_workers=3\n",
        "):\n",
        "    \"\"\"모든 쌍에 대해 병렬로 기본 비디오 생성\"\"\"\n",
        "\n",
        "    # 완료된 쌍들 찾기\n",
        "    pairs = get_swapped_pairs_info(frame_base_dir)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"❌ SimSwap이 완료된 쌍을 찾을 수 없습니다!\")\n",
        "        print(f\"디렉토리 확인: {frame_base_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"🎬 총 {len(pairs)}개 쌍의 기본 비디오 생성 시작!\")\n",
        "    print(f\"⚙️ 설정: 원본 FPS={original_fps}, 프레임 간격={frame_interval}, 워커={max_workers}개\")\n",
        "\n",
        "    # 전체 진행상황을 위한 변수들\n",
        "    completed_pairs = 0\n",
        "    total_pairs = len(pairs)\n",
        "    lock = threading.Lock()\n",
        "\n",
        "    # 전체 진행바 생성\n",
        "    overall_pbar = tqdm(total=total_pairs, desc=\"🎥 비디오 생성\", unit=\"쌍\")\n",
        "\n",
        "    def process_pair_with_progress(pair):\n",
        "        \"\"\"쌍 처리 후 전체 진행바 업데이트\"\"\"\n",
        "        nonlocal completed_pairs\n",
        "\n",
        "        success, message = process_single_pair_video_creation(pair, original_fps, frame_interval)\n",
        "\n",
        "        # 스레드 안전하게 진행바 업데이트\n",
        "        with lock:\n",
        "            completed_pairs += 1\n",
        "            overall_pbar.set_postfix({\n",
        "                '완료': f\"{completed_pairs}/{total_pairs}\",\n",
        "                '현재': pair['pair_name'][:12],\n",
        "                '프레임': f\"{pair['frame_count']}개\"\n",
        "            })\n",
        "            overall_pbar.update(1)\n",
        "\n",
        "        return success, pair, message\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    # 병렬 처리\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # 모든 쌍에 대한 작업 제출\n",
        "        futures = [executor.submit(process_pair_with_progress, pair) for pair in pairs]\n",
        "\n",
        "        # 결과 수집\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                success, pair, message = future.result()\n",
        "                if success:\n",
        "                    success_count += 1\n",
        "            except Exception as e:\n",
        "                # 에러가 발생해도 진행바는 계속 업데이트\n",
        "                with lock:\n",
        "                    completed_pairs += 1\n",
        "                    overall_pbar.set_postfix({\n",
        "                        '완료': f\"{completed_pairs}/{total_pairs}\",\n",
        "                        '상태': '에러'\n",
        "                    })\n",
        "                    overall_pbar.update(1)\n",
        "\n",
        "    # 진행바 닫기\n",
        "    overall_pbar.close()\n",
        "\n",
        "    print(f\"\\n🎊 기본 비디오 생성 완료!\")\n",
        "    print(f\"📊 성공: {success_count}/{len(pairs)}개\")\n",
        "    print(f\"📁 결과 위치: {frame_base_dir}\")\n",
        "    print(f\"💡 다음 단계: 프레임 보간을 원한다면 별도 스크립트를 실행하세요\")\n",
        "\n",
        "\n",
        "# 개별 쌍만 처리하고 싶을 때 사용하는 함수\n",
        "def create_single_pair_video_only(pair_name, original_fps=30.0, frame_interval=5,\n",
        "                                 frame_base_dir=\"/content/simswap_results\"):\n",
        "    \"\"\"특정 쌍만 기본 비디오 생성\"\"\"\n",
        "    pairs = get_swapped_pairs_info(frame_base_dir)\n",
        "\n",
        "    target_pair = None\n",
        "    for pair in pairs:\n",
        "        if pair['pair_name'] == pair_name:\n",
        "            target_pair = pair\n",
        "            break\n",
        "\n",
        "    if target_pair is None:\n",
        "        print(f\"❌ '{pair_name}' 쌍을 찾을 수 없습니다!\")\n",
        "        return False\n",
        "\n",
        "    print(f\"🎬 [{pair_name}] 기본 비디오 생성 시작...\")\n",
        "    success, message = process_single_pair_video_creation(target_pair, original_fps, frame_interval)\n",
        "\n",
        "    if success:\n",
        "        print(f\"✅ [{pair_name}] {message}\")\n",
        "    else:\n",
        "        print(f\"❌ [{pair_name}] {message}\")\n",
        "\n",
        "    return success\n",
        "\n",
        "\n",
        "# 실제 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    FRAME_BASE_DIR = \"/content/simswap_results\"  # SimSwap 결과가 있는 디렉토리\n",
        "    ORIGINAL_FPS = 30.0  # 원본 비디오의 FPS\n",
        "    FRAME_INTERVAL = 5   # 프레임 추출 시 사용한 간격\n",
        "    MAX_WORKERS = 3      # 병렬 처리 워커 수\n",
        "\n",
        "    print(\"=== SimSwap 3단계: 기본 비디오 생성 시작 ===\")\n",
        "    print(f\"결과 디렉토리: {FRAME_BASE_DIR}\")\n",
        "    print(f\"원본 FPS: {ORIGINAL_FPS}\")\n",
        "    print(f\"프레임 간격: {FRAME_INTERVAL}\")\n",
        "\n",
        "    # 모든 쌍의 기본 비디오 생성\n",
        "    create_videos_all_pairs_parallel(\n",
        "        frame_base_dir=FRAME_BASE_DIR,\n",
        "        original_fps=ORIGINAL_FPS,\n",
        "        frame_interval=FRAME_INTERVAL,\n",
        "        max_workers=MAX_WORKERS\n",
        "    )\n",
        "\n",
        "    # 특정 쌍만 처리하고 싶다면:\n",
        "    # create_single_pair_video_only(\"pair_001_video1\", original_fps=30.0, frame_interval=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kBtx7_B7usw",
        "outputId": "8372f49e-7859-4eb3-bc21-cbc4b5014ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SimSwap 3단계: 기본 비디오 생성 시작 ===\n",
            "결과 디렉토리: /content/simswap_results\n",
            "원본 FPS: 30.0\n",
            "프레임 간격: 5\n",
            "🎬 총 3개 쌍의 기본 비디오 생성 시작!\n",
            "⚙️ 설정: 원본 FPS=30.0, 프레임 간격=5, 워커=3개\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🎥 비디오 생성: 100%|██████████| 3/3 [00:00<00:00,  5.61쌍/s, 완료=3/3, 현재=pair_556_055, 프레임=117개]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎊 기본 비디오 생성 완료!\n",
            "📊 성공: 3/3개\n",
            "📁 결과 위치: /content/simswap_results\n",
            "💡 다음 단계: 프레임 보간을 원한다면 별도 스크립트를 실행하세요\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/hzwer/Practical-RIFE.git\n",
        "%cd Practical-RIFE\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -q gdown opencv-python numpy tqdm\n",
        "\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS/view\" -O RIFE_trained_model_HDv3.zip\n",
        "!unzip -q RIFE_trained_model_HDv3.zip\n",
        "!mv RIFEv4.21/train_log ./\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxHCP9w7aVzs",
        "outputId": "c25bcac0-2941-4931-bc2d-dbf9189e2430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Practical-RIFE' already exists and is not an empty directory.\n",
            "/content/Practical-RIFE\n",
            "Requirement already satisfied: numpy<=1.23.5,>=1.16 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: sk-video>=1.1.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.1.10)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.15.2+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sk-video>=1.1.10->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (15.0.7)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.34.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.7.0->-r requirements.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS\n",
            "From (redirected): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS&confirm=t&uuid=7e83813f-d126-4471-8a50-cf4ccc028ca6\n",
            "To: /content/Practical-RIFE/RIFE_trained_model_HDv3.zip\n",
            "100% 38.1M/38.1M [00:00<00:00, 142MB/s]\n",
            "replace __MACOSX/._RIFEv4.21? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "mv: cannot move 'RIFEv4.21/train_log' to './train_log': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4단계 보간\n"
      ],
      "metadata": {
        "id": "MSzZjJ9YHUMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "import cv2\n",
        "\n",
        "RIFE_DIR = \"/content/Practical-RIFE\"\n",
        "SIMSWAP_RESULT_DIR = \"/content/simswap_results\"\n",
        "TARGET_FPS = 30\n",
        "CUDA_DEVICE = \"0\"\n",
        "\n",
        "def interpolate_video_rife(input_path, output_path, fps=30):\n",
        "    cmd = [\n",
        "        \"python\", \"inference_video.py\",\n",
        "        \"--video\", input_path,\n",
        "        \"--output\", output_path,\n",
        "        \"--fps\", str(fps),\n",
        "    ]\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = CUDA_DEVICE\n",
        "    result = subprocess.run(cmd, cwd=RIFE_DIR, capture_output=True, text=True)\n",
        "    return result.returncode == 0, result.stdout.strip(), result.stderr.strip()\n",
        "\n",
        "def match_video_duration(original_path, input_path, output_path):\n",
        "    \"\"\"원본 영상 길이에 맞춰 RIFE 보간 영상의 속도 조정\"\"\"\n",
        "    original_cap = cv2.VideoCapture(original_path)\n",
        "    input_cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    original_duration = original_cap.get(cv2.CAP_PROP_FRAME_COUNT) / original_cap.get(cv2.CAP_PROP_FPS)\n",
        "    input_duration = input_cap.get(cv2.CAP_PROP_FRAME_COUNT) / input_cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    original_cap.release()\n",
        "    input_cap.release()\n",
        "\n",
        "    if input_duration == 0:\n",
        "        print(f\"⚠️ {input_path} 길이 계산 실패\")\n",
        "        return False\n",
        "\n",
        "    # ❗ 중요: 원래 길이에 맞춰 느리게 재생\n",
        "    speed_ratio = original_duration / input_duration\n",
        "\n",
        "    # ffmpeg로 재생 시간 맞추기\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-i\", input_path,\n",
        "        \"-filter:v\", f\"setpts={speed_ratio}*PTS\",\n",
        "        \"-an\",\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "    return os.path.exists(output_path)\n",
        "\n",
        "# base.mp4 파일 목록\n",
        "base_videos = sorted(glob(os.path.join(SIMSWAP_RESULT_DIR, \"pair_*\", \"*_base.mp4\")))\n",
        "\n",
        "if not base_videos:\n",
        "    print(\"❌ base.mp4 파일이 없습니다.\")\n",
        "else:\n",
        "    print(f\"🎬 총 {len(base_videos)}개 base.mp4에 대해 RIFE 보간 시작\")\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    for base_video in tqdm(base_videos, desc=\"🌀 RIFE 보간 중\", unit=\"쌍\"):\n",
        "        pair_dir = os.path.dirname(base_video)\n",
        "        pair_name = os.path.basename(base_video).replace(\"_base.mp4\", \"\")\n",
        "        rife_raw = os.path.join(pair_dir, f\"{pair_name}_rife_raw.mp4\")\n",
        "        rife_final = os.path.join(pair_dir, f\"{pair_name}_rife.mp4\")\n",
        "\n",
        "        if os.path.exists(rife_final):\n",
        "            print(f\"✅ {pair_name}: 이미 보간됨, 건너뜀\")\n",
        "            success_count += 1\n",
        "            continue\n",
        "\n",
        "        ok, out, err = interpolate_video_rife(base_video, rife_raw, TARGET_FPS)\n",
        "\n",
        "        if ok and os.path.exists(rife_raw):\n",
        "            # 재생 시간 맞춰 속도 조정\n",
        "            if match_video_duration(base_video, rife_raw, rife_final):\n",
        "                os.remove(rife_raw)\n",
        "                print(f\"✅ {pair_name}: 보간 + 시간조정 완료\")\n",
        "                success_count += 1\n",
        "            else:\n",
        "                print(f\"❌ {pair_name}: 시간 조정 실패\")\n",
        "        else:\n",
        "            print(f\"❌ {pair_name}: 보간 실패\\n{err}\")\n",
        "\n",
        "    print(f\"\\n🎉 완료: {success_count}/{len(base_videos)}개 보간 성공\")"
      ],
      "metadata": {
        "id": "E3y94iLJHXJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e95a1d2-15ac-4d9b-e044-f9089cc664fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 총 3개 base.mp4에 대해 RIFE 보간 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🌀 RIFE 보간 중:  33%|███▎      | 1/3 [00:06<00:13,  6.90s/쌍]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ pair_554_0554: 보간 + 시간조정 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r🌀 RIFE 보간 중:  67%|██████▋   | 2/3 [00:13<00:06,  6.76s/쌍]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ pair_555_0555: 보간 + 시간조정 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🌀 RIFE 보간 중: 100%|██████████| 3/3 [00:20<00:00,  6.98s/쌍]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ pair_556_0556: 보간 + 시간조정 완료\n",
            "\n",
            "🎉 완료: 3/3개 보간 성공\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 요건 기존 파이프 라인"
      ],
      "metadata": {
        "id": "6MV6dYClHXbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import subprocess\n",
        "import os\n",
        "from glob import glob\n",
        "import sys\n",
        "import warnings\n",
        "import re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 로그 정리\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "class SimSwapAutoPipeline:\n",
        "    def __init__(self):\n",
        "        self.setup_simswap()\n",
        "\n",
        "    def setup_simswap(self):\n",
        "        \"\"\"SimSwap 환경 설정\"\"\"\n",
        "        print(\"🔧 SimSwap 환경 설정 중...\")\n",
        "\n",
        "        # SimSwap 디렉토리로 이동\n",
        "        if not os.path.exists('/content/SimSwap'):\n",
        "            print(\"❌ SimSwap이 설치되지 않았습니다. 먼저 SimSwap을 설치해주세요.\")\n",
        "            return False\n",
        "\n",
        "        os.chdir('/content/SimSwap')\n",
        "\n",
        "        # 필요한 경로들\n",
        "        self.arcface_path = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "        self.checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "\n",
        "        print(\"✅ SimSwap 환경 설정 완료\")\n",
        "        return True\n",
        "\n",
        "    def extract_number_from_filename(self, filename):\n",
        "        \"\"\"파일명에서 숫자 추출 (영상과 이미지 매칭용)\"\"\"\n",
        "        numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "        if numbers:\n",
        "            return int(numbers[0])\n",
        "        return None\n",
        "\n",
        "    def get_video_image_pairs(self, video_dir, image_dir):\n",
        "        \"\"\"영상과 이미지 파일들을 번호로 매칭\"\"\"\n",
        "        video_files = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "        image_files = glob(os.path.join(image_dir, \"*.jpg\")) + glob(os.path.join(image_dir, \"*.png\"))\n",
        "\n",
        "        # 파일명에서 번호 추출하여 딕셔너리 생성\n",
        "        video_dict = {}\n",
        "        for video_path in video_files:\n",
        "            filename = os.path.basename(video_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                video_dict[number] = video_path\n",
        "\n",
        "        image_dict = {}\n",
        "        for image_path in image_files:\n",
        "            filename = os.path.basename(image_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                image_dict[number] = image_path\n",
        "\n",
        "        # 매칭되는 쌍 찾기\n",
        "        pairs = []\n",
        "        for number in sorted(set(video_dict.keys()) & set(image_dict.keys())):\n",
        "            pairs.append({\n",
        "                'number': number,\n",
        "                'video_path': video_dict[number],\n",
        "                'image_path': image_dict[number],\n",
        "                'video_name': os.path.splitext(os.path.basename(video_dict[number]))[0],\n",
        "                'image_name': os.path.splitext(os.path.basename(image_dict[number]))[0]\n",
        "            })\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def extract_frames(self, video_path, frame_dir, interval=5):\n",
        "        \"\"\"비디오에서 프레임 추출\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            return None, None\n",
        "\n",
        "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        new_fps = original_fps / interval\n",
        "\n",
        "        os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"  프레임 추출\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                if frame_count % interval == 0:\n",
        "                    cv2.imwrite(os.path.join(frame_dir, f'frame_{saved_count:04d}.jpg'), frame)\n",
        "                    saved_count += 1\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        return original_fps, new_fps\n",
        "\n",
        "\n",
        "    def run_simswap_on_frames(self, source_img, frame_dir, swap_dir):\n",
        "        \"\"\"SimSwap으로 프레임들 처리 - 에러 체크 추가\"\"\"\n",
        "        frames = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "        total_frames = len(frames)\n",
        "\n",
        "        os.makedirs(swap_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"     소스 이미지: {source_img}\")\n",
        "        print(f\"     소스 이미지 존재: {os.path.exists(source_img)}\")\n",
        "\n",
        "        success_count = 0\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"  SimSwap 처리\") as pbar:\n",
        "            for i, frame_name in enumerate(frames):\n",
        "                target_img = os.path.join(frame_dir, frame_name)\n",
        "                result_subdir = os.path.join(swap_dir, f'frame_{i:04d}')\n",
        "                os.makedirs(result_subdir, exist_ok=True)\n",
        "\n",
        "                # SimSwap 실행 (에러 체크 포함)\n",
        "                cmd = [\n",
        "                    'python', 'test_wholeimage_swapsingle.py',\n",
        "                    '--crop_size', '224',\n",
        "                    '--use_mask',\n",
        "                    '--no_simswaplogo',\n",
        "                    '--name', 'people',\n",
        "                    '--Arc_path', self.arcface_path,\n",
        "                    '--pic_a_path', source_img,\n",
        "                    '--pic_b_path', target_img,\n",
        "                    '--pic_specific_path', target_img,\n",
        "                    '--output_path', result_subdir,\n",
        "                    '--checkpoints_dir', self.checkpoints_dir\n",
        "                ]\n",
        "\n",
        "                # 첫 번째 프레임은 에러 체크\n",
        "                if i == 0:\n",
        "                    print(f\"     첫 번째 프레임 테스트 중...\")\n",
        "                    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "                    if result.returncode != 0:\n",
        "                        print(f\"     ❌ SimSwap 에러:\")\n",
        "                        print(f\"     stderr: {result.stderr[:500]}\")\n",
        "                        print(f\"     stdout: {result.stdout[:500]}\")\n",
        "                    else:\n",
        "                        print(f\"     ✅ 첫 번째 프레임 성공\")\n",
        "\n",
        "                    # 결과 파일 확인\n",
        "                    result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "                    print(f\"     생성된 파일: {result_files}\")\n",
        "\n",
        "                    if result_files:\n",
        "                        success_count += 1\n",
        "\n",
        "                    # 나머지는 조용히 처리\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                # 나머지 프레임들\n",
        "                subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "                # 결과 파일 확인\n",
        "                result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "                if result_files:\n",
        "                    success_count += 1\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        print(f\"     성공한 프레임: {success_count}/{total_frames}\")\n",
        "        return success_count > 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_video_from_swapped_results(self, swap_dir, output_video, target_fps):\n",
        "        \"\"\"SimSwap 결과를 비디오로 변환\"\"\"\n",
        "        print(f\"     swap_dir 확인: {swap_dir}\")\n",
        "\n",
        "        if not os.path.exists(swap_dir):\n",
        "            print(f\"     ❌ swap_dir이 존재하지 않음: {swap_dir}\")\n",
        "            return False\n",
        "\n",
        "        result_images = []\n",
        "        swap_subdirs = sorted([d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))])\n",
        "        print(f\"     발견된 하위 디렉토리: {len(swap_subdirs)}개\")\n",
        "\n",
        "        for subdir in swap_subdirs:\n",
        "            subdir_path = os.path.join(swap_dir, subdir)\n",
        "            result_files = [f for f in os.listdir(subdir_path) if f.endswith(('.jpg', '.png'))]\n",
        "            print(f\"     {subdir}: {len(result_files)}개 파일\")\n",
        "            if result_files:\n",
        "                result_images.append(os.path.join(subdir_path, result_files[0]))\n",
        "\n",
        "        print(f\"     총 수집된 이미지: {len(result_images)}개\")\n",
        "\n",
        "        if not result_images:\n",
        "            print(\"     ❌ 결과 이미지가 없음\")\n",
        "            return False\n",
        "\n",
        "        first_img = cv2.imread(result_images[0])\n",
        "        if first_img is None:\n",
        "            print(f\"     ❌ 첫 번째 이미지를 읽을 수 없음: {result_images[0]}\")\n",
        "            return False\n",
        "\n",
        "        height, width, _ = first_img.shape\n",
        "        print(f\"     비디오 크기: {width}x{height}, FPS: {target_fps}\")\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video, fourcc, target_fps, (width, height))\n",
        "\n",
        "        if not out.isOpened():\n",
        "            print(f\"     ❌ 비디오 라이터를 열 수 없음: {output_video}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"     비디오 생성 시작...\")\n",
        "        with tqdm(total=len(result_images), desc=\"  비디오 생성\") as pbar:\n",
        "            for img_path in result_images:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    out.write(img)\n",
        "                else:\n",
        "                    print(f\"     ⚠️ 이미지 읽기 실패: {img_path}\")\n",
        "                pbar.update(1)\n",
        "\n",
        "        out.release()\n",
        "        print(f\"     ✅ 비디오 생성 완료: {output_video}\")\n",
        "        return True\n",
        "\n",
        "    def interpolate_video(self, input_video, output_video, target_fps):\n",
        "        \"\"\"FFmpeg를 사용한 프레임 보간\"\"\"\n",
        "        print(f\"  보간 시작: {target_fps:.1f}FPS로 변환 중...\")\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci:mc_mode=aobmc:vsbmc=1',\n",
        "            '-c:v', 'libx264', '-crf', '23', '-preset', 'medium',\n",
        "            '-y', output_video\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                print(f\"  ✅ 보간 완료: {output_video}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"  ❌ 보간 실패\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ 보간 중 오류: {e}\")\n",
        "            return False\n",
        "\n",
        "    def process_single_pair(self, video_path, source_image_path, output_dir, frame_interval=5):\n",
        "        \"\"\"단일 영상-이미지 쌍 처리\"\"\"\n",
        "        # 디렉토리 설정\n",
        "        frame_dir = os.path.join(output_dir, \"extracted_frames\")\n",
        "        swap_dir = os.path.join(output_dir, \"swapped_frames\")\n",
        "\n",
        "        # 1. 프레임 추출\n",
        "        print(\"  1. 프레임 추출 중...\")\n",
        "        original_fps, new_fps = self.extract_frames(video_path, frame_dir, frame_interval)\n",
        "        if original_fps is None:\n",
        "            return False\n",
        "\n",
        "        print(f\"     원본 FPS: {original_fps:.1f} → 새 FPS: {new_fps:.1f}\")\n",
        "\n",
        "        # 2. SimSwap 처리\n",
        "        print(\"  2. SimSwap 얼굴 교체 중...\")\n",
        "        self.run_simswap_on_frames(source_image_path, frame_dir, swap_dir)\n",
        "\n",
        "        # 3. 기본 비디오 생성\n",
        "        print(\"  3. 기본 비디오 생성 중...\")\n",
        "        base_video_path = os.path.join(output_dir, \"base_video.mp4\")\n",
        "        if not self.create_video_from_swapped_results(swap_dir, base_video_path, new_fps):\n",
        "            return False\n",
        "\n",
        "        return True, original_fps, new_fps, base_video_path\n",
        "\n",
        "    def process_all_pairs(self, video_dir=\"/content/input_videos\",\n",
        "                         image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "                         output_base_dir=\"/content/simswap_results\",\n",
        "                         frame_interval=5, use_interpolation=True):\n",
        "        \"\"\"모든 영상-이미지 쌍 자동 처리\"\"\"\n",
        "\n",
        "        # 매칭되는 쌍 찾기\n",
        "        pairs = self.get_video_image_pairs(video_dir, image_dir)\n",
        "\n",
        "        if not pairs:\n",
        "            print(\"❌ 매칭되는 영상-이미지 쌍을 찾을 수 없습니다!\")\n",
        "            print(f\"영상 디렉토리: {video_dir}\")\n",
        "            print(f\"이미지 디렉토리: {image_dir}\")\n",
        "            return\n",
        "\n",
        "        print(f\"🎯 총 {len(pairs)}개의 매칭 쌍을 찾았습니다!\")\n",
        "\n",
        "        # 기본 출력 디렉토리 생성\n",
        "        os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "        success_count = 0\n",
        "\n",
        "        for i, pair in enumerate(pairs, 1):\n",
        "            print(f\"\\n[{i}/{len(pairs)}] 처리 중...\")\n",
        "            print(f\"  영상: {os.path.basename(pair['video_path'])}\")\n",
        "            print(f\"  이미지: {os.path.basename(pair['image_path'])}\")\n",
        "\n",
        "            # 개별 출력 디렉토리 생성\n",
        "            pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "            pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "\n",
        "            try:\n",
        "                # 1. SimSwap 처리\n",
        "                result = self.process_single_pair(\n",
        "                    pair['video_path'],\n",
        "                    pair['image_path'],\n",
        "                    pair_output_dir,\n",
        "                    frame_interval\n",
        "                )\n",
        "\n",
        "                if not result:\n",
        "                    print(f\"  ❌ 쌍 {pair['number']} 처리 실패\")\n",
        "                    continue\n",
        "\n",
        "                success, original_fps, base_fps, base_video_path = result\n",
        "\n",
        "                # 2. 보간된 비디오 생성 (선택사항)\n",
        "                if use_interpolation:\n",
        "                    final_video_path = os.path.join(pair_output_dir, f\"{pair_name}_final.mp4\")\n",
        "                    print(\"  4. 프레임 보간 중...\")\n",
        "                    if self.interpolate_video(base_video_path, final_video_path, original_fps):\n",
        "                        print(f\"  🎉 최종 결과: {final_video_path}\")\n",
        "                    else:\n",
        "                        print(f\"  ⚠️ 보간 실패, 기본 비디오 사용: {base_video_path}\")\n",
        "                else:\n",
        "                    print(f\"  🎉 최종 결과: {base_video_path}\")\n",
        "\n",
        "                success_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ❌ 쌍 {pair['number']} 처리 중 오류: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\n🎉 처리 완료! {success_count}/{len(pairs)}개 성공\")\n",
        "        print(f\"결과 저장 위치: {output_base_dir}\")\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_single_pair_wrapper(args):\n",
        "    pipeline, video_path, image_path, output_dir, frame_interval = args\n",
        "    return pipeline.process_single_pair(video_path, image_path, output_dir, frame_interval)\n",
        "\n",
        "def process_all_pairs_parallel(pipeline, pairs, output_base_dir, frame_interval=5, use_interpolation=True, max_workers=3):\n",
        "    tasks = []\n",
        "    for pair in pairs:\n",
        "        pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "        pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "        tasks.append((pipeline, pair['video_path'], pair['image_path'], pair_output_dir, frame_interval))\n",
        "    with Pool(processes=max_workers) as pool:\n",
        "        pool.map(process_single_pair_wrapper, tasks)\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    # 파이프라인 초기화\n",
        "    pipeline = SimSwapAutoPipeline()\n",
        "\n",
        "    # 설정\n",
        "    VIDEO_DIR = \"/content/input_videos\"\n",
        "    IMAGE_DIR = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "    OUTPUT_DIR = \"/content/simswap_results\"\n",
        "    FRAME_INTERVAL = 5  # 5프레임마다 샘플링\n",
        "    USE_INTERPOLATION = True  # 프레임 보간 사용 여부\n",
        "\n",
        "    print(\"=== SimSwap 자동 파이프라인 시작 ===\")\n",
        "    print(f\"영상 디렉토리: {VIDEO_DIR}\")\n",
        "    print(f\"이미지 디렉토리: {IMAGE_DIR}\")\n",
        "    print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
        "    print(f\"프레임 간격: {FRAME_INTERVAL}\")\n",
        "    print(f\"보간 사용: {'예' if USE_INTERPOLATION else '아니오'}\")\n",
        "\n",
        "    pairs = pipeline.get_video_image_pairs(VIDEO_DIR, IMAGE_DIR)\n",
        "\n",
        "  process_all_pairs_parallel(\n",
        "      pipeline, pairs,\n",
        "      output_base_dir=OUTPUT_DIR,\n",
        "      frame_interval=FRAME_INTERVAL,\n",
        "      use_interpolation=USE_INTERPOLATION,\n",
        "      max_workers=3  # 병렬 갯수 (T4 2장 쓰면 2~3, P100은 1~2 권장)\n",
        "  )"
      ],
      "metadata": {
        "id": "zcJJ4Dt_ZnQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/simswap_results/*"
      ],
      "metadata": {
        "id": "1wW_lfuKyt5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list\n"
      ],
      "metadata": {
        "id": "TKYtA2bxQk_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}