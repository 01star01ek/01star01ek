{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/deepfake_small_V3_gen_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dependency"
      ],
      "metadata": {
        "id": "An3Kh3m69Jqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.11\n",
        "!pip install opencv-contrib-python flatbuffers==23.5.26 sounddevice==0.4.6 attrs==23.1.0\n",
        "!pip install torch==2.1.0 torchvision==0.16.0\n",
        "!pip install dlib opencv-python scikit-image pillow matplotlib imageio gdown tqdm\n",
        "!pip install ninja tensorboard tensorboardX pyaml pyrallis ftfy\n",
        "!pip install face-alignment==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah4vUmMoLXIo",
        "outputId": "3bb567dd-7e9b-43f2-ffda-1900815fc294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.11 in /usr/local/lib/python3.11/dist-packages (0.10.11)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mediapipe==0.10.11) (12.4.127)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mediapipe==0.10.11) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->mediapipe==0.10.11) (1.3.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: flatbuffers==23.5.26 in /usr/local/lib/python3.11/dist-packages (23.5.26)\n",
            "Requirement already satisfied: sounddevice==0.4.6 in /usr/local/lib/python3.11/dist-packages (0.4.6)\n",
            "Requirement already satisfied: attrs==23.1.0 in /usr/local/lib/python3.11/dist-packages (23.1.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice==0.4.6) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice==0.4.6) (2.22)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.4)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.11/dist-packages (25.5.0)\n",
            "Requirement already satisfied: pyrallis in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyrallis) (0.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (4.14.0)\n",
            "Requirement already satisfied: face-alignment==1.3.5 in /usr/local/lib/python3.11/dist-packages (1.3.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.15.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment==1.3.5) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->face-alignment==1.3.5) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.3.5) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->face-alignment==1.3.5) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "j6kl565aMbdT",
        "outputId": "2272f817-e48f-4dff-dfd0-28d076d3d2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c7763a8b64b249f081db207500e850a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/extract_frames\n",
        "!mkdir -p /content/input_videos\n",
        "!mkdir -p /content/alignmented_frame\n",
        "!mkdir -p /content/alignmented_frame_aligned\n",
        "!mkdir -p /content/alignmented_frame_croped\n",
        "!mkdir -p /content/alignmented_frame_transforms"
      ],
      "metadata": {
        "id": "UlYQQ1my-rL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#git hub & model install"
      ],
      "metadata": {
        "id": "Io1UJS2j-HYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/stylegan3-editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae5jdZJn-UUn",
        "outputId": "8e7c3e0d-9c8c-4cb8-c8b4-edd8320995d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan3-editing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "8gQABgnW-aOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -P /content/pretrained_models/\n",
        "!bzip2 -d /content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZNpi4s-HAa",
        "outputId": "94a776c3-85a7-49fe-8154-5c38fb117092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 12:40:07--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-06-20 12:40:07--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‚Äò/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.1‚Äô\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  43.6MB/s    in 1.4s    \n",
            "\n",
            "2025-06-20 12:40:09 (43.6 MB/s) - ‚Äò/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2.1‚Äô saved [64040097/64040097]\n",
            "\n",
            "bzip2: Output file /content/pretrained_models/shape_predictor_68_face_landmarks.dat already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm -O /content/pretrained_models/restyle_e4e_sg3.pt\n",
        "!gdown --id 13q6m-bpe3Ws9en9y45JEx2PHQirStt8N -O /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
        "!gdown --id 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn -O /content/pretrained_models/model_ir_se50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntmFmSfd-ZiO",
        "outputId": "3ba1560a-707e-4778-f6c9-bb3944362b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm\n",
            "From (redirected): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm&confirm=t&uuid=3061d757-5756-4f17-8058-681ae6ad092d\n",
            "To: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "100% 809M/809M [00:03<00:00, 244MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N\n",
            "From (redirected): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N&confirm=t&uuid=9909ac68-a1c5-4507-9fdb-b25294fc1085\n",
            "To: /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
            "100% 60.4M/60.4M [00:00<00:00, 73.1MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn\n",
            "From (redirected): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn&confirm=t&uuid=e2291894-3b73-46dc-a81d-a3748046b2e7\n",
            "To: /content/pretrained_models/model_ir_se50.pth\n",
            "100% 175M/175M [00:01<00:00, 93.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stylegan3-editing/pretrained_models\n",
        "!cp /content/pretrained_models/shape_predictor_68_face_landmarks.dat /content/stylegan3-editing/pretrained_models/"
      ],
      "metadata": {
        "id": "aCa0uxct-mxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess frames"
      ],
      "metadata": {
        "id": "PBElw7K4_zJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Îã®Ïùº ÌîÑÎ°úÏÑ∏Ïä§ ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏΩîÎìú\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "video_dir = \"/content/input_videos\"  #@param {type:\"string\"}\n",
        "output_base = \"/content/extract_frames\"  #@param {type:\"string\"}\n",
        "extract_per_sec = 7  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "def extract_video_frames(video_path):\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    output_dir = os.path.join(output_base, video_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval = max(1, int(fps // extract_per_sec))\n",
        "\n",
        "    frame_idx = 0\n",
        "    frame_list = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % interval == 0:\n",
        "            frame_list.append(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Ïó¨Í∏∞ÏÑú Ìïú Î≤àÏóê Ï†ÄÏû•!\n",
        "    for saved_idx, frame in enumerate(frame_list):\n",
        "        frame_path = os.path.join(output_dir, f\"key_{saved_idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    return f\"{video_name}: {len(frame_list)} frames saved\"\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "video_paths = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "print(f\"üé¨ Ï¥ù {len(video_paths)}Í∞úÏùò ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\")\n",
        "\n",
        "for video_path in tqdm(video_paths, desc=\"üì¶ Processing videos\"):\n",
        "    msg = extract_video_frames(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3XEaKpDfN2",
        "outputId": "fb855b92-eb67-4187-a354-dc12fc754f68",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ Ï¥ù 3Í∞úÏùò ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üì¶ Processing videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:01<00:00,  1.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ÌîºÏπò Ï†úÌïú Í∞ïÌôî + ÎààÎú∏ 50% Í∏∞Ï§Ä + KeyError Ìï¥Í≤∞ ÏΩîÎìú\n",
        "import cv2, os, math, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe Ï¥àÍ∏∞Ìôî\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACE_MESH = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# Îàà Ï¢åÌëú Ïù∏Îç±Ïä§\n",
        "LEFT_EYE_IDX = [\n",
        "    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,\n",
        "    33, 173, 157, 158, 159, 160, 161, 246, 33\n",
        "]\n",
        "RIGHT_EYE_IDX = [\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382,\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 362\n",
        "]\n",
        "\n",
        "CORE_LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "CORE_RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_EYE_VERTICAL = [159, 145]\n",
        "RIGHT_EYE_VERTICAL = [386, 374]\n",
        "POSE_IDX = [1, 152, 33, 263, 61, 291]\n",
        "\n",
        "# ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï - ÌîºÏπò Ï†úÌïú Í∞ïÌôî, ÎààÎú∏ Í∏∞Ï§Ä ÏôÑÌôî\n",
        "YAW_T = 25\n",
        "PITCH_T = 25  # 35ÏóêÏÑú 25Î°ú Í∞ïÌôî (ÌîºÏπò Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "HEAD_DOWN_BONUS = 1  # Î≥¥ÎÑàÏä§ ÏµúÏÜåÌôî\n",
        "ENABLE_ADAPTIVE_EAR = True\n",
        "EAR_PERCENTILE_HIGH = 37 # ÏÉÅÏúÑ 50%Î•º ÎààÎú¨ ÏÉÅÌÉúÎ°ú ÌåêÏ†ï (Í∏∞Ï°¥ 40%ÏóêÏÑú ÏôÑÌôî)\n",
        "EAR_PERCENTILE_LOW = 10\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=\"double\")\n",
        "\n",
        "def get_mediapipe_landmarks(img):\n",
        "    h, w = img.shape[:2]\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = FACE_MESH.process(rgb)\n",
        "    if not res.multi_face_landmarks:\n",
        "        return None\n",
        "    lm = res.multi_face_landmarks[0]\n",
        "    coords = np.array([[p.x * w, p.y * h] for p in lm.landmark])\n",
        "    return coords\n",
        "\n",
        "def estimate_pose_mediapipe(landmarks, img_shape):\n",
        "    image_points = landmarks[POSE_IDX]\n",
        "    focal = img_shape[1]\n",
        "    center = (img_shape[1]/2, img_shape[0]/2)\n",
        "    cam = np.array([[focal, 0, center[0]], [0, focal, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "    dist = np.zeros((4,1))\n",
        "    success, rv, _ = cv2.solvePnP(model_points, image_points, cam, dist)\n",
        "    return rv if success else None\n",
        "\n",
        "def rotation_vector_to_euler(rv):\n",
        "    rmat, _ = cv2.Rodrigues(rv)\n",
        "    proj = np.hstack((rmat, np.zeros((3,1))))\n",
        "    angles = cv2.decomposeProjectionMatrix(proj)[6]\n",
        "    pitch = math.degrees(math.asin(math.sin(math.radians(angles[1][0]))))\n",
        "    yaw   = math.degrees(math.asin(math.sin(math.radians(angles[2][0]))))\n",
        "    roll  = -math.degrees(math.asin(math.sin(math.radians(angles[0][0]))))\n",
        "    return pitch, yaw, roll\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "def enhanced_eye_aspect_ratio(landmarks, is_left=True):\n",
        "    if is_left:\n",
        "        outer = landmarks[33]\n",
        "        inner = landmarks[133]\n",
        "        v1 = np.linalg.norm(landmarks[159] - landmarks[145])\n",
        "        v2 = np.linalg.norm(landmarks[158] - landmarks[153])\n",
        "        v3 = np.linalg.norm(landmarks[160] - landmarks[144])\n",
        "    else:\n",
        "        outer = landmarks[362]\n",
        "        inner = landmarks[263]\n",
        "        v1 = np.linalg.norm(landmarks[386] - landmarks[374])\n",
        "        v2 = np.linalg.norm(landmarks[385] - landmarks[373])\n",
        "        v3 = np.linalg.norm(landmarks[387] - landmarks[380])\n",
        "\n",
        "    horizontal = np.linalg.norm(outer - inner)\n",
        "    avg_vertical = (v1 + v2 + v3) / 3.0\n",
        "    return avg_vertical / horizontal\n",
        "\n",
        "def calculate_adaptive_ear_thresholds(all_ear_values):\n",
        "    \"\"\"ÏòÅÏÉÅÎ≥Ñ Ï†ÅÏùëÌòï EAR ÏûÑÍ≥ÑÍ∞í Í≥ÑÏÇ∞ - 50% Í∏∞Ï§Ä Ï†ÅÏö©\"\"\"\n",
        "    if len(all_ear_values) < 5:\n",
        "        return {\n",
        "            'high_threshold': 0.23,\n",
        "            'medium_threshold': 0.18,\n",
        "            'low_threshold': 0.15,\n",
        "            'min_threshold': 0.12\n",
        "        }\n",
        "\n",
        "    ear_array = np.array(all_ear_values)\n",
        "\n",
        "    # 50% Í∏∞Ï§ÄÏúºÎ°ú ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï\n",
        "    high_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH)  # ÏÉÅÏúÑ 50%\n",
        "    medium_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.2)  # ÏÉÅÏúÑ 60%\n",
        "    low_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.5)  # ÏÉÅÏúÑ 75%\n",
        "    min_threshold = np.percentile(ear_array, EAR_PERCENTILE_LOW)  # ÌïòÏúÑ 10%\n",
        "\n",
        "    # ÏµúÏÜåÍ∞í Î≥¥Ïû•\n",
        "    high_threshold = max(high_threshold, 0.16)  # Îçî Í¥ÄÎåÄÌïòÍ≤å\n",
        "    medium_threshold = max(medium_threshold, 0.13)\n",
        "    low_threshold = max(low_threshold, 0.10)\n",
        "    min_threshold = max(min_threshold, 0.07)\n",
        "\n",
        "    return {\n",
        "        'high_threshold': high_threshold,\n",
        "        'medium_threshold': medium_threshold,\n",
        "        'low_threshold': low_threshold,\n",
        "        'min_threshold': min_threshold,\n",
        "        'ear_stats': {\n",
        "            'mean': np.mean(ear_array),\n",
        "            'std': np.std(ear_array),\n",
        "            'min': np.min(ear_array),\n",
        "            'max': np.max(ear_array),\n",
        "            'count': len(ear_array)\n",
        "        }\n",
        "    }\n",
        "\n",
        "def is_eye_open_adaptive(landmarks, thresholds, pitch_angle=0):\n",
        "    \"\"\"Ï†ÅÏùëÌòï EAR Í∏∞Î∞ò ÎààÎú∏ ÌåêÏ†ï - ÌîºÏπò Ï°∞Ï†ï ÏµúÏÜåÌôî\"\"\"\n",
        "\n",
        "    left_eye_basic = landmarks[CORE_LEFT_EYE]\n",
        "    right_eye_basic = landmarks[CORE_RIGHT_EYE]\n",
        "\n",
        "    basic_left_ear = eye_aspect_ratio(left_eye_basic)\n",
        "    basic_right_ear = eye_aspect_ratio(right_eye_basic)\n",
        "    basic_avg_ear = (basic_left_ear + basic_right_ear) / 2.0\n",
        "\n",
        "    enhanced_left_ear = enhanced_eye_aspect_ratio(landmarks, True)\n",
        "    enhanced_right_ear = enhanced_eye_aspect_ratio(landmarks, False)\n",
        "    enhanced_avg_ear = (enhanced_left_ear + enhanced_right_ear) / 2.0\n",
        "\n",
        "    ear_difference = abs(basic_left_ear - basic_right_ear)\n",
        "\n",
        "    # ÌîºÏπò Ï°∞Ï†ï ÏµúÏÜåÌôî (Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "    pitch_factor = 1.0\n",
        "    if pitch_angle > 20:  # 20ÎèÑ Ïù¥ÏÉÅÏóêÏÑúÎßå ÏµúÏÜå Ï°∞Ï†ï\n",
        "        pitch_factor = max(0.95, 1.0 - (pitch_angle - 20) * 0.005)  # ÏµúÎåÄ 5%Îßå ÏôÑÌôî\n",
        "\n",
        "    # Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö©\n",
        "    adj_high = thresholds['high_threshold'] * pitch_factor\n",
        "    adj_medium = thresholds['medium_threshold'] * pitch_factor\n",
        "    adj_low = thresholds['low_threshold'] * pitch_factor\n",
        "    adj_min = thresholds['min_threshold'] * pitch_factor\n",
        "\n",
        "    # 4Îã®Í≥Ñ ÎààÎú∏ ÌåêÏ†ï\n",
        "    level_1 = (basic_avg_ear > adj_high and\n",
        "               enhanced_avg_ear > adj_high * 0.9 and\n",
        "               basic_left_ear > adj_medium and\n",
        "               basic_right_ear > adj_medium and\n",
        "               ear_difference < 0.08)\n",
        "\n",
        "    level_2 = (basic_avg_ear > adj_medium and\n",
        "               enhanced_avg_ear > adj_medium * 0.8 and\n",
        "               basic_left_ear > adj_low and\n",
        "               basic_right_ear > adj_low and\n",
        "               ear_difference < 0.12)\n",
        "\n",
        "    level_3 = (basic_avg_ear > adj_low and\n",
        "               basic_left_ear > adj_min and\n",
        "               basic_right_ear > adj_min and\n",
        "               ear_difference < 0.15)\n",
        "\n",
        "    level_4 = (basic_avg_ear > adj_min and\n",
        "               basic_left_ear > adj_min * 0.8 and\n",
        "               basic_right_ear > adj_min * 0.8)\n",
        "\n",
        "    # Î†àÎ≤®Î≥Ñ Ï†êÏàò Î∂ÄÏó¨\n",
        "    if level_1:\n",
        "        eye_level = 4\n",
        "    elif level_2:\n",
        "        eye_level = 3\n",
        "    elif level_3:\n",
        "        eye_level = 2\n",
        "    elif level_4:\n",
        "        eye_level = 1\n",
        "    else:\n",
        "        eye_level = 0\n",
        "\n",
        "    return eye_level, {\n",
        "        'basic_ear': basic_avg_ear,\n",
        "        'enhanced_ear': enhanced_avg_ear,\n",
        "        'left_ear': basic_left_ear,\n",
        "        'right_ear': basic_right_ear,\n",
        "        'ear_diff': ear_difference,\n",
        "        'eye_level': eye_level,\n",
        "        'pitch_factor': pitch_factor,\n",
        "        'thresholds_used': {\n",
        "            'high': adj_high,\n",
        "            'medium': adj_medium,\n",
        "            'low': adj_low,\n",
        "            'min': adj_min\n",
        "        }\n",
        "    }\n",
        "\n",
        "def frontal_score_strict_pitch(c):\n",
        "    \"\"\"ÌîºÏπò Ï†úÌïú Í∞ïÌôîÎêú Ï†ïÎ©¥ÏÑ± ÌèâÍ∞Ä Ìï®Ïàò\"\"\"\n",
        "\n",
        "    yaw_angle = abs(c['yaw'])\n",
        "    pitch_angle = c['pitch']\n",
        "\n",
        "    # ÏóÑÍ≤©Ìïú Í∞ÅÎèÑ Ï†úÌïú (ÌîºÏπò Í¥ÄÎåÄÌïòÍ≤å ÌïòÏßÄ ÏïäÏùå)\n",
        "    if yaw_angle > YAW_T:  # 25ÎèÑ\n",
        "        return -1000\n",
        "    if abs(pitch_angle) > PITCH_T:  # ¬±25ÎèÑ (ÏóÑÍ≤©)\n",
        "        return -1000\n",
        "\n",
        "    # Í∏∞Î≥∏ ÌéòÎÑêÌã∞ (ÌîºÏπòÏóê Îçî ÌÅ∞ Í∞ÄÏ§ëÏπò)\n",
        "    yaw_penalty = yaw_angle * 0.8\n",
        "    pitch_penalty = abs(pitch_angle) * 1.2  # ÌîºÏπò ÌéòÎÑêÌã∞ Ï¶ùÍ∞Ä\n",
        "\n",
        "    # Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§ ÏµúÏÜåÌôî\n",
        "    head_down_bonus = 0\n",
        "    if -15 <= pitch_angle <= -5:  # ÏïÑÏ£º Ï†úÌïúÏ†ÅÏù∏ Î≤îÏúÑÏóêÏÑúÎßå\n",
        "        head_down_bonus = HEAD_DOWN_BONUS * 0.5  # Î≥¥ÎÑàÏä§ÎèÑ Ï†àÎ∞òÏúºÎ°ú\n",
        "\n",
        "    # ÎààÎú∏ Î†àÎ≤® Î≥¥ÎÑàÏä§\n",
        "    eye_level = c.get('eye_level', 0)\n",
        "    eye_bonus = eye_level * 12  # ÎààÎú∏Ïù¥ Îçî Ï§ëÏöî\n",
        "\n",
        "    bonus = eye_bonus + (head_down_bonus if pitch_angle < 0 else 0)\n",
        "\n",
        "    return -(0.5 * yaw_penalty + 0.5 * pitch_penalty) + bonus\n",
        "\n",
        "def calculate_final_quality_score(pitch, yaw, eye_level, ear_details):\n",
        "    \"\"\"ÏµúÏ¢Ö ÌíàÏßà Ï†êÏàò Í≥ÑÏÇ∞ - ÌîºÏπò ÌéòÎÑêÌã∞ Í∞ïÌôî\"\"\"\n",
        "\n",
        "    # Í∞ÅÎèÑ Ï†êÏàò (ÌîºÏπòÏóê Îçî ÌÅ∞ ÌéòÎÑêÌã∞)\n",
        "    yaw_score = max(0, 100 - abs(yaw) * 2.0)\n",
        "    pitch_score = max(0, 100 - abs(pitch) * 2.5)  # ÌîºÏπò ÌéòÎÑêÌã∞ Ï¶ùÍ∞Ä\n",
        "    angle_score = (yaw_score + pitch_score) / 2\n",
        "\n",
        "    # ÎààÎú∏ Î†àÎ≤® Ï†êÏàò (50% Í∏∞Ï§ÄÏù¥ÎØÄÎ°ú Îçî Í¥ÄÎåÄ)\n",
        "    eye_score = eye_level * 25\n",
        "\n",
        "    # EAR ÌíàÏßà Ï†êÏàò\n",
        "    ear_quality = min(100, ear_details['basic_ear'] * 300)\n",
        "\n",
        "    # Ï¢ÖÌï© Ï†êÏàò (ÎààÎú∏ ÎπÑÏ§ë Ï¶ùÍ∞Ä)\n",
        "    total_score = (\n",
        "        angle_score * 0.3 +    # Í∞ÅÎèÑ 30%\n",
        "        eye_score * 0.5 +      # ÎààÎú∏ 50% (Ï¶ùÍ∞Ä)\n",
        "        ear_quality * 0.2      # EAR ÌíàÏßà 20%\n",
        "    )\n",
        "\n",
        "    return total_score\n",
        "\n",
        "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "INPUT_ROOT = \"/content/extract_frames\"\n",
        "OUTPUT_ROOT = \"/content/alignmented_frame\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "file_ext = \".jpg\"\n",
        "video_dirs = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
        "missing_videos = []\n",
        "detailed_log = []\n",
        "best_images = []\n",
        "best_names = []\n",
        "\n",
        "print(f\"üì¶ Ï¥ù {len(video_dirs)}Í∞ú ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\")\n",
        "print(f\"üéØ ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ {EAR_PERCENTILE_HIGH}% (50% Í∏∞Ï§ÄÏúºÎ°ú ÏôÑÌôî)\")\n",
        "print(f\"üìê Í∞ÅÎèÑ Ï†úÌïú: Yaw ¬±{YAW_T}¬∞, Pitch ¬±{PITCH_T}¬∞ (ÌîºÏπò Ï†úÌïú Í∞ïÌôî)\")\n",
        "print(f\"üéÅ Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: {HEAD_DOWN_BONUS}Ï†ê (ÏµúÏÜåÌôî)\")\n",
        "\n",
        "for video_name in tqdm(video_dirs, desc=\"üéØ Strict pitch + 50% eye threshold\"):\n",
        "    input_dir = os.path.join(INPUT_ROOT, video_name)\n",
        "\n",
        "    # 1Îã®Í≥Ñ: Î™®Îì† ÌîÑÎ†àÏûÑÏùò EAR Í∞í ÏàòÏßë\n",
        "    all_ear_values = []\n",
        "    frame_data = []\n",
        "\n",
        "    for f in sorted(os.listdir(input_dir)):\n",
        "        if not f.lower().endswith(file_ext):\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(input_dir, f)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        lm = get_mediapipe_landmarks(img)\n",
        "        if lm is None:\n",
        "            continue\n",
        "\n",
        "        rv = estimate_pose_mediapipe(lm, img.shape)\n",
        "        if rv is None:\n",
        "            continue\n",
        "\n",
        "        pitch, yaw, _ = rotation_vector_to_euler(rv)\n",
        "\n",
        "        # ÏóÑÍ≤©Ìïú Í∞ÅÎèÑ Ï†úÌïú\n",
        "        if abs(yaw) > YAW_T * 1.5 or abs(pitch) > PITCH_T * 1.5:\n",
        "            continue\n",
        "\n",
        "        # EAR Í≥ÑÏÇ∞\n",
        "        left_eye = lm[CORE_LEFT_EYE]\n",
        "        right_eye = lm[CORE_RIGHT_EYE]\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        all_ear_values.append(avg_ear)\n",
        "\n",
        "        # ÌîÑÎ†àÏûÑ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\n",
        "        x1, y1 = lm[:,0].min(), lm[:,1].min()\n",
        "        x2, y2 = lm[:,0].max(), lm[:,1].max()\n",
        "        face_area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "        frame_data.append({\n",
        "            'img': img,\n",
        "            'filename': f,\n",
        "            'landmarks': lm,\n",
        "            'pitch': pitch,\n",
        "            'yaw': yaw,\n",
        "            'avg_ear': avg_ear,\n",
        "            'cx': cx,\n",
        "            'cy': cy,\n",
        "            'face_area': face_area\n",
        "        })\n",
        "\n",
        "    if not all_ear_values:\n",
        "        missing_videos.append(video_name)\n",
        "        detailed_log.append({\n",
        "            'video_name': video_name,\n",
        "            'total_frames': 0,\n",
        "            'selected': False,\n",
        "            'selection_level': 0,  # KeyError Î∞©ÏßÄÎ•º ÏúÑÌï¥ Ï∂îÍ∞Ä\n",
        "            'reason': 'No valid frames found'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 2Îã®Í≥Ñ: Ï†ÅÏùëÌòï ÏûÑÍ≥ÑÍ∞í Í≥ÑÏÇ∞ (50% Í∏∞Ï§Ä)\n",
        "    thresholds = calculate_adaptive_ear_thresholds(all_ear_values)\n",
        "\n",
        "    # 3Îã®Í≥Ñ: 4Îã®Í≥Ñ ÌõÑÎ≥¥ Î∂ÑÎ•ò\n",
        "    level_4_candidates = []\n",
        "    level_3_candidates = []\n",
        "    level_2_candidates = []\n",
        "    level_1_candidates = []\n",
        "\n",
        "    for frame in frame_data:\n",
        "        # ÏóÑÍ≤©Ìïú ÌîºÏπò Ï†úÌïú Ï†ÅÏö©\n",
        "        if abs(frame['pitch']) > PITCH_T:\n",
        "            continue\n",
        "\n",
        "        eye_level, eye_details = is_eye_open_adaptive(\n",
        "            frame['landmarks'], thresholds, abs(frame['pitch'])\n",
        "        )\n",
        "\n",
        "        if eye_level == 0:\n",
        "            continue\n",
        "\n",
        "        candidate = {\n",
        "            'img': frame['img'],\n",
        "            'filename': frame['filename'],\n",
        "            'pitch': frame['pitch'],\n",
        "            'yaw': frame['yaw'],\n",
        "            'cx': frame['cx'],\n",
        "            'cy': frame['cy'],\n",
        "            'face_area': frame['face_area'],\n",
        "            'w': frame['img'].shape[1],\n",
        "            'h': frame['img'].shape[0],\n",
        "            'eye_level': eye_level,\n",
        "            'eye_details': eye_details,\n",
        "            'quality_score': calculate_final_quality_score(\n",
        "                frame['pitch'], frame['yaw'], eye_level, eye_details\n",
        "            )\n",
        "        }\n",
        "\n",
        "        if eye_level == 4:\n",
        "            level_4_candidates.append(candidate)\n",
        "        elif eye_level == 3:\n",
        "            level_3_candidates.append(candidate)\n",
        "        elif eye_level == 2:\n",
        "            level_2_candidates.append(candidate)\n",
        "        else:\n",
        "            level_1_candidates.append(candidate)\n",
        "\n",
        "    # 4Îã®Í≥Ñ: ÏµúÏ†Å ÌîÑÎ†àÏûÑ ÏÑ†ÌÉù\n",
        "    best_img = None\n",
        "    best_filename = None\n",
        "    selection_reason = \"No suitable frames\"\n",
        "    selection_level = 0\n",
        "\n",
        "    if level_4_candidates:\n",
        "        best = max(level_4_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 4: Selected from {len(level_4_candidates)} highest quality candidates\"\n",
        "        selection_level = 4\n",
        "\n",
        "    elif level_3_candidates:\n",
        "        best = max(level_3_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 3: Selected from {len(level_3_candidates)} high quality candidates\"\n",
        "        selection_level = 3\n",
        "\n",
        "    elif level_2_candidates:\n",
        "        best = max(level_2_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 2: Selected from {len(level_2_candidates)} medium quality candidates\"\n",
        "        selection_level = 2\n",
        "\n",
        "    elif level_1_candidates:\n",
        "        best = max(level_1_candidates, key=lambda x: x['quality_score'])\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 1: Selected from {len(level_1_candidates)} minimum quality candidates\"\n",
        "        selection_level = 1\n",
        "\n",
        "    elif frame_data:\n",
        "        # ÏµúÌõÑÏùò ÏàòÎã®: Í∞ÄÏû• ÌíàÏßà Ï¢ãÏùÄ ÌîÑÎ†àÏûÑ Î¨¥Ï°∞Í±¥ ÏÑ†ÌÉù\n",
        "        best_frame = max(frame_data, key=lambda x: x['avg_ear'])\n",
        "        best_img = best_frame['img']\n",
        "        best_filename = best_frame['filename']\n",
        "        selection_reason = f\"Emergency: Selected best EAR frame ({best_frame['avg_ear']:.3f})\"\n",
        "        selection_level = 0\n",
        "\n",
        "    # KeyError Î∞©ÏßÄÎ•º ÏúÑÌïú ÏïàÏ†ÑÌïú Î°úÍ∑∏ Í∏∞Î°ù\n",
        "    detailed_log.append({\n",
        "        'video_name': video_name,\n",
        "        'total_frames': len(frame_data),\n",
        "        'level_4_candidates': len(level_4_candidates),\n",
        "        'level_3_candidates': len(level_3_candidates),\n",
        "        'level_2_candidates': len(level_2_candidates),\n",
        "        'level_1_candidates': len(level_1_candidates),\n",
        "        'selected': best_filename is not None,\n",
        "        'selection_level': selection_level,  # Ìï≠ÏÉÅ Ìè¨Ìï®\n",
        "        'best_filename': best_filename,\n",
        "        'reason': selection_reason,\n",
        "        'ear_thresholds': thresholds,\n",
        "        'quality_score': best.get('quality_score', 0) if 'best' in locals() else 0\n",
        "    })\n",
        "\n",
        "    # ÌîÑÎ†àÏûÑ Ï†ÄÏû•\n",
        "    if best_img is not None:\n",
        "        save_path = os.path.join(OUTPUT_ROOT, f\"{video_name}.jpg\")\n",
        "        cv2.imwrite(save_path, best_img)\n",
        "\n",
        "        if selection_level <= 1:\n",
        "            print(f\"‚ö†Ô∏è  {video_name}: Low quality selection (Level {selection_level})\")\n",
        "    else:\n",
        "        missing_videos.append(video_name)\n",
        "\n",
        "# Í≤∞Í≥º Ï†ÄÏû•\n",
        "if missing_videos:\n",
        "    df_missing = pd.DataFrame(missing_videos, columns=[\"video_name\"])\n",
        "    df_missing.to_csv(\"no_frame_found.csv\", index=False)\n",
        "    print(f\"‚ùó {len(missing_videos)}Í∞ú ÏòÅÏÉÅÏóêÏÑú ÌîÑÎ†àÏûÑÏùÑ Ï∞æÏßÄ Î™ªÌï®\")\n",
        "\n",
        "df_log = pd.DataFrame(detailed_log)\n",
        "df_log.to_csv(\"strict_pitch_50percent_eye_log.csv\", index=False)\n",
        "print(f\"üìä Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû•: strict_pitch_50percent_eye_log.csv\")\n",
        "\n",
        "# KeyError Î∞©ÏßÄÎêú ÏïàÏ†ÑÌïú ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
        "success_rate = (len(video_dirs) - len(missing_videos)) / len(video_dirs) * 100 if video_dirs else 0\n",
        "\n",
        "# .get() Î©îÏÑúÎìú ÏÇ¨Ïö©ÏúºÎ°ú KeyError Î∞©ÏßÄ\n",
        "level_4_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 4)\n",
        "level_3_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 3)\n",
        "level_2_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 2)\n",
        "level_1_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 1)\n",
        "emergency_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 0)\n",
        "\n",
        "print(f\"‚úÖ ÏÑ±Í≥µÎ•†: {success_rate:.1f}% ({len(video_dirs) - len(missing_videos)}/{len(video_dirs)})\")\n",
        "print(f\"üèÜ Level 4 (ÏµúÍ≥†ÌíàÏßà): {level_4_usage}Í∞ú\")\n",
        "print(f\"ü•à Level 3 (Í≥†ÌíàÏßà): {level_3_usage}Í∞ú\")\n",
        "print(f\"ü•â Level 2 (Ï§ëÌíàÏßà): {level_2_usage}Í∞ú\")\n",
        "print(f\"üìâ Level 1 (ÏµúÏÜåÌíàÏßà): {level_1_usage}Í∞ú\")\n",
        "print(f\"üö® Emergency (Í∞ïÏ†úÏÑ†ÌÉù): {emergency_usage}Í∞ú\")\n",
        "\n",
        "print(f\"\\nüìà ÌíàÏßà Î∂ÑÌè¨:\")\n",
        "print(f\"   - Í≥†ÌíàÏßà Ïù¥ÏÉÅ (Level 3+): {(level_4_usage + level_3_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - Ï§ëÌíàÏßà Ïù¥ÏÉÅ (Level 2+): {(level_4_usage + level_3_usage + level_2_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - ÏµúÏÜåÌíàÏßà Ïù¥ÏÉÅ (Level 1+): {(len(video_dirs) - emergency_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nüéØ ÏÑ§Ï†ï ÏöîÏïΩ:\")\n",
        "print(f\"   - ÌîºÏπò Ï†úÌïú: ¬±{PITCH_T}¬∞ (ÏóÑÍ≤©)\")\n",
        "print(f\"   - ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ {EAR_PERCENTILE_HIGH}% (Í¥ÄÎåÄ)\")\n",
        "print(f\"   - Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: {HEAD_DOWN_BONUS}Ï†ê (ÏµúÏÜå)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlELfbUkEFea",
        "outputId": "c5a09ebb-e20a-4289-a593-e459bafeb9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Ï¥ù 3Í∞ú ÏòÅÏÉÅ Ï≤òÎ¶¨ ÏãúÏûë\n",
            "üéØ ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ 37% (50% Í∏∞Ï§ÄÏúºÎ°ú ÏôÑÌôî)\n",
            "üìê Í∞ÅÎèÑ Ï†úÌïú: Yaw ¬±25¬∞, Pitch ¬±25¬∞ (ÌîºÏπò Ï†úÌïú Í∞ïÌôî)\n",
            "üéÅ Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: 1Ï†ê (ÏµúÏÜåÌôî)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üéØ Strict pitch + 50% eye threshold: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Ï≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû•: strict_pitch_50percent_eye_log.csv\n",
            "‚úÖ ÏÑ±Í≥µÎ•†: 100.0% (3/3)\n",
            "üèÜ Level 4 (ÏµúÍ≥†ÌíàÏßà): 1Í∞ú\n",
            "ü•à Level 3 (Í≥†ÌíàÏßà): 0Í∞ú\n",
            "ü•â Level 2 (Ï§ëÌíàÏßà): 2Í∞ú\n",
            "üìâ Level 1 (ÏµúÏÜåÌíàÏßà): 0Í∞ú\n",
            "üö® Emergency (Í∞ïÏ†úÏÑ†ÌÉù): 0Í∞ú\n",
            "\n",
            "üìà ÌíàÏßà Î∂ÑÌè¨:\n",
            "   - Í≥†ÌíàÏßà Ïù¥ÏÉÅ (Level 3+): 33.3%\n",
            "   - Ï§ëÌíàÏßà Ïù¥ÏÉÅ (Level 2+): 100.0%\n",
            "   - ÏµúÏÜåÌíàÏßà Ïù¥ÏÉÅ (Level 1+): 100.0%\n",
            "\n",
            "üéØ ÏÑ§Ï†ï ÏöîÏïΩ:\n",
            "   - ÌîºÏπò Ï†úÌïú: ¬±25¬∞ (ÏóÑÍ≤©)\n",
            "   - ÎààÎú∏ Í∏∞Ï§Ä: ÏÉÅÏúÑ 37% (Í¥ÄÎåÄ)\n",
            "   - Í≥†Í∞ú ÏàôÏûÑ Î≥¥ÎÑàÏä§: 1Ï†ê (ÏµúÏÜå)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "H_23qUpRqSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c98b584-3c45-4b67-93b6-a87574b5ae76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image crop"
      ],
      "metadata": {
        "id": "22A2atJxxcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan3-editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W19HlMQIxcMs",
        "outputId": "88eeaaa2-87d9-4a36-c4b0-5e383ebd40f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3-editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/stylegan3-editing')"
      ],
      "metadata": {
        "id": "UE0wMtQ79bS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "base_raw_root = \"/content/alignmented_frame\"\n",
        "aligned_root = f\"{base_raw_root}_aligned\"\n",
        "cropped_root = f\"{base_raw_root}_croped\"\n",
        "transform_root = f\"{base_raw_root}_transforms\"\n",
        "\n",
        "print(\"üöÄ Aligning all images...\")\n",
        "# Ïã§Ìñâ Î™ÖÎ†πÏñ¥Ïóê PYTHONPATHÎ•º Ï∂îÍ∞ÄÌïòÏó¨ Î™®ÎìàÏùÑ Ï∞æÏùÑ Í≤ΩÎ°úÎ•º ÏïåÎ†§Ï§çÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode align \\\n",
        "    --root_path \"{base_raw_root}\"\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"üîÅ Cropping all images...\")\n",
        "# Ïó¨Í∏∞ÎèÑ ÎèôÏùºÌïòÍ≤å Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode crop \\\n",
        "    --root_path \"{base_raw_root}\" \\\n",
        "    --random_shift 0.05\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"üîÅ Computing transforms for all images...\")\n",
        "# Ïó¨Í∏∞ÎèÑ ÎèôÏùºÌïòÍ≤å Ï∂îÍ∞ÄÌï©ÎãàÎã§.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/compute_landmarks_transforms.py \\\n",
        "    --raw_root \"{base_raw_root}\" \\\n",
        "    --aligned_root \"{aligned_root}\" \\\n",
        "    --cropped_root \"{cropped_root}\" \\\n",
        "    --output_root \"{transform_root}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kzg1k-FxgA2",
        "outputId": "933d5d2a-7ace-4104-e3f2-e0e44a6a1c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Aligning all images...\n",
            "1\n",
            "Running on 3 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #3 images\n",
            "\tDone!\n",
            "Mischief managed in -2.4075844287872314s\n",
            "üîÅ Cropping all images...\n",
            "1\n",
            "Running on 3 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #3 images\n",
            "\tDone!\n",
            "Mischief managed in -2.117825984954834s\n",
            "üîÅ Computing transforms for all images...\n",
            "Computing landmarks transforms...\n",
            "100% 3/3 [00:06<00:00,  2.09s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
        "input_root = \"/content/alignmented_frame_croped\"\n",
        "transforms_root = \"/content/alignmented_frame_transforms/landmarks_transforms.npy\"\n",
        "output_root = \"/content/experiments/restyle_e4e_sg3\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "\n",
        "# output ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "print(\"üöÄ Inverting video\")\n",
        "\n",
        "!python {script_path} \\\n",
        "    --output_path \"{output_root}\" \\\n",
        "    --checkpoint_path \"{ckpt_path}\" \\\n",
        "    --data_path \"{input_root}\" \\\n",
        "    --test_batch_size 4 \\\n",
        "    --test_workers 4 \\\n",
        "    --n_iters_per_batch 3 \\\n",
        "    --landmarks_transforms_path \"{transforms_root}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdozUaBz7ja",
        "outputId": "c9bc31eb-cfbe-4873-db7b-9aaac7ace668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Inverting video\n",
            "Loading ReStyle e4e from checkpoint: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "Loading StyleGAN3 generator from path: None\n",
            "Done!\n",
            "Model successfully loaded!\n",
            "Loading dataset for ffhq_encode\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "100% 1/1 [00:01<00:00,  1.72s/it]\n",
            "Runtime 1.0465+-0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save CSV"
      ],
      "metadata": {
        "id": "BAaQSZUwoGsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load latent dictionary\n",
        "latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "latent_dict = np.load(latent_path, allow_pickle=True).item()\n",
        "\n",
        "# 2. Ï†ïÎ†¨Îêú ÌååÏùº Î¶¨Ïä§Ìä∏ ÌôïÎ≥¥\n",
        "filenames = sorted(latent_dict.keys())\n",
        "\n",
        "# 3. Í∞Å latentÏóêÏÑú ÎßàÏßÄÎßâ step ‚Üí ÌèâÍ∑† ‚Üí (512,)\n",
        "latents = []\n",
        "for key in filenames:\n",
        "    latent = latent_dict[key][-1]  # ÎßàÏßÄÎßâ step (18, 512)\n",
        "    mean_latent = latent.mean(axis=0).astype('float32')  # (512,)\n",
        "    latents.append(mean_latent)\n",
        "\n",
        "latents = np.stack(latents)  # shape: (N, 512)\n",
        "\n",
        "# 4. cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(latents)  # shape: (N, N)\n",
        "\n",
        "# 5. Í∞Å query ÌååÏùºÎßàÎã§ top-3 Ïú†ÏÇ¨Ìïú match + score Ï†ÄÏû•\n",
        "rows = []\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    sims = sim_matrix[i].copy()\n",
        "    sims[i] = -np.inf  # ÏûêÍ∏∞ ÏûêÏã† Ï†úÏô∏\n",
        "    top3_idx = np.argsort(sims)[::-1][:3]\n",
        "    row = {\n",
        "        \"query\": filenames[i],\n",
        "        \"top1\": filenames[top3_idx[0]],\n",
        "        \"top2\": filenames[top3_idx[1]],\n",
        "        \"top3\": filenames[top3_idx[2]],\n",
        "        \"top1val\": round(float(sims[top3_idx[0]]), 6),\n",
        "        \"top2val\": round(float(sims[top3_idx[1]]), 6),\n",
        "        \"top3val\": round(float(sims[top3_idx[2]]), 6),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 6. Save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"video_similarity_top3_compact.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ Saved to video_similarity_top3_compact.csv\")\n"
      ],
      "metadata": {
        "id": "WjMFJ5i2oE78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229ae341-9dac-45fe-8b67-8cbd0633170a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved to video_similarity_top3_compact.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "fdUFzopMZjug",
        "outputId": "3c5d8525-0195-48e3-9056-ab3462639b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e9085cb761924200a42f4abaf57e6913"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone -q https://github.com/woctezuma/SimSwap.git SimSwap\n",
        "\n",
        "!pip install -q torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q insightface==0.7.3 onnxruntime moviepy opencv-python imageio==2.34.0\n",
        "!pip install scikit-video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCFEDIxZmkq",
        "outputId": "b812735a-663c-4d98-bca7-f72a8dc9ddd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m983.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 6.31.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.31.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-video) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from scikit-video) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from scikit-video) (1.15.3)\n",
            "Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SimSwap ÏÑ§Ï†ï ÌôïÏù∏ Î∞è ÏàòÏ†ï\n",
        "\n",
        "import os\n",
        "\n",
        "def check_and_fix_simswap():\n",
        "    \"\"\"SimSwap ÏÑ§Ï†ï ÌôïÏù∏ Î∞è ÏàòÏ†ï\"\"\"\n",
        "    print(\"üîß SimSwap ÏÑ§Ï†ï ÌôïÏù∏ Ï§ë...\")\n",
        "\n",
        "    # 1. ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏\n",
        "    required_dirs = [\n",
        "        '/content/SimSwap',\n",
        "        '/content/arcface_model',\n",
        "        '/content/SimSwap/checkpoints',\n",
        "        '/content/SimSwap/parsing_model/checkpoint'\n",
        "    ]\n",
        "\n",
        "    for dir_path in required_dirs:\n",
        "        if os.path.exists(dir_path):\n",
        "            print(f\"‚úÖ {dir_path} Ï°¥Ïû¨\")\n",
        "        else:\n",
        "            print(f\"‚ùå {dir_path} ÏóÜÏùå\")\n",
        "\n",
        "    # 2. ÌååÏùº ÌôïÏù∏\n",
        "    required_files = [\n",
        "        '/content/arcface_model/arcface_checkpoint.tar',\n",
        "        '/content/SimSwap/parsing_model/checkpoint/79999_iter.pth'\n",
        "    ]\n",
        "\n",
        "    for file_path in required_files:\n",
        "        if os.path.exists(file_path):\n",
        "            print(f\"‚úÖ {file_path} Ï°¥Ïû¨\")\n",
        "        else:\n",
        "            print(f\"‚ùå {file_path} ÏóÜÏùå\")\n",
        "\n",
        "    # 3. checkpoints ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö© ÌôïÏù∏\n",
        "    checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "    if os.path.exists(checkpoints_dir):\n",
        "        files = os.listdir(checkpoints_dir)\n",
        "        print(f\"üìÅ checkpoints ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö©: {files}\")\n",
        "\n",
        "        # people Ìè¥Îçî ÌôïÏù∏\n",
        "        people_dir = os.path.join(checkpoints_dir, 'people')\n",
        "        if os.path.exists(people_dir):\n",
        "            people_files = os.listdir(people_dir)\n",
        "            print(f\"üìÅ people Ìè¥Îçî ÎÇ¥Ïö©: {people_files}\")\n",
        "        else:\n",
        "            print(\"‚ùå people Ìè¥ÎçîÍ∞Ä ÏóÜÏùå\")\n",
        "\n",
        "    # 4. arcface ÏïïÏ∂ï Ìï¥Ï†ú ÌôïÏù∏\n",
        "    arcface_tar = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "    if os.path.exists(arcface_tar):\n",
        "        print(\"üîß arcface ÏïïÏ∂ï Ìï¥Ï†ú Ï§ë...\")\n",
        "        os.chdir('/content/arcface_model')\n",
        "        os.system('tar -xf arcface_checkpoint.tar')\n",
        "\n",
        "        # ÏïïÏ∂ï Ìï¥Ï†ú ÌõÑ ÌååÏùº ÌôïÏù∏\n",
        "        extracted_files = os.listdir('/content/arcface_model')\n",
        "        print(f\"üìÅ ÏïïÏ∂ï Ìï¥Ï†ú ÌõÑ arcface_model ÎÇ¥Ïö©: {extracted_files}\")\n",
        "\n",
        "def download_missing_models():\n",
        "    \"\"\"ÎàÑÎùΩÎêú Î™®Îç∏ Îã§Ïö¥Î°úÎìú\"\"\"\n",
        "    print(\"üì• ÎàÑÎùΩÎêú Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë...\")\n",
        "\n",
        "    # Í∏∞Î≥∏ ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "    os.makedirs('/content/arcface_model', exist_ok=True)\n",
        "    os.makedirs('/content/SimSwap/parsing_model/checkpoint', exist_ok=True)\n",
        "    os.makedirs('/content/SimSwap/checkpoints', exist_ok=True)\n",
        "    os.makedirs('/content/insightface_func/models', exist_ok=True)\n",
        "\n",
        "    # Î™®Îç∏ Îã§Ïö¥Î°úÎìú\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/1.0/arcface_checkpoint.tar -O /content/arcface_model/arcface_checkpoint.tar')\n",
        "    os.system('wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip -O /content/checkpoints.zip')\n",
        "    os.system('wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth -O /content/SimSwap/parsing_model/checkpoint/79999_iter.pth')\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/antelope/antelope.zip -O /content/antelope.zip')\n",
        "\n",
        "    # ÏïïÏ∂ï Ìï¥Ï†ú\n",
        "    os.system('unzip -q /content/checkpoints.zip -d /content/SimSwap/checkpoints')\n",
        "    os.system('unzip -q /content/antelope.zip -d /content/insightface_func/models/')\n",
        "\n",
        "    print(\"‚úÖ Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å\")\n",
        "\n",
        "def fix_simswap_compatibility():\n",
        "    \"\"\"SimSwap Ìò∏ÌôòÏÑ± ÏàòÏ†ï\"\"\"\n",
        "    print(\"üîß SimSwap Ìò∏ÌôòÏÑ± ÏàòÏ†ï Ï§ë...\")\n",
        "\n",
        "    os.chdir('/content/SimSwap')\n",
        "\n",
        "    # PyTorch Ìò∏ÌôòÏÑ± ÏàòÏ†ï\n",
        "    os.system(\"sed -i.bak 's/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"))/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"), weights_only=False)/' models/fs_model.py\")\n",
        "\n",
        "    # Í∞êÏßÄ ÌÅ¨Í∏∞ ÏàòÏ†ï\n",
        "    os.system(\"sed -i 's/det_size=(640,640)/det_size=(224,224)/' test_wholeimage_swapsingle.py\")\n",
        "\n",
        "    # NMS ÏûÑÍ≥ÑÍ∞í ÏàòÏ†ï\n",
        "    with open('test_wholeimage_swapsingle.py', 'r') as f:\n",
        "        content = f.read()\n",
        "    if 'app.models[\"detection\"].nms_thresh' not in content:\n",
        "        new_lines = []\n",
        "        for line in content.splitlines():\n",
        "            new_lines.append(line)\n",
        "            if 'app.prepare(' in line:\n",
        "                new_lines.append('    if hasattr(app.models, \"detection\"):')\n",
        "                new_lines.append('        app.models[\"detection\"].nms_thresh = 0.3')\n",
        "                new_lines.append('        app.models[\"detection\"].det_thresh = 0.3')\n",
        "        with open('test_wholeimage_swapsingle.py', 'w') as f:\n",
        "            f.write('\\n'.join(new_lines))\n",
        "\n",
        "    print(\"‚úÖ Ìò∏ÌôòÏÑ± ÏàòÏ†ï ÏôÑÎ£å\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "print(\"=== SimSwap ÏÑ§Ï†ï ÏßÑÎã® Î∞è ÏàòÏ†ï ===\")\n",
        "check_and_fix_simswap()\n",
        "download_missing_models()\n",
        "check_and_fix_simswap()  # Îã§Ïãú ÌôïÏù∏\n",
        "fix_simswap_compatibility()\n",
        "print(\"üéâ SimSwap ÏÑ§Ï†ï ÏôÑÎ£å!\")"
      ],
      "metadata": {
        "id": "Rd03Ysagf8gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6055c12-9254-4c84-ae25-7438368f70bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SimSwap ÏÑ§Ï†ï ÏßÑÎã® Î∞è ÏàòÏ†ï ===\n",
            "üîß SimSwap ÏÑ§Ï†ï ÌôïÏù∏ Ï§ë...\n",
            "‚úÖ /content/SimSwap Ï°¥Ïû¨\n",
            "‚ùå /content/arcface_model ÏóÜÏùå\n",
            "‚ùå /content/SimSwap/checkpoints ÏóÜÏùå\n",
            "‚ùå /content/SimSwap/parsing_model/checkpoint ÏóÜÏùå\n",
            "‚ùå /content/arcface_model/arcface_checkpoint.tar ÏóÜÏùå\n",
            "‚ùå /content/SimSwap/parsing_model/checkpoint/79999_iter.pth ÏóÜÏùå\n",
            "üì• ÎàÑÎùΩÎêú Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë...\n",
            "‚úÖ Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å\n",
            "üîß SimSwap ÏÑ§Ï†ï ÌôïÏù∏ Ï§ë...\n",
            "‚úÖ /content/SimSwap Ï°¥Ïû¨\n",
            "‚úÖ /content/arcface_model Ï°¥Ïû¨\n",
            "‚úÖ /content/SimSwap/checkpoints Ï°¥Ïû¨\n",
            "‚úÖ /content/SimSwap/parsing_model/checkpoint Ï°¥Ïû¨\n",
            "‚úÖ /content/arcface_model/arcface_checkpoint.tar Ï°¥Ïû¨\n",
            "‚úÖ /content/SimSwap/parsing_model/checkpoint/79999_iter.pth Ï°¥Ïû¨\n",
            "üìÅ checkpoints ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö©: ['people']\n",
            "üìÅ people Ìè¥Îçî ÎÇ¥Ïö©: ['latest_net_G.pth', 'latest_net_D2.pth', 'latest_net_D1.pth', 'loss_log.txt', 'iter.txt', 'web', 'opt.txt']\n",
            "üîß arcface ÏïïÏ∂ï Ìï¥Ï†ú Ï§ë...\n",
            "üìÅ ÏïïÏ∂ï Ìï¥Ï†ú ÌõÑ arcface_model ÎÇ¥Ïö©: ['arcface_checkpoint.tar']\n",
            "üîß SimSwap Ìò∏ÌôòÏÑ± ÏàòÏ†ï Ï§ë...\n",
            "‚úÖ Ìò∏ÌôòÏÑ± ÏàòÏ†ï ÏôÑÎ£å\n",
            "üéâ SimSwap ÏÑ§Ï†ï ÏôÑÎ£å!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# InsightFace Î™®Îç∏ Î¨∏Ï†ú Ìï¥Í≤∞\n",
        "\n",
        "import os\n",
        "\n",
        "def fix_insightface_models():\n",
        "    \"\"\"InsightFace Î™®Îç∏ Î¨∏Ï†ú Ìï¥Í≤∞\"\"\"\n",
        "    print(\"üîß InsightFace Î™®Îç∏ Î¨∏Ï†ú Ìï¥Í≤∞ Ï§ë...\")\n",
        "\n",
        "    # 1. ÌòÑÏû¨ ÏÉÅÌô© ÌôïÏù∏\n",
        "    models_dir = '/content/SimSwap/insightface_func/models'\n",
        "    if os.path.exists(models_dir):\n",
        "        print(f\"üìÅ models ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö©: {os.listdir(models_dir)}\")\n",
        "\n",
        "        antelope_dir = os.path.join(models_dir, 'antelope')\n",
        "        if os.path.exists(antelope_dir):\n",
        "            print(f\"üìÅ antelope ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïö©: {os.listdir(antelope_dir)}\")\n",
        "        else:\n",
        "            print(\"‚ùå antelope ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏùå\")\n",
        "\n",
        "    # 2. antelope Î™®Îç∏ Ïû¨Îã§Ïö¥Î°úÎìú Î∞è Ïò¨Î∞îÎ•∏ ÏúÑÏπòÏóê ÏÑ§Ïπò\n",
        "    print(\"üì• antelope Î™®Îç∏ Ïû¨ÏÑ§Ïπò Ï§ë...\")\n",
        "\n",
        "    antelope_dir = '/content/SimSwap/insightface_func/models/antelope'\n",
        "\n",
        "    # Í∏∞Ï°¥ ÌååÏùº Ï†ïÎ¶¨\n",
        "    os.system('rm -rf /content/SimSwap/insightface_func/models/antelope')\n",
        "    os.system('rm -f /content/antelope.zip')\n",
        "\n",
        "    # Ïò¨Î∞îÎ•∏ antelope Î™®Îç∏ Îã§Ïö¥Î°úÎìú\n",
        "    os.system('wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/antelope/antelope.zip -O /content/antelope.zip')\n",
        "\n",
        "    # ÏïïÏ∂ï Ìï¥Ï†ú\n",
        "    os.system('unzip -q /content/antelope.zip -d /content/SimSwap/insightface_func/models/')\n",
        "\n",
        "    # 3. Îã§Ïãú ÌôïÏù∏\n",
        "    if os.path.exists(antelope_dir):\n",
        "        files = os.listdir(antelope_dir)\n",
        "        print(f\"üìÅ ÏÑ§Ïπò ÌõÑ antelope ÎÇ¥Ïö©: {files}\")\n",
        "\n",
        "        # ÌïÑÏàò ÌååÏùºÎì§ ÌôïÏù∏\n",
        "        required_files = ['glintr100.onnx', 'scrfd_10g_bnkps.onnx']\n",
        "        for req_file in required_files:\n",
        "            if req_file in files:\n",
        "                print(f\"‚úÖ {req_file} Ï°¥Ïû¨\")\n",
        "            else:\n",
        "                print(f\"‚ùå {req_file} ÏóÜÏùå\")\n",
        "\n",
        "    print(\"‚úÖ InsightFace Î™®Îç∏ Ïû¨ÏÑ§Ïπò ÏôÑÎ£å\")\n",
        "\n",
        "def alternative_download():\n",
        "    \"\"\"ÎåÄÏïà Îã§Ïö¥Î°úÎìú Î∞©Î≤ï\"\"\"\n",
        "    print(\"üîÑ ÎåÄÏïà Î∞©Î≤ïÏúºÎ°ú Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë...\")\n",
        "\n",
        "    # Í∞úÎ≥Ñ ÌååÏùº Îã§Ïö¥Î°úÎìú\n",
        "    antelope_dir = '/content/SimSwap/insightface_func/models/antelope'\n",
        "    os.makedirs(antelope_dir, exist_ok=True)\n",
        "\n",
        "    # ÌïÑÏàò Î™®Îç∏ ÌååÏùºÎì§ Í∞úÎ≥Ñ Îã§Ïö¥Î°úÎìú\n",
        "    models = {\n",
        "        'glintr100.onnx': 'https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip',\n",
        "        'scrfd_10g_bnkps.onnx': 'https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip'\n",
        "    }\n",
        "\n",
        "    # buffalo_l Î™®Îç∏ Îã§Ïö¥Î°úÎìú (Îçî ÏïàÏ†ïÏ†Å)\n",
        "    print(\"üì• buffalo_l Î™®Îç∏ Îã§Ïö¥Î°úÎìú Ï§ë...\")\n",
        "    os.system('wget -q https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip -O /content/buffalo_l.zip')\n",
        "    os.system(f'unzip -q /content/buffalo_l.zip -d {antelope_dir}')\n",
        "\n",
        "    # ÌååÏùº ÌôïÏù∏\n",
        "    if os.path.exists(antelope_dir):\n",
        "        files = os.listdir(antelope_dir)\n",
        "        print(f\"üìÅ buffalo_l ÏÑ§Ïπò ÌõÑ: {files}\")\n",
        "\n",
        "# Ïã§Ìñâ\n",
        "fix_insightface_models()\n",
        "\n",
        "# Ïã§Ìå®Ïãú ÎåÄÏïà Î∞©Î≤ï\n",
        "if not os.path.exists('/content/SimSwap/insightface_func/models/antelope/glintr100.onnx'):\n",
        "    print(\"\\nüîÑ Í∏∞Î≥∏ Î∞©Î≤ï Ïã§Ìå®, ÎåÄÏïà Î∞©Î≤ï ÏãúÎèÑ...\")\n",
        "    alternative_download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKyxMFQOgeo0",
        "outputId": "58513377-4d99-44b6-86f9-f597f77909b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß InsightFace Î™®Îç∏ Î¨∏Ï†ú Ìï¥Í≤∞ Ï§ë...\n",
            "üì• antelope Î™®Îç∏ Ïû¨ÏÑ§Ïπò Ï§ë...\n",
            "üìÅ ÏÑ§Ïπò ÌõÑ antelope ÎÇ¥Ïö©: ['glintr100.onnx', 'scrfd_10g_bnkps.onnx']\n",
            "‚úÖ glintr100.onnx Ï°¥Ïû¨\n",
            "‚úÖ scrfd_10g_bnkps.onnx Ï°¥Ïû¨\n",
            "‚úÖ InsightFace Î™®Îç∏ Ïû¨ÏÑ§Ïπò ÏôÑÎ£å\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÏÉùÏÑ± Î∞è Î≥¥Í∞Ñ"
      ],
      "metadata": {
        "id": "KrMwYq9k3ZfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Îã®Í≥Ñ ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú"
      ],
      "metadata": {
        "id": "QlQtGSs23feG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú Ïà´Ïûê Ï∂îÏ∂ú (ÏòÅÏÉÅÍ≥º Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Ïö©)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "def extract_frames_all_videos(\n",
        "    video_dir=\"/content/input_videos\",\n",
        "    output_base_dir=\"/content/simswap_results\",\n",
        "    interval=5\n",
        "):\n",
        "    # Î™®Îì† mp4 ÌååÏùº Í≤ÄÏÉâ\n",
        "    video_files = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "    print(f\"Ï¥ù {len(video_files)}Í∞ú mp4 ÏòÅÏÉÅÏóêÏÑú ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏãúÏûë!\")\n",
        "\n",
        "    for video_path in video_files:\n",
        "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        number = extract_number_from_filename(video_name)\n",
        "        if number is None:\n",
        "            print(f\"  {video_path}: Ïà´Ïûê ÎØ∏Ìè¨Ìï®, Ïä§ÌÇµ\")\n",
        "            continue\n",
        "\n",
        "        # ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞: /content/simswap_results/pair_XXX_xxxx/extracted_frames/\n",
        "        pair_name = f\"pair_{number:03d}_{video_name}\"\n",
        "        pair_output_dir = os.path.join(output_base_dir, pair_name, \"extracted_frames\")\n",
        "        os.makedirs(pair_output_dir, exist_ok=True)\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"  {video_path}: Ïò§Ìîà Ïã§Ìå®, Ïä§ÌÇµ\")\n",
        "            continue\n",
        "\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        print(f\"  {video_name}({number}): {total_frames}ÌîÑÎ†àÏûÑ Ï§ë interval={interval}ÎßàÎã§ Ï∂îÏ∂ú\")\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "        with tqdm(total=total_frames, desc=f\"    {pair_name} ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                if frame_count % interval == 0:\n",
        "                    cv2.imwrite(os.path.join(pair_output_dir, f'frame_{saved_count:04d}.jpg'), frame)\n",
        "                    saved_count += 1\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"    >> Ï†ÄÏû•: {saved_count}Ïû• ÏôÑÎ£å ({pair_output_dir})\")\n",
        "    print(\"Î™®Îì† mp4 ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏôÑÎ£å.\")\n",
        "\n",
        "# Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú\n",
        "if __name__ == \"__main__\":\n",
        "    VIDEO_DIR = \"/content/input_videos\"\n",
        "    OUTPUT_DIR = \"/content/simswap_results\"\n",
        "    INTERVAL = 5\n",
        "    extract_frames_all_videos(VIDEO_DIR, OUTPUT_DIR, INTERVAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCmYO0Am3Qfr",
        "outputId": "748fa329-8977-431a-fa10-b5c95ee1b568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï¥ù 3Í∞ú mp4 ÏòÅÏÉÅÏóêÏÑú ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏãúÏûë!\n",
            "  0555(555): 460ÌîÑÎ†àÏûÑ Ï§ë interval=5ÎßàÎã§ Ï∂îÏ∂ú\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_555_0555 ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 460/460 [00:00<00:00, 1252.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> Ï†ÄÏû•: 92Ïû• ÏôÑÎ£å (/content/simswap_results/pair_555_0555/extracted_frames)\n",
            "  0556(556): 582ÌîÑÎ†àÏûÑ Ï§ë interval=5ÎßàÎã§ Ï∂îÏ∂ú\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_556_0556 ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 582/582 [00:00<00:00, 1315.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> Ï†ÄÏû•: 117Ïû• ÏôÑÎ£å (/content/simswap_results/pair_556_0556/extracted_frames)\n",
            "  0554(554): 457ÌîÑÎ†àÏûÑ Ï§ë interval=5ÎßàÎã§ Ï∂îÏ∂ú\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    pair_554_0554 ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 457/457 [00:00<00:00, 1164.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    >> Ï†ÄÏû•: 92Ïû• ÏôÑÎ£å (/content/simswap_results/pair_554_0554/extracted_frames)\n",
            "Î™®Îì† mp4 ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú ÏôÑÎ£å.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Îã®Í≥Ñ SimSwap ÏñºÍµ¥ ÍµêÏ≤¥"
      ],
      "metadata": {
        "id": "BqHzGI2a5A67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú Ïà´Ïûê Ï∂îÏ∂ú (ÏòÅÏÉÅÍ≥º Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Ïö©)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_video_image_pairs(frame_base_dir, image_dir):\n",
        "    \"\"\"Ï∂îÏ∂úÎêú ÌîÑÎ†àÏûÑÍ≥º Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎì§ÏùÑ Î≤àÌò∏Î°ú Îß§Ïπ≠\"\"\"\n",
        "    # ÌîÑÎ†àÏûÑ ÎîîÎ†âÌÜ†Î¶¨Îì§ Í≤ÄÏÉâ (pair_XXX_xxxx ÌòïÌÉú)\n",
        "    pair_dirs = glob(os.path.join(frame_base_dir, \"pair_*\"))\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎì§ Í≤ÄÏÉâ\n",
        "    image_files = glob(os.path.join(image_dir, \"*.jpg\")) + glob(os.path.join(image_dir, \"*.png\"))\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄÎ•º Î≤àÌò∏Î≥ÑÎ°ú ÎîïÏÖîÎÑàÎ¶¨ ÏÉùÏÑ±\n",
        "    image_dict = {}\n",
        "    for image_path in image_files:\n",
        "        filename = os.path.basename(image_path)\n",
        "        number = extract_number_from_filename(filename)\n",
        "        if number is not None:\n",
        "            image_dict[number] = image_path\n",
        "\n",
        "    # Îß§Ïπ≠ÎêòÎäî Ïåç Ï∞æÍ∏∞\n",
        "    pairs = []\n",
        "    for pair_dir in pair_dirs:\n",
        "        # pair_XXX_xxxxÏóêÏÑú Î≤àÌò∏ Ï∂îÏ∂ú\n",
        "        pair_name = os.path.basename(pair_dir)\n",
        "        number = extract_number_from_filename(pair_name)\n",
        "\n",
        "        if number is not None and number in image_dict:\n",
        "            frame_dir = os.path.join(pair_dir, \"extracted_frames\")\n",
        "            if os.path.exists(frame_dir):\n",
        "                pairs.append({\n",
        "                    'number': number,\n",
        "                    'pair_name': pair_name,\n",
        "                    'frame_dir': frame_dir,\n",
        "                    'image_path': image_dict[number],\n",
        "                    'swap_dir': os.path.join(pair_dir, \"swapped_frames\")\n",
        "                })\n",
        "\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def run_simswap_single_frame(source_img, target_img, result_subdir):\n",
        "    \"\"\"Îã®Ïùº ÌîÑÎ†àÏûÑÏóê ÎåÄÌïú SimSwap Ï≤òÎ¶¨\"\"\"\n",
        "    # SimSwap Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "    arcface_path = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "    checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "\n",
        "    # Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "    os.makedirs(result_subdir, exist_ok=True)\n",
        "\n",
        "    # SimSwap Ïã§Ìñâ Î™ÖÎ†π\n",
        "    cmd = [\n",
        "        'python', 'test_wholeimage_swapsingle.py',\n",
        "        '--crop_size', '224',\n",
        "        '--use_mask',\n",
        "        '--no_simswaplogo',\n",
        "        '--name', 'people',\n",
        "        '--Arc_path', arcface_path,\n",
        "        '--pic_a_path', source_img,\n",
        "        '--pic_b_path', target_img,\n",
        "        '--pic_specific_path', target_img,\n",
        "        '--output_path', result_subdir,\n",
        "        '--checkpoints_dir', checkpoints_dir\n",
        "    ]\n",
        "\n",
        "    # ÏõêÎûò ÎîîÎ†âÌÜ†Î¶¨ Ï†ÄÏû•\n",
        "    original_cwd = os.getcwd()\n",
        "\n",
        "    try:\n",
        "        # SimSwap ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥Îèô\n",
        "        os.chdir('/content/SimSwap')\n",
        "\n",
        "        # SimSwap Ïã§Ìñâ\n",
        "        result = subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Í≤∞Í≥º ÌååÏùº ÌôïÏù∏\n",
        "        result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "        return len(result_files) > 0\n",
        "\n",
        "    except Exception as e:\n",
        "        return False\n",
        "    finally:\n",
        "        # ÏõêÎûò ÎîîÎ†âÌÜ†Î¶¨Î°ú Î≥µÍ∑Ä\n",
        "        os.chdir(original_cwd)\n",
        "\n",
        "\n",
        "def process_single_pair_no_progress(pair_info, max_workers=4):\n",
        "    \"\"\"Îã®Ïùº ÏåçÏùò Î™®Îì† ÌîÑÎ†àÏûÑÏùÑ ÏßÑÌñâÎ∞î ÏóÜÏù¥ Î≥ëÎ†¨ Ï≤òÎ¶¨\"\"\"\n",
        "    source_img = pair_info['image_path']\n",
        "    frame_dir = pair_info['frame_dir']\n",
        "    swap_dir = pair_info['swap_dir']\n",
        "\n",
        "    # ÌîÑÎ†àÏûÑ ÌååÏùºÎì§ Í∞ÄÏ†∏Ïò§Í∏∞\n",
        "    frames = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "    total_frames = len(frames)\n",
        "\n",
        "    if total_frames == 0:\n",
        "        return False, 0, total_frames\n",
        "\n",
        "    # ÏûëÏóÖ Î™©Î°ù ÏÉùÏÑ±\n",
        "    tasks = []\n",
        "    for i, frame_name in enumerate(frames):\n",
        "        target_img = os.path.join(frame_dir, frame_name)\n",
        "        result_subdir = os.path.join(swap_dir, f'frame_{i:04d}')\n",
        "        tasks.append((source_img, target_img, result_subdir, i))\n",
        "\n",
        "    # Î≥ëÎ†¨ Ï≤òÎ¶¨ (ÏßÑÌñâÎ∞î ÏôÑÏ†Ñ Ï†úÍ±∞)\n",
        "    success_count = 0\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # ÏûëÏóÖ Ï†úÏ∂ú\n",
        "        futures = [executor.submit(run_simswap_single_frame, task[0], task[1], task[2]) for task in tasks]\n",
        "\n",
        "        # Í≤∞Í≥º ÏàòÏßë (ÏßÑÌñâÎ∞î ÏóÜÏù¥)\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                success = future.result()\n",
        "                if success:\n",
        "                    success_count += 1\n",
        "            except Exception:\n",
        "                pass  # ÏóêÎü¨ÎèÑ Ï°∞Ïö©Ìûà Î¨¥Ïãú\n",
        "\n",
        "    return success_count > 0, success_count, total_frames\n",
        "\n",
        "\n",
        "def simswap_all_pairs_parallel(\n",
        "    frame_base_dir=\"/content/simswap_results\",\n",
        "    image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "    max_workers_per_pair=4,\n",
        "    max_concurrent_pairs=2\n",
        "):\n",
        "    \"\"\"Î™®Îì† ÏåçÏóê ÎåÄÌï¥ Î≥ëÎ†¨ SimSwap Ï≤òÎ¶¨ - Ï†ÑÏ≤¥ ÏßÑÌñâÏÉÅÌô©Îßå ÌëúÏãú\"\"\"\n",
        "\n",
        "    # tqdm Ï†ÑÏó≠ ÎπÑÌôúÏÑ±Ìôî (ÌòπÏãú Î™®Î•º Îã§Î•∏ ÏßÑÌñâÎ∞îÎì§ÍπåÏßÄ Ï∞®Îã®)\n",
        "    import tqdm as tqdm_module\n",
        "    original_tqdm = tqdm_module.tqdm\n",
        "\n",
        "    def disabled_tqdm(*args, **kwargs):\n",
        "        kwargs['disable'] = True\n",
        "        return original_tqdm(*args, **kwargs)\n",
        "\n",
        "    tqdm_module.tqdm = disabled_tqdm\n",
        "\n",
        "    try:\n",
        "        # SimSwap ÌôòÍ≤Ω ÌôïÏù∏\n",
        "        if not os.path.exists('/content/SimSwap'):\n",
        "            print(\"‚ùå SimSwapÏù¥ ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Î®ºÏ†Ä SimSwapÏùÑ ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "            return\n",
        "\n",
        "        # Îß§Ïπ≠ÎêòÎäî Ïåç Ï∞æÍ∏∞\n",
        "        pairs = get_video_image_pairs(frame_base_dir, image_dir)\n",
        "\n",
        "        if not pairs:\n",
        "            print(\"‚ùå Îß§Ïπ≠ÎêòÎäî ÌîÑÎ†àÏûÑ-Ïù¥ÎØ∏ÏßÄ ÏåçÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!\")\n",
        "            return\n",
        "\n",
        "        # Ï¥àÍ∏∞ Ï†ïÎ≥¥Îßå Ï∂úÎ†•\n",
        "        print(f\"üéØ Ï¥ù {len(pairs)}Í∞ú Ïåç Ï≤òÎ¶¨ ÏãúÏûë (ÏåçÎãπ {max_workers_per_pair}ÏõåÏª§, ÎèôÏãú {max_concurrent_pairs}Ïåç)\")\n",
        "\n",
        "        # Ï†ÑÏ≤¥ ÏßÑÌñâÏÉÅÌô©ÏùÑ ÏúÑÌïú Î≥ÄÏàòÎì§\n",
        "        completed_pairs = 0\n",
        "        total_pairs = len(pairs)\n",
        "        lock = threading.Lock()\n",
        "\n",
        "        # Ï†ÑÏ≤¥ ÏßÑÌñâÎ∞î ÏÉùÏÑ± (ÏõêÎûò tqdm ÏÇ¨Ïö©)\n",
        "        overall_pbar = original_tqdm(total=total_pairs, desc=\"üîÑ SimSwap Ï≤òÎ¶¨\", unit=\"Ïåç\")\n",
        "\n",
        "        def process_pair_with_progress(pair):\n",
        "            \"\"\"Ïåç Ï≤òÎ¶¨ ÌõÑ Ï†ÑÏ≤¥ ÏßÑÌñâÎ∞î ÏóÖÎç∞Ïù¥Ìä∏\"\"\"\n",
        "            nonlocal completed_pairs\n",
        "\n",
        "            # ÏßÑÌñâÎ∞î ÏóÜÎäî Ìï®Ïàò ÏÇ¨Ïö©\n",
        "            success, success_frames, total_frames = process_single_pair_no_progress(pair, max_workers_per_pair)\n",
        "\n",
        "            # Ïä§Î†àÎìú ÏïàÏ†ÑÌïòÍ≤å ÏßÑÌñâÎ∞î ÏóÖÎç∞Ïù¥Ìä∏\n",
        "            with lock:\n",
        "                completed_pairs += 1\n",
        "                # ÏßÑÌñâÎ∞î Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏\n",
        "                overall_pbar.set_postfix({\n",
        "                    'ÏôÑÎ£å': f\"{completed_pairs}/{total_pairs}\",\n",
        "                    'ÌòÑÏû¨': pair['pair_name'][:12],  # Ïù¥Î¶Ñ Í∏∏Ïù¥ Ï†úÌïú\n",
        "                    'ÏÑ±Í≥µ': f\"{success_frames}/{total_frames}\" if total_frames > 0 else \"0/0\"\n",
        "                })\n",
        "                overall_pbar.update(1)\n",
        "\n",
        "            return success, pair\n",
        "\n",
        "        start_time = time.time()\n",
        "        success_count = 0\n",
        "\n",
        "        # ÏåçÎ≥ÑÎ°ú Î≥ëÎ†¨ Ï≤òÎ¶¨\n",
        "        with ThreadPoolExecutor(max_workers=max_concurrent_pairs) as executor:\n",
        "            # Î™®Îì† ÏåçÏóê ÎåÄÌïú ÏûëÏóÖ Ï†úÏ∂ú\n",
        "            futures = [executor.submit(process_pair_with_progress, pair) for pair in pairs]\n",
        "\n",
        "            # Í≤∞Í≥º ÏàòÏßë (Ï°∞Ïö©Ìûà)\n",
        "            for future in as_completed(futures):\n",
        "                try:\n",
        "                    success, pair = future.result()\n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                except Exception:\n",
        "                    # ÏóêÎü¨Í∞Ä Î∞úÏÉùÌï¥ÎèÑ ÏßÑÌñâÎ∞îÎäî Í≥ÑÏÜç ÏóÖÎç∞Ïù¥Ìä∏\n",
        "                    with lock:\n",
        "                        completed_pairs += 1\n",
        "                        overall_pbar.set_postfix({\n",
        "                            'ÏôÑÎ£å': f\"{completed_pairs}/{total_pairs}\",\n",
        "                            'ÏÉÅÌÉú': 'ÏóêÎü¨'\n",
        "                        })\n",
        "                        overall_pbar.update(1)\n",
        "\n",
        "        # ÏßÑÌñâÎ∞î Îã´Í∏∞\n",
        "        overall_pbar.close()\n",
        "\n",
        "        end_time = time.time()\n",
        "        total_duration = end_time - start_time\n",
        "\n",
        "        # ÏµúÏ¢Ö Í≤∞Í≥ºÎßå Ï∂úÎ†•\n",
        "        print(f\"üéä ÏôÑÎ£å! ÏÑ±Í≥µ: {success_count}/{len(pairs)}Í∞ú, ÏãúÍ∞Ñ: {total_duration:.1f}Ï¥à\")\n",
        "\n",
        "    finally:\n",
        "        # tqdm ÏõêÎûòÎåÄÎ°ú Î≥µÍµ¨\n",
        "        tqdm_module.tqdm = original_tqdm\n",
        "\n",
        "\n",
        "# Í∞úÎ≥Ñ ÏåçÎßå Ï≤òÎ¶¨ÌïòÍ≥† Ïã∂ÏùÑ Îïå ÏÇ¨Ïö©ÌïòÎäî Ìï®Ïàò\n",
        "def simswap_single_pair_only(pair_name, max_workers=4,\n",
        "                            frame_base_dir=\"/content/simswap_results\",\n",
        "                            image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\"):\n",
        "    \"\"\"ÌäπÏ†ï ÏåçÎßå Î≥ëÎ†¨Î°ú Ï≤òÎ¶¨\"\"\"\n",
        "    pairs = get_video_image_pairs(frame_base_dir, image_dir)\n",
        "\n",
        "    target_pair = None\n",
        "    for pair in pairs:\n",
        "        if pair['pair_name'] == pair_name:\n",
        "            target_pair = pair\n",
        "            break\n",
        "\n",
        "    if target_pair is None:\n",
        "        print(f\"‚ùå '{pair_name}' ÏåçÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!\")\n",
        "        return False\n",
        "\n",
        "    success, success_frames, total_frames = process_single_pair_no_progress(target_pair, max_workers)\n",
        "\n",
        "    if success:\n",
        "        print(f\"‚úÖ [{pair_name}] ÏôÑÎ£å: {success_frames}/{total_frames} ÌîÑÎ†àÏûÑ ÏÑ±Í≥µ\")\n",
        "    else:\n",
        "        print(f\"‚ùå [{pair_name}] Ïã§Ìå®\")\n",
        "\n",
        "    return success\n",
        "\n",
        "\n",
        "# Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú\n",
        "if __name__ == \"__main__\":\n",
        "    FRAME_BASE_DIR = \"/content/simswap_results\"\n",
        "    IMAGE_DIR = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "\n",
        "    simswap_all_pairs_parallel(\n",
        "        frame_base_dir=FRAME_BASE_DIR,\n",
        "        image_dir=IMAGE_DIR,\n",
        "        max_workers_per_pair=4,\n",
        "        max_concurrent_pairs=2\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a3hccpeB22m",
        "outputId": "5ba69d59-d361-459b-d39c-3c73731c7123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Ï¥ù 3Í∞ú Ïåç Ï≤òÎ¶¨ ÏãúÏûë (ÏåçÎãπ 4ÏõåÏª§, ÎèôÏãú 2Ïåç)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ SimSwap Ï≤òÎ¶¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [07:58<00:00, 159.60s/Ïåç, ÏôÑÎ£å=3/3, ÌòÑÏû¨=pair_556_055, ÏÑ±Í≥µ=117/117]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéä ÏôÑÎ£å! ÏÑ±Í≥µ: 3/3Í∞ú, ÏãúÍ∞Ñ: 478.8Ï¥à\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Îã®Í≥Ñ ÏòÅÏÉÅÏÉùÏÑ±"
      ],
      "metadata": {
        "id": "kcbawQB47hNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "\n",
        "\n",
        "def extract_number_from_filename(filename):\n",
        "    \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú Ïà´Ïûê Ï∂îÏ∂ú (ÏòÅÏÉÅÍ≥º Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Ïö©)\"\"\"\n",
        "    numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_swapped_pairs_info(frame_base_dir=\"/content/simswap_results\"):\n",
        "    \"\"\"SimSwap ÏôÑÎ£åÎêú ÏåçÎì§Ïùò Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞\"\"\"\n",
        "    pair_dirs = glob(os.path.join(frame_base_dir, \"pair_*\"))\n",
        "    pairs_info = []\n",
        "\n",
        "    for pair_dir in pair_dirs:\n",
        "        pair_name = os.path.basename(pair_dir)\n",
        "        number = extract_number_from_filename(pair_name)\n",
        "\n",
        "        if number is not None:\n",
        "            swap_dir = os.path.join(pair_dir, \"swapped_frames\")\n",
        "            if os.path.exists(swap_dir):\n",
        "                # Ïä§ÏôëÎêú ÌîÑÎ†àÏûÑ Í∞úÏàò ÌôïÏù∏\n",
        "                swap_subdirs = [d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))]\n",
        "                pairs_info.append({\n",
        "                    'number': number,\n",
        "                    'pair_name': pair_name,\n",
        "                    'pair_dir': pair_dir,\n",
        "                    'swap_dir': swap_dir,\n",
        "                    'frame_count': len(swap_subdirs)\n",
        "                })\n",
        "\n",
        "    return sorted(pairs_info, key=lambda x: x['number'])\n",
        "\n",
        "\n",
        "def create_video_from_swapped_frames(swap_dir, output_video, target_fps):\n",
        "    \"\"\"SimSwap Í≤∞Í≥º ÌîÑÎ†àÏûÑÎì§ÏùÑ ÎπÑÎîîÏò§Î°ú Î≥ÄÌôò\"\"\"\n",
        "    if not os.path.exists(swap_dir):\n",
        "        return False, \"swap_dirÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùå\"\n",
        "\n",
        "    # Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄÎì§ ÏàòÏßë\n",
        "    result_images = []\n",
        "    swap_subdirs = sorted([d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))])\n",
        "\n",
        "    if not swap_subdirs:\n",
        "        return False, \"Ïä§ÏôëÎêú ÌîÑÎ†àÏûÑ ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏùå\"\n",
        "\n",
        "    for subdir in swap_subdirs:\n",
        "        subdir_path = os.path.join(swap_dir, subdir)\n",
        "        result_files = [f for f in os.listdir(subdir_path) if f.endswith(('.jpg', '.png'))]\n",
        "        if result_files:\n",
        "            # Ï≤´ Î≤àÏß∏ Í≤∞Í≥º ÌååÏùº ÏÇ¨Ïö©\n",
        "            result_images.append(os.path.join(subdir_path, result_files[0]))\n",
        "\n",
        "    if not result_images:\n",
        "        return False, \"Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏùå\"\n",
        "\n",
        "    # Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎ°ú ÎπÑÎîîÏò§ ÌÅ¨Í∏∞ Í≤∞Ï†ï\n",
        "    first_img = cv2.imread(result_images[0])\n",
        "    if first_img is None:\n",
        "        return False, f\"Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎ•º ÏùΩÏùÑ Ïàò ÏóÜÏùå: {result_images[0]}\"\n",
        "\n",
        "    height, width, _ = first_img.shape\n",
        "\n",
        "    # ÎπÑÎîîÏò§ ÎùºÏù¥ÌÑ∞ ÏÑ§Ï†ï\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, target_fps, (width, height))\n",
        "\n",
        "    if not out.isOpened():\n",
        "        return False, f\"ÎπÑÎîîÏò§ ÎùºÏù¥ÌÑ∞Î•º Ïó¥ Ïàò ÏóÜÏùå: {output_video}\"\n",
        "\n",
        "    # ÌîÑÎ†àÏûÑÎì§ÏùÑ ÎπÑÎîîÏò§Î°ú ÏûëÏÑ±\n",
        "    success_frames = 0\n",
        "    for img_path in result_images:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None:\n",
        "            out.write(img)\n",
        "            success_frames += 1\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    if success_frames > 0:\n",
        "        return True, f\"ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏôÑÎ£å: {success_frames}ÌîÑÎ†àÏûÑ\"\n",
        "    else:\n",
        "        return False, \"ÌîÑÎ†àÏûÑÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏùå\"\n",
        "\n",
        "\n",
        "def process_single_pair_video_creation(pair_info, original_fps=30.0, frame_interval=5):\n",
        "    \"\"\"Îã®Ïùº ÏåçÏùò Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\"\"\"\n",
        "    swap_dir = pair_info['swap_dir']\n",
        "    pair_name = pair_info['pair_name']\n",
        "    pair_dir = pair_info['pair_dir']\n",
        "\n",
        "    # ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©Ïóê Îî∞Î•∏ FPS Í≥ÑÏÇ∞\n",
        "    base_fps = original_fps / frame_interval\n",
        "\n",
        "    # Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\n",
        "    base_video_path = os.path.join(pair_dir, f\"{pair_name}_base.mp4\")\n",
        "    success, message = create_video_from_swapped_frames(swap_dir, base_video_path, base_fps)\n",
        "\n",
        "    if success:\n",
        "        return True, f\"Í∏∞Î≥∏ ÎπÑÎîîÏò§: {base_video_path}\"\n",
        "    else:\n",
        "        return False, f\"ÎπÑÎîîÏò§ ÏÉùÏÑ± Ïã§Ìå®: {message}\"\n",
        "\n",
        "\n",
        "def create_videos_all_pairs_parallel(\n",
        "    frame_base_dir=\"/content/simswap_results\",\n",
        "    original_fps=30.0,\n",
        "    frame_interval=5,\n",
        "    max_workers=3\n",
        "):\n",
        "    \"\"\"Î™®Îì† ÏåçÏóê ÎåÄÌï¥ Î≥ëÎ†¨Î°ú Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\"\"\"\n",
        "\n",
        "    # ÏôÑÎ£åÎêú ÏåçÎì§ Ï∞æÍ∏∞\n",
        "    pairs = get_swapped_pairs_info(frame_base_dir)\n",
        "\n",
        "    if not pairs:\n",
        "        print(\"‚ùå SimSwapÏù¥ ÏôÑÎ£åÎêú ÏåçÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!\")\n",
        "        print(f\"ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏: {frame_base_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"üé¨ Ï¥ù {len(pairs)}Í∞ú ÏåçÏùò Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë!\")\n",
        "    print(f\"‚öôÔ∏è ÏÑ§Ï†ï: ÏõêÎ≥∏ FPS={original_fps}, ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©={frame_interval}, ÏõåÏª§={max_workers}Í∞ú\")\n",
        "\n",
        "    # Ï†ÑÏ≤¥ ÏßÑÌñâÏÉÅÌô©ÏùÑ ÏúÑÌïú Î≥ÄÏàòÎì§\n",
        "    completed_pairs = 0\n",
        "    total_pairs = len(pairs)\n",
        "    lock = threading.Lock()\n",
        "\n",
        "    # Ï†ÑÏ≤¥ ÏßÑÌñâÎ∞î ÏÉùÏÑ±\n",
        "    overall_pbar = tqdm(total=total_pairs, desc=\"üé• ÎπÑÎîîÏò§ ÏÉùÏÑ±\", unit=\"Ïåç\")\n",
        "\n",
        "    def process_pair_with_progress(pair):\n",
        "        \"\"\"Ïåç Ï≤òÎ¶¨ ÌõÑ Ï†ÑÏ≤¥ ÏßÑÌñâÎ∞î ÏóÖÎç∞Ïù¥Ìä∏\"\"\"\n",
        "        nonlocal completed_pairs\n",
        "\n",
        "        success, message = process_single_pair_video_creation(pair, original_fps, frame_interval)\n",
        "\n",
        "        # Ïä§Î†àÎìú ÏïàÏ†ÑÌïòÍ≤å ÏßÑÌñâÎ∞î ÏóÖÎç∞Ïù¥Ìä∏\n",
        "        with lock:\n",
        "            completed_pairs += 1\n",
        "            overall_pbar.set_postfix({\n",
        "                'ÏôÑÎ£å': f\"{completed_pairs}/{total_pairs}\",\n",
        "                'ÌòÑÏû¨': pair['pair_name'][:12],\n",
        "                'ÌîÑÎ†àÏûÑ': f\"{pair['frame_count']}Í∞ú\"\n",
        "            })\n",
        "            overall_pbar.update(1)\n",
        "\n",
        "        return success, pair, message\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    # Î≥ëÎ†¨ Ï≤òÎ¶¨\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # Î™®Îì† ÏåçÏóê ÎåÄÌïú ÏûëÏóÖ Ï†úÏ∂ú\n",
        "        futures = [executor.submit(process_pair_with_progress, pair) for pair in pairs]\n",
        "\n",
        "        # Í≤∞Í≥º ÏàòÏßë\n",
        "        for future in as_completed(futures):\n",
        "            try:\n",
        "                success, pair, message = future.result()\n",
        "                if success:\n",
        "                    success_count += 1\n",
        "            except Exception as e:\n",
        "                # ÏóêÎü¨Í∞Ä Î∞úÏÉùÌï¥ÎèÑ ÏßÑÌñâÎ∞îÎäî Í≥ÑÏÜç ÏóÖÎç∞Ïù¥Ìä∏\n",
        "                with lock:\n",
        "                    completed_pairs += 1\n",
        "                    overall_pbar.set_postfix({\n",
        "                        'ÏôÑÎ£å': f\"{completed_pairs}/{total_pairs}\",\n",
        "                        'ÏÉÅÌÉú': 'ÏóêÎü¨'\n",
        "                    })\n",
        "                    overall_pbar.update(1)\n",
        "\n",
        "    # ÏßÑÌñâÎ∞î Îã´Í∏∞\n",
        "    overall_pbar.close()\n",
        "\n",
        "    print(f\"\\nüéä Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
        "    print(f\"üìä ÏÑ±Í≥µ: {success_count}/{len(pairs)}Í∞ú\")\n",
        "    print(f\"üìÅ Í≤∞Í≥º ÏúÑÏπò: {frame_base_dir}\")\n",
        "    print(f\"üí° Îã§Ïùå Îã®Í≥Ñ: ÌîÑÎ†àÏûÑ Î≥¥Í∞ÑÏùÑ ÏõêÌïúÎã§Î©¥ Î≥ÑÎèÑ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ïã§ÌñâÌïòÏÑ∏Ïöî\")\n",
        "\n",
        "\n",
        "# Í∞úÎ≥Ñ ÏåçÎßå Ï≤òÎ¶¨ÌïòÍ≥† Ïã∂ÏùÑ Îïå ÏÇ¨Ïö©ÌïòÎäî Ìï®Ïàò\n",
        "def create_single_pair_video_only(pair_name, original_fps=30.0, frame_interval=5,\n",
        "                                 frame_base_dir=\"/content/simswap_results\"):\n",
        "    \"\"\"ÌäπÏ†ï ÏåçÎßå Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\"\"\"\n",
        "    pairs = get_swapped_pairs_info(frame_base_dir)\n",
        "\n",
        "    target_pair = None\n",
        "    for pair in pairs:\n",
        "        if pair['pair_name'] == pair_name:\n",
        "            target_pair = pair\n",
        "            break\n",
        "\n",
        "    if target_pair is None:\n",
        "        print(f\"‚ùå '{pair_name}' ÏåçÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!\")\n",
        "        return False\n",
        "\n",
        "    print(f\"üé¨ [{pair_name}] Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë...\")\n",
        "    success, message = process_single_pair_video_creation(target_pair, original_fps, frame_interval)\n",
        "\n",
        "    if success:\n",
        "        print(f\"‚úÖ [{pair_name}] {message}\")\n",
        "    else:\n",
        "        print(f\"‚ùå [{pair_name}] {message}\")\n",
        "\n",
        "    return success\n",
        "\n",
        "\n",
        "# Ïã§Ï†ú ÏÇ¨Ïö© ÏòàÏãú\n",
        "if __name__ == \"__main__\":\n",
        "    FRAME_BASE_DIR = \"/content/simswap_results\"  # SimSwap Í≤∞Í≥ºÍ∞Ä ÏûàÎäî ÎîîÎ†âÌÜ†Î¶¨\n",
        "    ORIGINAL_FPS = 30.0  # ÏõêÎ≥∏ ÎπÑÎîîÏò§Ïùò FPS\n",
        "    FRAME_INTERVAL = 5   # ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú Ïãú ÏÇ¨Ïö©Ìïú Í∞ÑÍ≤©\n",
        "    MAX_WORKERS = 3      # Î≥ëÎ†¨ Ï≤òÎ¶¨ ÏõåÏª§ Ïàò\n",
        "\n",
        "    print(\"=== SimSwap 3Îã®Í≥Ñ: Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë ===\")\n",
        "    print(f\"Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨: {FRAME_BASE_DIR}\")\n",
        "    print(f\"ÏõêÎ≥∏ FPS: {ORIGINAL_FPS}\")\n",
        "    print(f\"ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©: {FRAME_INTERVAL}\")\n",
        "\n",
        "    # Î™®Îì† ÏåçÏùò Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\n",
        "    create_videos_all_pairs_parallel(\n",
        "        frame_base_dir=FRAME_BASE_DIR,\n",
        "        original_fps=ORIGINAL_FPS,\n",
        "        frame_interval=FRAME_INTERVAL,\n",
        "        max_workers=MAX_WORKERS\n",
        "    )\n",
        "\n",
        "    # ÌäπÏ†ï ÏåçÎßå Ï≤òÎ¶¨ÌïòÍ≥† Ïã∂Îã§Î©¥:\n",
        "    # create_single_pair_video_only(\"pair_001_video1\", original_fps=30.0, frame_interval=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kBtx7_B7usw",
        "outputId": "8372f49e-7859-4eb3-bc21-cbc4b5014ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SimSwap 3Îã®Í≥Ñ: Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë ===\n",
            "Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨: /content/simswap_results\n",
            "ÏõêÎ≥∏ FPS: 30.0\n",
            "ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©: 5\n",
            "üé¨ Ï¥ù 3Í∞ú ÏåçÏùò Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë!\n",
            "‚öôÔ∏è ÏÑ§Ï†ï: ÏõêÎ≥∏ FPS=30.0, ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©=5, ÏõåÏª§=3Í∞ú\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üé• ÎπÑÎîîÏò§ ÏÉùÏÑ±: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.61Ïåç/s, ÏôÑÎ£å=3/3, ÌòÑÏû¨=pair_556_055, ÌîÑÎ†àÏûÑ=117Í∞ú]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéä Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏôÑÎ£å!\n",
            "üìä ÏÑ±Í≥µ: 3/3Í∞ú\n",
            "üìÅ Í≤∞Í≥º ÏúÑÏπò: /content/simswap_results\n",
            "üí° Îã§Ïùå Îã®Í≥Ñ: ÌîÑÎ†àÏûÑ Î≥¥Í∞ÑÏùÑ ÏõêÌïúÎã§Î©¥ Î≥ÑÎèÑ Ïä§ÌÅ¨Î¶ΩÌä∏Î•º Ïã§ÌñâÌïòÏÑ∏Ïöî\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/hzwer/Practical-RIFE.git\n",
        "%cd Practical-RIFE\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -q gdown opencv-python numpy tqdm\n",
        "\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS/view\" -O RIFE_trained_model_HDv3.zip\n",
        "!unzip -q RIFE_trained_model_HDv3.zip\n",
        "!mv RIFEv4.21/train_log ./\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxHCP9w7aVzs",
        "outputId": "c25bcac0-2941-4931-bc2d-dbf9189e2430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Practical-RIFE' already exists and is not an empty directory.\n",
            "/content/Practical-RIFE\n",
            "Requirement already satisfied: numpy<=1.23.5,>=1.16 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: sk-video>=1.1.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.1.10)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.15.2+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sk-video>=1.1.10->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (15.0.7)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.34.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.7.0->-r requirements.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS\n",
            "From (redirected): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS&confirm=t&uuid=7e83813f-d126-4471-8a50-cf4ccc028ca6\n",
            "To: /content/Practical-RIFE/RIFE_trained_model_HDv3.zip\n",
            "100% 38.1M/38.1M [00:00<00:00, 142MB/s]\n",
            "replace __MACOSX/._RIFEv4.21? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "mv: cannot move 'RIFEv4.21/train_log' to './train_log': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Îã®Í≥Ñ Î≥¥Í∞Ñ\n"
      ],
      "metadata": {
        "id": "MSzZjJ9YHUMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import subprocess\n",
        "import cv2\n",
        "\n",
        "RIFE_DIR = \"/content/Practical-RIFE\"\n",
        "SIMSWAP_RESULT_DIR = \"/content/simswap_results\"\n",
        "TARGET_FPS = 30\n",
        "CUDA_DEVICE = \"0\"\n",
        "\n",
        "def interpolate_video_rife(input_path, output_path, fps=30):\n",
        "    cmd = [\n",
        "        \"python\", \"inference_video.py\",\n",
        "        \"--video\", input_path,\n",
        "        \"--output\", output_path,\n",
        "        \"--fps\", str(fps),\n",
        "    ]\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = CUDA_DEVICE\n",
        "    result = subprocess.run(cmd, cwd=RIFE_DIR, capture_output=True, text=True)\n",
        "    return result.returncode == 0, result.stdout.strip(), result.stderr.strip()\n",
        "\n",
        "def match_video_duration(original_path, input_path, output_path):\n",
        "    \"\"\"ÏõêÎ≥∏ ÏòÅÏÉÅ Í∏∏Ïù¥Ïóê ÎßûÏ∂∞ RIFE Î≥¥Í∞Ñ ÏòÅÏÉÅÏùò ÏÜçÎèÑ Ï°∞Ï†ï\"\"\"\n",
        "    original_cap = cv2.VideoCapture(original_path)\n",
        "    input_cap = cv2.VideoCapture(input_path)\n",
        "\n",
        "    original_duration = original_cap.get(cv2.CAP_PROP_FRAME_COUNT) / original_cap.get(cv2.CAP_PROP_FPS)\n",
        "    input_duration = input_cap.get(cv2.CAP_PROP_FRAME_COUNT) / input_cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    original_cap.release()\n",
        "    input_cap.release()\n",
        "\n",
        "    if input_duration == 0:\n",
        "        print(f\"‚ö†Ô∏è {input_path} Í∏∏Ïù¥ Í≥ÑÏÇ∞ Ïã§Ìå®\")\n",
        "        return False\n",
        "\n",
        "    # ‚ùó Ï§ëÏöî: ÏõêÎûò Í∏∏Ïù¥Ïóê ÎßûÏ∂∞ ÎäêÎ¶¨Í≤å Ïû¨ÏÉù\n",
        "    speed_ratio = original_duration / input_duration\n",
        "\n",
        "    # ffmpegÎ°ú Ïû¨ÏÉù ÏãúÍ∞Ñ ÎßûÏ∂îÍ∏∞\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-i\", input_path,\n",
        "        \"-filter:v\", f\"setpts={speed_ratio}*PTS\",\n",
        "        \"-an\",\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(cmd, capture_output=True)\n",
        "    return os.path.exists(output_path)\n",
        "\n",
        "# base.mp4 ÌååÏùº Î™©Î°ù\n",
        "base_videos = sorted(glob(os.path.join(SIMSWAP_RESULT_DIR, \"pair_*\", \"*_base.mp4\")))\n",
        "\n",
        "if not base_videos:\n",
        "    print(\"‚ùå base.mp4 ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "else:\n",
        "    print(f\"üé¨ Ï¥ù {len(base_videos)}Í∞ú base.mp4Ïóê ÎåÄÌï¥ RIFE Î≥¥Í∞Ñ ÏãúÏûë\")\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    for base_video in tqdm(base_videos, desc=\"üåÄ RIFE Î≥¥Í∞Ñ Ï§ë\", unit=\"Ïåç\"):\n",
        "        pair_dir = os.path.dirname(base_video)\n",
        "        pair_name = os.path.basename(base_video).replace(\"_base.mp4\", \"\")\n",
        "        rife_raw = os.path.join(pair_dir, f\"{pair_name}_rife_raw.mp4\")\n",
        "        rife_final = os.path.join(pair_dir, f\"{pair_name}_rife.mp4\")\n",
        "\n",
        "        if os.path.exists(rife_final):\n",
        "            print(f\"‚úÖ {pair_name}: Ïù¥ÎØ∏ Î≥¥Í∞ÑÎê®, Í±¥ÎÑàÎúÄ\")\n",
        "            success_count += 1\n",
        "            continue\n",
        "\n",
        "        ok, out, err = interpolate_video_rife(base_video, rife_raw, TARGET_FPS)\n",
        "\n",
        "        if ok and os.path.exists(rife_raw):\n",
        "            # Ïû¨ÏÉù ÏãúÍ∞Ñ ÎßûÏ∂∞ ÏÜçÎèÑ Ï°∞Ï†ï\n",
        "            if match_video_duration(base_video, rife_raw, rife_final):\n",
        "                os.remove(rife_raw)\n",
        "                print(f\"‚úÖ {pair_name}: Î≥¥Í∞Ñ + ÏãúÍ∞ÑÏ°∞Ï†ï ÏôÑÎ£å\")\n",
        "                success_count += 1\n",
        "            else:\n",
        "                print(f\"‚ùå {pair_name}: ÏãúÍ∞Ñ Ï°∞Ï†ï Ïã§Ìå®\")\n",
        "        else:\n",
        "            print(f\"‚ùå {pair_name}: Î≥¥Í∞Ñ Ïã§Ìå®\\n{err}\")\n",
        "\n",
        "    print(f\"\\nüéâ ÏôÑÎ£å: {success_count}/{len(base_videos)}Í∞ú Î≥¥Í∞Ñ ÏÑ±Í≥µ\")"
      ],
      "metadata": {
        "id": "E3y94iLJHXJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e95a1d2-15ac-4d9b-e044-f9089cc664fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ Ï¥ù 3Í∞ú base.mp4Ïóê ÎåÄÌï¥ RIFE Î≥¥Í∞Ñ ÏãúÏûë\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üåÄ RIFE Î≥¥Í∞Ñ Ï§ë:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:06<00:13,  6.90s/Ïåç]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_554_0554: Î≥¥Í∞Ñ + ÏãúÍ∞ÑÏ°∞Ï†ï ÏôÑÎ£å\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rüåÄ RIFE Î≥¥Í∞Ñ Ï§ë:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:13<00:06,  6.76s/Ïåç]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_555_0555: Î≥¥Í∞Ñ + ÏãúÍ∞ÑÏ°∞Ï†ï ÏôÑÎ£å\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üåÄ RIFE Î≥¥Í∞Ñ Ï§ë: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:20<00:00,  6.98s/Ïåç]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ pair_556_0556: Î≥¥Í∞Ñ + ÏãúÍ∞ÑÏ°∞Ï†ï ÏôÑÎ£å\n",
            "\n",
            "üéâ ÏôÑÎ£å: 3/3Í∞ú Î≥¥Í∞Ñ ÏÑ±Í≥µ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ÏöîÍ±¥ Í∏∞Ï°¥ ÌååÏù¥ÌîÑ ÎùºÏù∏"
      ],
      "metadata": {
        "id": "6MV6dYClHXbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import subprocess\n",
        "import os\n",
        "from glob import glob\n",
        "import sys\n",
        "import warnings\n",
        "import re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Î°úÍ∑∏ Ï†ïÎ¶¨\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "\n",
        "class SimSwapAutoPipeline:\n",
        "    def __init__(self):\n",
        "        self.setup_simswap()\n",
        "\n",
        "    def setup_simswap(self):\n",
        "        \"\"\"SimSwap ÌôòÍ≤Ω ÏÑ§Ï†ï\"\"\"\n",
        "        print(\"üîß SimSwap ÌôòÍ≤Ω ÏÑ§Ï†ï Ï§ë...\")\n",
        "\n",
        "        # SimSwap ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥Îèô\n",
        "        if not os.path.exists('/content/SimSwap'):\n",
        "            print(\"‚ùå SimSwapÏù¥ ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Î®ºÏ†Ä SimSwapÏùÑ ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî.\")\n",
        "            return False\n",
        "\n",
        "        os.chdir('/content/SimSwap')\n",
        "\n",
        "        # ÌïÑÏöîÌïú Í≤ΩÎ°úÎì§\n",
        "        self.arcface_path = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "        self.checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "\n",
        "        print(\"‚úÖ SimSwap ÌôòÍ≤Ω ÏÑ§Ï†ï ÏôÑÎ£å\")\n",
        "        return True\n",
        "\n",
        "    def extract_number_from_filename(self, filename):\n",
        "        \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú Ïà´Ïûê Ï∂îÏ∂ú (ÏòÅÏÉÅÍ≥º Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Ïö©)\"\"\"\n",
        "        numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "        if numbers:\n",
        "            return int(numbers[0])\n",
        "        return None\n",
        "\n",
        "    def get_video_image_pairs(self, video_dir, image_dir):\n",
        "        \"\"\"ÏòÅÏÉÅÍ≥º Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎì§ÏùÑ Î≤àÌò∏Î°ú Îß§Ïπ≠\"\"\"\n",
        "        video_files = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "        image_files = glob(os.path.join(image_dir, \"*.jpg\")) + glob(os.path.join(image_dir, \"*.png\"))\n",
        "\n",
        "        # ÌååÏùºÎ™ÖÏóêÏÑú Î≤àÌò∏ Ï∂îÏ∂úÌïòÏó¨ ÎîïÏÖîÎÑàÎ¶¨ ÏÉùÏÑ±\n",
        "        video_dict = {}\n",
        "        for video_path in video_files:\n",
        "            filename = os.path.basename(video_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                video_dict[number] = video_path\n",
        "\n",
        "        image_dict = {}\n",
        "        for image_path in image_files:\n",
        "            filename = os.path.basename(image_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                image_dict[number] = image_path\n",
        "\n",
        "        # Îß§Ïπ≠ÎêòÎäî Ïåç Ï∞æÍ∏∞\n",
        "        pairs = []\n",
        "        for number in sorted(set(video_dict.keys()) & set(image_dict.keys())):\n",
        "            pairs.append({\n",
        "                'number': number,\n",
        "                'video_path': video_dict[number],\n",
        "                'image_path': image_dict[number],\n",
        "                'video_name': os.path.splitext(os.path.basename(video_dict[number]))[0],\n",
        "                'image_name': os.path.splitext(os.path.basename(image_dict[number]))[0]\n",
        "            })\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def extract_frames(self, video_path, frame_dir, interval=5):\n",
        "        \"\"\"ÎπÑÎîîÏò§ÏóêÏÑú ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            return None, None\n",
        "\n",
        "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        new_fps = original_fps / interval\n",
        "\n",
        "        os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"  ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                if frame_count % interval == 0:\n",
        "                    cv2.imwrite(os.path.join(frame_dir, f'frame_{saved_count:04d}.jpg'), frame)\n",
        "                    saved_count += 1\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        return original_fps, new_fps\n",
        "\n",
        "\n",
        "    def run_simswap_on_frames(self, source_img, frame_dir, swap_dir):\n",
        "        \"\"\"SimSwapÏúºÎ°ú ÌîÑÎ†àÏûÑÎì§ Ï≤òÎ¶¨ - ÏóêÎü¨ Ï≤¥ÌÅ¨ Ï∂îÍ∞Ä\"\"\"\n",
        "        frames = sorted([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "        total_frames = len(frames)\n",
        "\n",
        "        os.makedirs(swap_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"     ÏÜåÏä§ Ïù¥ÎØ∏ÏßÄ: {source_img}\")\n",
        "        print(f\"     ÏÜåÏä§ Ïù¥ÎØ∏ÏßÄ Ï°¥Ïû¨: {os.path.exists(source_img)}\")\n",
        "\n",
        "        success_count = 0\n",
        "\n",
        "        with tqdm(total=total_frames, desc=\"  SimSwap Ï≤òÎ¶¨\") as pbar:\n",
        "            for i, frame_name in enumerate(frames):\n",
        "                target_img = os.path.join(frame_dir, frame_name)\n",
        "                result_subdir = os.path.join(swap_dir, f'frame_{i:04d}')\n",
        "                os.makedirs(result_subdir, exist_ok=True)\n",
        "\n",
        "                # SimSwap Ïã§Ìñâ (ÏóêÎü¨ Ï≤¥ÌÅ¨ Ìè¨Ìï®)\n",
        "                cmd = [\n",
        "                    'python', 'test_wholeimage_swapsingle.py',\n",
        "                    '--crop_size', '224',\n",
        "                    '--use_mask',\n",
        "                    '--no_simswaplogo',\n",
        "                    '--name', 'people',\n",
        "                    '--Arc_path', self.arcface_path,\n",
        "                    '--pic_a_path', source_img,\n",
        "                    '--pic_b_path', target_img,\n",
        "                    '--pic_specific_path', target_img,\n",
        "                    '--output_path', result_subdir,\n",
        "                    '--checkpoints_dir', self.checkpoints_dir\n",
        "                ]\n",
        "\n",
        "                # Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑÏùÄ ÏóêÎü¨ Ï≤¥ÌÅ¨\n",
        "                if i == 0:\n",
        "                    print(f\"     Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑ ÌÖåÏä§Ìä∏ Ï§ë...\")\n",
        "                    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "                    if result.returncode != 0:\n",
        "                        print(f\"     ‚ùå SimSwap ÏóêÎü¨:\")\n",
        "                        print(f\"     stderr: {result.stderr[:500]}\")\n",
        "                        print(f\"     stdout: {result.stdout[:500]}\")\n",
        "                    else:\n",
        "                        print(f\"     ‚úÖ Ï≤´ Î≤àÏß∏ ÌîÑÎ†àÏûÑ ÏÑ±Í≥µ\")\n",
        "\n",
        "                    # Í≤∞Í≥º ÌååÏùº ÌôïÏù∏\n",
        "                    result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "                    print(f\"     ÏÉùÏÑ±Îêú ÌååÏùº: {result_files}\")\n",
        "\n",
        "                    if result_files:\n",
        "                        success_count += 1\n",
        "\n",
        "                    # ÎÇòÎ®∏ÏßÄÎäî Ï°∞Ïö©Ìûà Ï≤òÎ¶¨\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "                # ÎÇòÎ®∏ÏßÄ ÌîÑÎ†àÏûÑÎì§\n",
        "                subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "                # Í≤∞Í≥º ÌååÏùº ÌôïÏù∏\n",
        "                result_files = [f for f in os.listdir(result_subdir) if f.endswith(('.jpg', '.png'))]\n",
        "                if result_files:\n",
        "                    success_count += 1\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        print(f\"     ÏÑ±Í≥µÌïú ÌîÑÎ†àÏûÑ: {success_count}/{total_frames}\")\n",
        "        return success_count > 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_video_from_swapped_results(self, swap_dir, output_video, target_fps):\n",
        "        \"\"\"SimSwap Í≤∞Í≥ºÎ•º ÎπÑÎîîÏò§Î°ú Î≥ÄÌôò\"\"\"\n",
        "        print(f\"     swap_dir ÌôïÏù∏: {swap_dir}\")\n",
        "\n",
        "        if not os.path.exists(swap_dir):\n",
        "            print(f\"     ‚ùå swap_dirÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùå: {swap_dir}\")\n",
        "            return False\n",
        "\n",
        "        result_images = []\n",
        "        swap_subdirs = sorted([d for d in os.listdir(swap_dir) if os.path.isdir(os.path.join(swap_dir, d))])\n",
        "        print(f\"     Î∞úÍ≤¨Îêú ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨: {len(swap_subdirs)}Í∞ú\")\n",
        "\n",
        "        for subdir in swap_subdirs:\n",
        "            subdir_path = os.path.join(swap_dir, subdir)\n",
        "            result_files = [f for f in os.listdir(subdir_path) if f.endswith(('.jpg', '.png'))]\n",
        "            print(f\"     {subdir}: {len(result_files)}Í∞ú ÌååÏùº\")\n",
        "            if result_files:\n",
        "                result_images.append(os.path.join(subdir_path, result_files[0]))\n",
        "\n",
        "        print(f\"     Ï¥ù ÏàòÏßëÎêú Ïù¥ÎØ∏ÏßÄ: {len(result_images)}Í∞ú\")\n",
        "\n",
        "        if not result_images:\n",
        "            print(\"     ‚ùå Í≤∞Í≥º Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏùå\")\n",
        "            return False\n",
        "\n",
        "        first_img = cv2.imread(result_images[0])\n",
        "        if first_img is None:\n",
        "            print(f\"     ‚ùå Ï≤´ Î≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎ•º ÏùΩÏùÑ Ïàò ÏóÜÏùå: {result_images[0]}\")\n",
        "            return False\n",
        "\n",
        "        height, width, _ = first_img.shape\n",
        "        print(f\"     ÎπÑÎîîÏò§ ÌÅ¨Í∏∞: {width}x{height}, FPS: {target_fps}\")\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video, fourcc, target_fps, (width, height))\n",
        "\n",
        "        if not out.isOpened():\n",
        "            print(f\"     ‚ùå ÎπÑÎîîÏò§ ÎùºÏù¥ÌÑ∞Î•º Ïó¥ Ïàò ÏóÜÏùå: {output_video}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"     ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏãúÏûë...\")\n",
        "        with tqdm(total=len(result_images), desc=\"  ÎπÑÎîîÏò§ ÏÉùÏÑ±\") as pbar:\n",
        "            for img_path in result_images:\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    out.write(img)\n",
        "                else:\n",
        "                    print(f\"     ‚ö†Ô∏è Ïù¥ÎØ∏ÏßÄ ÏùΩÍ∏∞ Ïã§Ìå®: {img_path}\")\n",
        "                pbar.update(1)\n",
        "\n",
        "        out.release()\n",
        "        print(f\"     ‚úÖ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏôÑÎ£å: {output_video}\")\n",
        "        return True\n",
        "\n",
        "    def interpolate_video(self, input_video, output_video, target_fps):\n",
        "        \"\"\"FFmpegÎ•º ÏÇ¨Ïö©Ìïú ÌîÑÎ†àÏûÑ Î≥¥Í∞Ñ\"\"\"\n",
        "        print(f\"  Î≥¥Í∞Ñ ÏãúÏûë: {target_fps:.1f}FPSÎ°ú Î≥ÄÌôò Ï§ë...\")\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci:mc_mode=aobmc:vsbmc=1',\n",
        "            '-c:v', 'libx264', '-crf', '23', '-preset', 'medium',\n",
        "            '-y', output_video\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                print(f\"  ‚úÖ Î≥¥Í∞Ñ ÏôÑÎ£å: {output_video}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"  ‚ùå Î≥¥Í∞Ñ Ïã§Ìå®\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Î≥¥Í∞Ñ Ï§ë Ïò§Î•ò: {e}\")\n",
        "            return False\n",
        "\n",
        "    def process_single_pair(self, video_path, source_image_path, output_dir, frame_interval=5):\n",
        "        \"\"\"Îã®Ïùº ÏòÅÏÉÅ-Ïù¥ÎØ∏ÏßÄ Ïåç Ï≤òÎ¶¨\"\"\"\n",
        "        # ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
        "        frame_dir = os.path.join(output_dir, \"extracted_frames\")\n",
        "        swap_dir = os.path.join(output_dir, \"swapped_frames\")\n",
        "\n",
        "        # 1. ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú\n",
        "        print(\"  1. ÌîÑÎ†àÏûÑ Ï∂îÏ∂ú Ï§ë...\")\n",
        "        original_fps, new_fps = self.extract_frames(video_path, frame_dir, frame_interval)\n",
        "        if original_fps is None:\n",
        "            return False\n",
        "\n",
        "        print(f\"     ÏõêÎ≥∏ FPS: {original_fps:.1f} ‚Üí ÏÉà FPS: {new_fps:.1f}\")\n",
        "\n",
        "        # 2. SimSwap Ï≤òÎ¶¨\n",
        "        print(\"  2. SimSwap ÏñºÍµ¥ ÍµêÏ≤¥ Ï§ë...\")\n",
        "        self.run_simswap_on_frames(source_image_path, frame_dir, swap_dir)\n",
        "\n",
        "        # 3. Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ±\n",
        "        print(\"  3. Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÉùÏÑ± Ï§ë...\")\n",
        "        base_video_path = os.path.join(output_dir, \"base_video.mp4\")\n",
        "        if not self.create_video_from_swapped_results(swap_dir, base_video_path, new_fps):\n",
        "            return False\n",
        "\n",
        "        return True, original_fps, new_fps, base_video_path\n",
        "\n",
        "    def process_all_pairs(self, video_dir=\"/content/input_videos\",\n",
        "                         image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "                         output_base_dir=\"/content/simswap_results\",\n",
        "                         frame_interval=5, use_interpolation=True):\n",
        "        \"\"\"Î™®Îì† ÏòÅÏÉÅ-Ïù¥ÎØ∏ÏßÄ Ïåç ÏûêÎèô Ï≤òÎ¶¨\"\"\"\n",
        "\n",
        "        # Îß§Ïπ≠ÎêòÎäî Ïåç Ï∞æÍ∏∞\n",
        "        pairs = self.get_video_image_pairs(video_dir, image_dir)\n",
        "\n",
        "        if not pairs:\n",
        "            print(\"‚ùå Îß§Ïπ≠ÎêòÎäî ÏòÅÏÉÅ-Ïù¥ÎØ∏ÏßÄ ÏåçÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!\")\n",
        "            print(f\"ÏòÅÏÉÅ ÎîîÎ†âÌÜ†Î¶¨: {video_dir}\")\n",
        "            print(f\"Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨: {image_dir}\")\n",
        "            return\n",
        "\n",
        "        print(f\"üéØ Ï¥ù {len(pairs)}Í∞úÏùò Îß§Ïπ≠ ÏåçÏùÑ Ï∞æÏïòÏäµÎãàÎã§!\")\n",
        "\n",
        "        # Í∏∞Î≥∏ Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "        os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "        success_count = 0\n",
        "\n",
        "        for i, pair in enumerate(pairs, 1):\n",
        "            print(f\"\\n[{i}/{len(pairs)}] Ï≤òÎ¶¨ Ï§ë...\")\n",
        "            print(f\"  ÏòÅÏÉÅ: {os.path.basename(pair['video_path'])}\")\n",
        "            print(f\"  Ïù¥ÎØ∏ÏßÄ: {os.path.basename(pair['image_path'])}\")\n",
        "\n",
        "            # Í∞úÎ≥Ñ Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "            pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "            pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "\n",
        "            try:\n",
        "                # 1. SimSwap Ï≤òÎ¶¨\n",
        "                result = self.process_single_pair(\n",
        "                    pair['video_path'],\n",
        "                    pair['image_path'],\n",
        "                    pair_output_dir,\n",
        "                    frame_interval\n",
        "                )\n",
        "\n",
        "                if not result:\n",
        "                    print(f\"  ‚ùå Ïåç {pair['number']} Ï≤òÎ¶¨ Ïã§Ìå®\")\n",
        "                    continue\n",
        "\n",
        "                success, original_fps, base_fps, base_video_path = result\n",
        "\n",
        "                # 2. Î≥¥Í∞ÑÎêú ÎπÑÎîîÏò§ ÏÉùÏÑ± (ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
        "                if use_interpolation:\n",
        "                    final_video_path = os.path.join(pair_output_dir, f\"{pair_name}_final.mp4\")\n",
        "                    print(\"  4. ÌîÑÎ†àÏûÑ Î≥¥Í∞Ñ Ï§ë...\")\n",
        "                    if self.interpolate_video(base_video_path, final_video_path, original_fps):\n",
        "                        print(f\"  üéâ ÏµúÏ¢Ö Í≤∞Í≥º: {final_video_path}\")\n",
        "                    else:\n",
        "                        print(f\"  ‚ö†Ô∏è Î≥¥Í∞Ñ Ïã§Ìå®, Í∏∞Î≥∏ ÎπÑÎîîÏò§ ÏÇ¨Ïö©: {base_video_path}\")\n",
        "                else:\n",
        "                    print(f\"  üéâ ÏµúÏ¢Ö Í≤∞Í≥º: {base_video_path}\")\n",
        "\n",
        "                success_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå Ïåç {pair['number']} Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\nüéâ Ï≤òÎ¶¨ ÏôÑÎ£å! {success_count}/{len(pairs)}Í∞ú ÏÑ±Í≥µ\")\n",
        "        print(f\"Í≤∞Í≥º Ï†ÄÏû• ÏúÑÏπò: {output_base_dir}\")\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_single_pair_wrapper(args):\n",
        "    pipeline, video_path, image_path, output_dir, frame_interval = args\n",
        "    return pipeline.process_single_pair(video_path, image_path, output_dir, frame_interval)\n",
        "\n",
        "def process_all_pairs_parallel(pipeline, pairs, output_base_dir, frame_interval=5, use_interpolation=True, max_workers=3):\n",
        "    tasks = []\n",
        "    for pair in pairs:\n",
        "        pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "        pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "        tasks.append((pipeline, pair['video_path'], pair['image_path'], pair_output_dir, frame_interval))\n",
        "    with Pool(processes=max_workers) as pool:\n",
        "        pool.map(process_single_pair_wrapper, tasks)\n",
        "\n",
        "# ÏÇ¨Ïö© ÏòàÏãú\n",
        "if __name__ == \"__main__\":\n",
        "    # ÌååÏù¥ÌîÑÎùºÏù∏ Ï¥àÍ∏∞Ìôî\n",
        "    pipeline = SimSwapAutoPipeline()\n",
        "\n",
        "    # ÏÑ§Ï†ï\n",
        "    VIDEO_DIR = \"/content/input_videos\"\n",
        "    IMAGE_DIR = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "    OUTPUT_DIR = \"/content/simswap_results\"\n",
        "    FRAME_INTERVAL = 5  # 5ÌîÑÎ†àÏûÑÎßàÎã§ ÏÉòÌîåÎßÅ\n",
        "    USE_INTERPOLATION = True  # ÌîÑÎ†àÏûÑ Î≥¥Í∞Ñ ÏÇ¨Ïö© Ïó¨Î∂Ä\n",
        "\n",
        "    print(\"=== SimSwap ÏûêÎèô ÌååÏù¥ÌîÑÎùºÏù∏ ÏãúÏûë ===\")\n",
        "    print(f\"ÏòÅÏÉÅ ÎîîÎ†âÌÜ†Î¶¨: {VIDEO_DIR}\")\n",
        "    print(f\"Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨: {IMAGE_DIR}\")\n",
        "    print(f\"Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨: {OUTPUT_DIR}\")\n",
        "    print(f\"ÌîÑÎ†àÏûÑ Í∞ÑÍ≤©: {FRAME_INTERVAL}\")\n",
        "    print(f\"Î≥¥Í∞Ñ ÏÇ¨Ïö©: {'Ïòà' if USE_INTERPOLATION else 'ÏïÑÎãàÏò§'}\")\n",
        "\n",
        "    pairs = pipeline.get_video_image_pairs(VIDEO_DIR, IMAGE_DIR)\n",
        "\n",
        "  process_all_pairs_parallel(\n",
        "      pipeline, pairs,\n",
        "      output_base_dir=OUTPUT_DIR,\n",
        "      frame_interval=FRAME_INTERVAL,\n",
        "      use_interpolation=USE_INTERPOLATION,\n",
        "      max_workers=3  # Î≥ëÎ†¨ Í∞ØÏàò (T4 2Ïû• Ïì∞Î©¥ 2~3, P100ÏùÄ 1~2 Í∂åÏû•)\n",
        "  )"
      ],
      "metadata": {
        "id": "zcJJ4Dt_ZnQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/simswap_results/*"
      ],
      "metadata": {
        "id": "1wW_lfuKyt5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list\n"
      ],
      "metadata": {
        "id": "TKYtA2bxQk_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}