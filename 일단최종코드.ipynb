{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%EC%9D%BC%EB%8B%A8%EC%B5%9C%EC%A2%85%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로딩"
      ],
      "metadata": {
        "id": "FnfNNJz2BwN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data():\n",
        "    train_path = '/content/u.base'\n",
        "    test_path = '/content/u.test'\n",
        "\n",
        "    # Load training and testing data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Determine the number of users and movies\n",
        "    num_users = max(train_data['user_id'].max(), test_data['user_id'].max())\n",
        "    num_movies = max(train_data['item_id'].max(), test_data['item_id'].max())\n",
        "\n",
        "    # Convert to zero-based index\n",
        "    train_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['rating']] = 1 # NaN을 모두 1로 바꿔줌\n",
        "\n",
        "    train, valid = train_test_split(train_data, test_size=0.1, random_state = 1234)\n",
        "\n",
        "    # Create matrices\n",
        "    train_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "    valid_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "\n",
        "\n",
        "    for row in train.itertuples():\n",
        "        train_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "    for row in valid.itertuples():\n",
        "        valid_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "\n",
        "    return num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data\n"
      ],
      "metadata": {
        "id": "p2EvqZIaudah"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation 평가"
      ],
      "metadata": {
        "id": "DhrtYhPjB0yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation 평가\n",
        "def eval(model, train_data, valid_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = np.where(valid_data > 0)\n",
        "\n",
        "    # 예측값을 원래 스케일로 복원 (0-1 -> 1-5)\n",
        "    pred_original_scale = pred_u_score * 4.0 + 1.0\n",
        "    valid_original_scale = valid_data * 4.0 + 1.0\n",
        "\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(valid_original_scale[target_item], pred_original_scale[target_item]))\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "53KhetYhBsVP"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "3h2XEB-lB3NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx\n",
        "\n",
        "\n",
        "\n",
        "class MSELoss:\n",
        "    def __init__(self, weight_decay_lambda=0.005):\n",
        "        self.loss = None\n",
        "        self.y = None\n",
        "        self.t = None\n",
        "        self.t_mask = None\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "\n",
        "    def forward(self, x, t, params=None):\n",
        "        self.t = t\n",
        "        self.y = x\n",
        "        self.loss = (self.y - self.t)**2\n",
        "        loss = np.mean(self.loss) * 0.5\n",
        "\n",
        "        if params is not None and self.weight_decay_lambda > 0:\n",
        "            weight_decay = 0\n",
        "            for idx in range(1, len(params)//2 + 1):\n",
        "                weight_key = 'W' + str(idx)\n",
        "                if weight_key in params:\n",
        "                    W = params[weight_key]\n",
        "                    weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
        "            loss += weight_decay\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dx = ( self.y - self.t) / len(self.y[self.t_mask])\n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "GYuA47b3ZYej"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class MultiLayerNet:\n",
        "    def __init__(self, input_size, hidden_size_list, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size_list = hidden_size_list\n",
        "        self.hidden_layer_num = len(hidden_size_list)\n",
        "        self.params = {}\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self.__init_weight()\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        for idx in range(1, self.hidden_layer_num+1):\n",
        "            self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "                                                      self.params['b' + str(idx)])\n",
        "            self.layers['Activation_function' + str(idx)] =Relu()\n",
        "\n",
        "        idx = self.hidden_layer_num + 1\n",
        "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "            self.params['b' + str(idx)])\n",
        "\n",
        "        self.last_layer = MSELoss()\n",
        "\n",
        "    def __init_weight(self):\n",
        "      layer_sizes = [self.input_size]\n",
        "      for hidden_size in self.hidden_size_list:\n",
        "          layer_sizes.append(hidden_size)\n",
        "      layer_sizes.append(self.output_size)\n",
        "\n",
        "\n",
        "      for i in range(1, len(layer_sizes)):\n",
        "          prev_size = layer_sizes[i-1]\n",
        "          current_size = layer_sizes[i]\n",
        "\n",
        "          xavier_scale = np.sqrt(2.0 / (prev_size + current_size))\n",
        "\n",
        "          weight_key = 'W' + str(i)\n",
        "          self.params[weight_key] = xavier_scale * np.random.randn(prev_size, current_size)\n",
        "\n",
        "          bias_key = 'b' + str(i)\n",
        "          self.params[bias_key] = np.zeros(current_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return self.last_layer.forward(y, t, self.params)\n",
        "\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        for idx in range(1, self.hidden_layer_num+2):\n",
        "            grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW\n",
        "            grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "tnhB1vd3CGIX"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ],
      "metadata": {
        "id": "sI6-Qu3JCP59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Adam:\n",
        "    def __init__(self, lr=0.001, beta1=0.8, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def update(self, params, grads):\n",
        "\n",
        "        if self.m is None or self.v is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key in params.keys():\n",
        "                self.m[key] = np.zeros_like(params[key])\n",
        "                self.v[key] = np.zeros_like(params[key])\n",
        "\n",
        "        self.iter += 1\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.m[key] = self.beta1 * self.m[key] + (1.0 - self.beta1) * grads[key]\n",
        "            self.v[key] = self.beta2 * self.v[key] + (1.0 - self.beta2) * (grads[key] ** 2)\n",
        "            m_corrected = self.m[key] / (1.0 - self.beta1 ** self.iter)\n",
        "            v_corrected = self.v[key] / (1.0 - self.beta2 ** self.iter)\n",
        "            params[key] -= self.lr * m_corrected / (np.sqrt(v_corrected) + self.epsilon)"
      ],
      "metadata": {
        "id": "vyN7VyTlCSo6"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission 만들기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pandas import DataFrame\n",
        "def make_submission(model, train_data, test_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = (test_data['user_id'].to_numpy(), test_data['item_id'].to_numpy())\n",
        "\n",
        "    pred_original_scale = pred_u_score[target_item] * 4.0 + 1.0\n",
        "    pred_original_scale = np.clip(pred_original_scale, 1.0, 5.0)\n",
        "\n",
        "    results = pd.DataFrame()\n",
        "    results[\"target_id\"] = test_data[\"target_id\"]\n",
        "    results[\"rating\"] = pred_original_scale\n",
        "    print(results.head())  # 결과 확인용\n",
        "    results.to_csv('/content/submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DgX4D_md-FwP"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "zcb7o5gbCjsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# colab에서 나오는 warning들을 무시\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 결과 재현을 위해 Seed를 고정\n",
        "def seed_everything(random_seed):\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "seed = 1\n",
        "seed_everything(seed)\n",
        "\n",
        "\n",
        "# 0. 데이터 읽기==========\n",
        "num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data = load_data()\n",
        "\n",
        "\n",
        "# 1. 실험용 설정==========\n",
        "train_size = num_users\n",
        "max_epochs = 30\n",
        "batch_size = 60\n",
        "initial_lr = 0.001\n",
        "decay_rate = 0.97\n",
        "patience = 10\n",
        "\n",
        "optimizers = Adam(lr=initial_lr, beta1=0.9, beta2=0.999)\n",
        "train_loss = []\n",
        "Model = MultiLayerNet(\n",
        "        input_size=num_movies, hidden_size_list=[40, 30],\n",
        "        output_size=num_movies)\n",
        "\n",
        "\n",
        "# 2. 훈련 시작==========\n",
        "best_rmse = float('inf')\n",
        "best_epoch = 0\n",
        "best_params = {}\n",
        "counter = 0\n",
        "\n",
        "for i in range(max_epochs):\n",
        "    if i > 10:\n",
        "      optimizers.lr = initial_lr * (decay_rate ** (i-10))\n",
        "\n",
        "    shuffled_user_index = np.asarray(range(num_users))\n",
        "    np.random.shuffle(shuffled_user_index)\n",
        "\n",
        "    batch_num = int(num_users / batch_size) + 1\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for b_idx in range(batch_num):\n",
        "        batch_idx = shuffled_user_index[b_idx*batch_size : (b_idx+1)*batch_size]\n",
        "        if len(batch_idx) == 0:\n",
        "            continue\n",
        "\n",
        "        x_batch = train_ratings_matrix[batch_idx]\n",
        "\n",
        "        grads = Model.gradient(x_batch, x_batch)\n",
        "        optimizers.update(Model.params, grads)\n",
        "\n",
        "        loss = Model.loss(x_batch, x_batch)\n",
        "        train_loss.append(loss)\n",
        "        epoch_loss += loss\n",
        "\n",
        "    avg_loss = epoch_loss / batch_num if batch_num > 0 else 0\n",
        "    print(\"epoch:\" + str(i+1) + \"  loss:\" + str(loss))\n",
        "\n",
        "    current_rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "    print(\"validation rmse:\", current_rmse)\n",
        "\n",
        "    if current_rmse < best_rmse:\n",
        "        print(f\"성능 good RMSE: {best_rmse:.4f} -> {current_rmse:.4f}\")\n",
        "        best_rmse = current_rmse\n",
        "        best_epoch = i\n",
        "\n",
        "        best_params = {}\n",
        "        for key, val in Model.params.items():\n",
        "            best_params[key] = val.copy()\n",
        "\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"성능 bad {counter}/{patience}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {i+1}!\")\n",
        "        print(f\"Best epoch was {best_epoch+1} with RMSE {best_rmse:.4f}\")\n",
        "        break\n",
        "\n",
        "if best_params:\n",
        "    print(f\"최고 성능 모델 복원(에폭 {best_epoch+1})\")\n",
        "    for key in Model.params:\n",
        "        Model.params[key] = best_params[key]\n",
        "\n",
        "# 3. 평가==========\n",
        "rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "print( \"============================\")\n",
        "print( \"=========== rmse ===========\")\n",
        "print(str(rmse))\n",
        "\n",
        "\n",
        "# # 4. submission만들기==========\n",
        "make_submission(Model, train_ratings_matrix, test_data)"
      ],
      "metadata": {
        "id": "3Te9mcuVBrNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c601ee01-be32-46d3-89a7-966a918372c8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1  loss:0.4301287025853614\n",
            "validation rmse: 2.6540067322295395\n",
            "성능 good RMSE: inf -> 2.6540\n",
            "epoch:2  loss:0.4291073300098328\n",
            "validation rmse: 2.346386606497952\n",
            "성능 good RMSE: 2.6540 -> 2.3464\n",
            "epoch:3  loss:0.4263394901455469\n",
            "validation rmse: 2.317354370036533\n",
            "성능 good RMSE: 2.3464 -> 2.3174\n",
            "epoch:4  loss:0.4279028266016043\n",
            "validation rmse: 2.2887015820932874\n",
            "성능 good RMSE: 2.3174 -> 2.2887\n",
            "epoch:5  loss:0.43033170687551947\n",
            "validation rmse: 2.248699341921355\n",
            "성능 good RMSE: 2.2887 -> 2.2487\n",
            "epoch:6  loss:0.43097915638035317\n",
            "validation rmse: 2.213207256748558\n",
            "성능 good RMSE: 2.2487 -> 2.2132\n",
            "epoch:7  loss:0.43334836550122224\n",
            "validation rmse: 2.1849303784668077\n",
            "성능 good RMSE: 2.2132 -> 2.1849\n",
            "epoch:8  loss:0.43460664509341457\n",
            "validation rmse: 2.167203154319526\n",
            "성능 good RMSE: 2.1849 -> 2.1672\n",
            "epoch:9  loss:0.4381294161918005\n",
            "validation rmse: 2.154807822436993\n",
            "성능 good RMSE: 2.1672 -> 2.1548\n",
            "epoch:10  loss:0.44227277355623107\n",
            "validation rmse: 2.1453873582207614\n",
            "성능 good RMSE: 2.1548 -> 2.1454\n",
            "epoch:11  loss:0.4431631318715162\n",
            "validation rmse: 2.1334466760384334\n",
            "성능 good RMSE: 2.1454 -> 2.1334\n",
            "epoch:12  loss:0.4463029512354401\n",
            "validation rmse: 2.1357252227230346\n",
            "성능 bad 1/10\n",
            "epoch:13  loss:0.4507941582405446\n",
            "validation rmse: 2.1289425043924624\n",
            "성능 good RMSE: 2.1334 -> 2.1289\n",
            "epoch:14  loss:0.4541164438894607\n",
            "validation rmse: 2.1245364607768193\n",
            "성능 good RMSE: 2.1289 -> 2.1245\n",
            "epoch:15  loss:0.4584588834404672\n",
            "validation rmse: 2.121537350958305\n",
            "성능 good RMSE: 2.1245 -> 2.1215\n",
            "epoch:16  loss:0.461677920440988\n",
            "validation rmse: 2.1155630019819363\n",
            "성능 good RMSE: 2.1215 -> 2.1156\n",
            "epoch:17  loss:0.4654414982592678\n",
            "validation rmse: 2.116864988767926\n",
            "성능 bad 1/10\n",
            "epoch:18  loss:0.4692258907981179\n",
            "validation rmse: 2.118845397814138\n",
            "성능 bad 2/10\n",
            "epoch:19  loss:0.47052772075505006\n",
            "validation rmse: 2.1118457515068596\n",
            "성능 good RMSE: 2.1156 -> 2.1118\n",
            "epoch:20  loss:0.47483136710718055\n",
            "validation rmse: 2.1095187105252604\n",
            "성능 good RMSE: 2.1118 -> 2.1095\n",
            "epoch:21  loss:0.477720219465853\n",
            "validation rmse: 2.1073728697357113\n",
            "성능 good RMSE: 2.1095 -> 2.1074\n",
            "epoch:22  loss:0.47987015319655946\n",
            "validation rmse: 2.108274255429511\n",
            "성능 bad 1/10\n",
            "epoch:23  loss:0.4833145488197257\n",
            "validation rmse: 2.10678737744935\n",
            "성능 good RMSE: 2.1074 -> 2.1068\n",
            "epoch:24  loss:0.48573696070430655\n",
            "validation rmse: 2.105117146313678\n",
            "성능 good RMSE: 2.1068 -> 2.1051\n",
            "epoch:25  loss:0.48670464562694754\n",
            "validation rmse: 2.10657811085189\n",
            "성능 bad 1/10\n",
            "epoch:26  loss:0.4899793725078962\n",
            "validation rmse: 2.104736827852535\n",
            "성능 good RMSE: 2.1051 -> 2.1047\n",
            "epoch:27  loss:0.4927484625074861\n",
            "validation rmse: 2.1007837298709386\n",
            "성능 good RMSE: 2.1047 -> 2.1008\n",
            "epoch:28  loss:0.4928438190431259\n",
            "validation rmse: 2.1073619820702554\n",
            "성능 bad 1/10\n",
            "epoch:29  loss:0.4953329956370219\n",
            "validation rmse: 2.1053292292232055\n",
            "성능 bad 2/10\n",
            "epoch:30  loss:0.4983794380668011\n",
            "validation rmse: 2.1035966139762383\n",
            "성능 bad 3/10\n",
            "최고 성능 모델 복원(에폭 27)\n",
            "============================\n",
            "=========== rmse ===========\n",
            "2.1035966139762383\n",
            "   target_id    rating\n",
            "0          1  1.164791\n",
            "1          2  1.640529\n",
            "2          3  2.824188\n",
            "3          4  2.146240\n",
            "4          5  1.520427\n"
          ]
        }
      ]
    }
  ]
}