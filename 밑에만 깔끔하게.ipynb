{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%EB%B0%91%EC%97%90%EB%A7%8C%20%EA%B9%94%EB%81%94%ED%95%98%EA%B2%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dependency"
      ],
      "metadata": {
        "id": "An3Kh3m69Jqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.11\n",
        "!pip install opencv-contrib-python flatbuffers==23.5.26 sounddevice==0.4.6 attrs==23.1.0\n",
        "!pip install torch==2.1.0 torchvision==0.16.0\n",
        "!pip install dlib opencv-python scikit-image pillow matplotlib imageio gdown tqdm\n",
        "!pip install ninja tensorboard tensorboardX pyaml pyrallis ftfy\n",
        "!pip install face-alignment==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ah4vUmMoLXIo",
        "outputId": "3c014605-7d42-4505-c8b0-28cd70bb459f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.11\n",
            "  Downloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.6.0+cu124)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (4.11.0.86)\n",
            "Collecting protobuf<4,>=3.11 (from mediapipe==0.10.11)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.11)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->mediapipe==0.10.11) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mediapipe==0.10.11) (3.0.2)\n",
            "Downloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "91fd1409747f411d85d5178bab7d7e6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting flatbuffers==23.5.26\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting sounddevice==0.4.6\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting attrs==23.1.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice==0.4.6) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice==0.4.6) (2.22)\n",
            "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flatbuffers, attrs, sounddevice\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: sounddevice\n",
            "    Found existing installation: sounddevice 0.5.2\n",
            "    Uninstalling sounddevice-0.5.2:\n",
            "      Successfully uninstalled sounddevice-0.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 flatbuffers-23.5.26 sounddevice-0.4.6\n",
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.16.0\n",
            "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m739.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchvision-0.16.0 triton-2.1.0\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyrallis\n",
            "  Downloading pyrallis-0.3.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Collecting typing-inspect (from pyrallis)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyrallis)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (4.14.0)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: tensorboardX, pyaml, ninja, mypy-extensions, ftfy, typing-inspect, pyrallis\n",
            "Successfully installed ftfy-6.3.1 mypy-extensions-1.1.0 ninja-1.11.1.4 pyaml-25.5.0 pyrallis-0.3.1 tensorboardX-2.6.4 typing-inspect-0.9.0\n",
            "Collecting face-alignment==1.3.5\n",
            "  Downloading face_alignment-1.3.5-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.15.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment==1.3.5) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->face-alignment==1.3.5) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.3.5) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->face-alignment==1.3.5) (1.3.0)\n",
            "Downloading face_alignment-1.3.5-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "j6kl565aMbdT",
        "outputId": "4ff031ca-49f6-4136-fce7-908bbee87e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "10bd3946c9c5423ebe320e41f68960d8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/extract_frames\n",
        "!mkdir -p /content/input_videos\n",
        "!mkdir -p /content/alignmented_frame\n",
        "!mkdir -p /content/alignmented_frame_aligned\n",
        "!mkdir -p /content/alignmented_frame_croped\n",
        "!mkdir -p /content/alignmented_frame_transforms"
      ],
      "metadata": {
        "id": "UlYQQ1my-rL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#git hub & model install"
      ],
      "metadata": {
        "id": "Io1UJS2j-HYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/stylegan3-editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae5jdZJn-UUn",
        "outputId": "a4fb5f13-280f-40f3-9951-1d77d3379d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3-editing'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 278 (delta 8), reused 5 (delta 5), pack-reused 230 (from 1)\u001b[K\n",
            "Receiving objects: 100% (278/278), 74.09 MiB | 39.89 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "8gQABgnW-aOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -P /content/pretrained_models/\n",
        "!bzip2 -d /content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZNpi4s-HAa",
        "outputId": "910754bf-5760-42e5-f4eb-28da8dba19aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 08:46:20--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-06-20 08:46:20--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  19.8MB/s    in 3.1s    \n",
            "\n",
            "2025-06-20 08:46:24 (19.8 MB/s) - ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm -O /content/pretrained_models/restyle_e4e_sg3.pt\n",
        "!gdown --id 13q6m-bpe3Ws9en9y45JEx2PHQirStt8N -O /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
        "!gdown --id 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn -O /content/pretrained_models/model_ir_se50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntmFmSfd-ZiO",
        "outputId": "41760c6d-2715-4d54-e659-f042a6fca7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm\n",
            "From (redirected): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm&confirm=t&uuid=9ebc1e07-7535-4a48-b243-1e94ae228afd\n",
            "To: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "100% 809M/809M [00:08<00:00, 91.8MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N\n",
            "From (redirected): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N&confirm=t&uuid=53e647e3-06d7-47a7-a134-150d913d0a48\n",
            "To: /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
            "100% 60.4M/60.4M [00:00<00:00, 151MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn\n",
            "From (redirected): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn&confirm=t&uuid=bebb8d52-c033-4f85-8ee7-604ab5b83241\n",
            "To: /content/pretrained_models/model_ir_se50.pth\n",
            "100% 175M/175M [00:02<00:00, 73.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stylegan3-editing/pretrained_models\n",
        "!cp /content/pretrained_models/shape_predictor_68_face_landmarks.dat /content/stylegan3-editing/pretrained_models/"
      ],
      "metadata": {
        "id": "aCa0uxct-mxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess frames"
      ],
      "metadata": {
        "id": "PBElw7K4_zJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 단일 프로세스 프레임 추출 코드\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "video_dir = \"/content/input_videos\"  #@param {type:\"string\"}\n",
        "output_base = \"/content/extract_frames\"  #@param {type:\"string\"}\n",
        "extract_per_sec = 7  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "def extract_video_frames(video_path):\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    output_dir = os.path.join(output_base, video_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval = max(1, int(fps // extract_per_sec))\n",
        "\n",
        "    frame_idx = 0\n",
        "    frame_list = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % interval == 0:\n",
        "            frame_list.append(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # 여기서 한 번에 저장!\n",
        "    for saved_idx, frame in enumerate(frame_list):\n",
        "        frame_path = os.path.join(output_dir, f\"key_{saved_idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    return f\"{video_name}: {len(frame_list)} frames saved\"\n",
        "\n",
        "# 실행\n",
        "video_paths = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "print(f\"🎬 총 {len(video_paths)}개의 영상 처리 시작\")\n",
        "\n",
        "for video_path in tqdm(video_paths, desc=\"📦 Processing videos\"):\n",
        "    msg = extract_video_frames(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3XEaKpDfN2",
        "outputId": "a6cbfe47-84d4-4734-b661-d8ffd3aa3467",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 총 1개의 영상 처리 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📦 Processing videos: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 피치 제한 강화 + 눈뜸 50% 기준 + KeyError 해결 코드\n",
        "import cv2, os, math, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACE_MESH = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# 눈 좌표 인덱스\n",
        "LEFT_EYE_IDX = [\n",
        "    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,\n",
        "    33, 173, 157, 158, 159, 160, 161, 246, 33\n",
        "]\n",
        "RIGHT_EYE_IDX = [\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382,\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 362\n",
        "]\n",
        "\n",
        "CORE_LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "CORE_RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_EYE_VERTICAL = [159, 145]\n",
        "RIGHT_EYE_VERTICAL = [386, 374]\n",
        "POSE_IDX = [1, 152, 33, 263, 61, 291]\n",
        "\n",
        "# 파라미터 설정 - 피치 제한 강화, 눈뜸 기준 완화\n",
        "YAW_T = 25\n",
        "PITCH_T = 25  # 35에서 25로 강화 (피치 관대하게 하지 않음)\n",
        "HEAD_DOWN_BONUS = 1  # 보너스 최소화\n",
        "ENABLE_ADAPTIVE_EAR = True\n",
        "EAR_PERCENTILE_HIGH = 37 # 상위 50%를 눈뜬 상태로 판정 (기존 40%에서 완화)\n",
        "EAR_PERCENTILE_LOW = 10\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=\"double\")\n",
        "\n",
        "def get_mediapipe_landmarks(img):\n",
        "    h, w = img.shape[:2]\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = FACE_MESH.process(rgb)\n",
        "    if not res.multi_face_landmarks:\n",
        "        return None\n",
        "    lm = res.multi_face_landmarks[0]\n",
        "    coords = np.array([[p.x * w, p.y * h] for p in lm.landmark])\n",
        "    return coords\n",
        "\n",
        "def estimate_pose_mediapipe(landmarks, img_shape):\n",
        "    image_points = landmarks[POSE_IDX]\n",
        "    focal = img_shape[1]\n",
        "    center = (img_shape[1]/2, img_shape[0]/2)\n",
        "    cam = np.array([[focal, 0, center[0]], [0, focal, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "    dist = np.zeros((4,1))\n",
        "    success, rv, _ = cv2.solvePnP(model_points, image_points, cam, dist)\n",
        "    return rv if success else None\n",
        "\n",
        "def rotation_vector_to_euler(rv):\n",
        "    rmat, _ = cv2.Rodrigues(rv)\n",
        "    proj = np.hstack((rmat, np.zeros((3,1))))\n",
        "    angles = cv2.decomposeProjectionMatrix(proj)[6]\n",
        "    pitch = math.degrees(math.asin(math.sin(math.radians(angles[1][0]))))\n",
        "    yaw   = math.degrees(math.asin(math.sin(math.radians(angles[2][0]))))\n",
        "    roll  = -math.degrees(math.asin(math.sin(math.radians(angles[0][0]))))\n",
        "    return pitch, yaw, roll\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "def enhanced_eye_aspect_ratio(landmarks, is_left=True):\n",
        "    if is_left:\n",
        "        outer = landmarks[33]\n",
        "        inner = landmarks[133]\n",
        "        v1 = np.linalg.norm(landmarks[159] - landmarks[145])\n",
        "        v2 = np.linalg.norm(landmarks[158] - landmarks[153])\n",
        "        v3 = np.linalg.norm(landmarks[160] - landmarks[144])\n",
        "    else:\n",
        "        outer = landmarks[362]\n",
        "        inner = landmarks[263]\n",
        "        v1 = np.linalg.norm(landmarks[386] - landmarks[374])\n",
        "        v2 = np.linalg.norm(landmarks[385] - landmarks[373])\n",
        "        v3 = np.linalg.norm(landmarks[387] - landmarks[380])\n",
        "\n",
        "    horizontal = np.linalg.norm(outer - inner)\n",
        "    avg_vertical = (v1 + v2 + v3) / 3.0\n",
        "    return avg_vertical / horizontal\n",
        "\n",
        "def calculate_adaptive_ear_thresholds(all_ear_values):\n",
        "    \"\"\"영상별 적응형 EAR 임계값 계산 - 50% 기준 적용\"\"\"\n",
        "    if len(all_ear_values) < 5:\n",
        "        return {\n",
        "            'high_threshold': 0.23,\n",
        "            'medium_threshold': 0.18,\n",
        "            'low_threshold': 0.15,\n",
        "            'min_threshold': 0.12\n",
        "        }\n",
        "\n",
        "    ear_array = np.array(all_ear_values)\n",
        "\n",
        "    # 50% 기준으로 임계값 설정\n",
        "    high_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH)  # 상위 50%\n",
        "    medium_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.2)  # 상위 60%\n",
        "    low_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.5)  # 상위 75%\n",
        "    min_threshold = np.percentile(ear_array, EAR_PERCENTILE_LOW)  # 하위 10%\n",
        "\n",
        "    # 최소값 보장\n",
        "    high_threshold = max(high_threshold, 0.16)  # 더 관대하게\n",
        "    medium_threshold = max(medium_threshold, 0.13)\n",
        "    low_threshold = max(low_threshold, 0.10)\n",
        "    min_threshold = max(min_threshold, 0.07)\n",
        "\n",
        "    return {\n",
        "        'high_threshold': high_threshold,\n",
        "        'medium_threshold': medium_threshold,\n",
        "        'low_threshold': low_threshold,\n",
        "        'min_threshold': min_threshold,\n",
        "        'ear_stats': {\n",
        "            'mean': np.mean(ear_array),\n",
        "            'std': np.std(ear_array),\n",
        "            'min': np.min(ear_array),\n",
        "            'max': np.max(ear_array),\n",
        "            'count': len(ear_array)\n",
        "        }\n",
        "    }\n",
        "\n",
        "def is_eye_open_adaptive(landmarks, thresholds, pitch_angle=0):\n",
        "    \"\"\"적응형 EAR 기반 눈뜸 판정 - 피치 조정 최소화\"\"\"\n",
        "\n",
        "    left_eye_basic = landmarks[CORE_LEFT_EYE]\n",
        "    right_eye_basic = landmarks[CORE_RIGHT_EYE]\n",
        "\n",
        "    basic_left_ear = eye_aspect_ratio(left_eye_basic)\n",
        "    basic_right_ear = eye_aspect_ratio(right_eye_basic)\n",
        "    basic_avg_ear = (basic_left_ear + basic_right_ear) / 2.0\n",
        "\n",
        "    enhanced_left_ear = enhanced_eye_aspect_ratio(landmarks, True)\n",
        "    enhanced_right_ear = enhanced_eye_aspect_ratio(landmarks, False)\n",
        "    enhanced_avg_ear = (enhanced_left_ear + enhanced_right_ear) / 2.0\n",
        "\n",
        "    ear_difference = abs(basic_left_ear - basic_right_ear)\n",
        "\n",
        "    # 피치 조정 최소화 (관대하게 하지 않음)\n",
        "    pitch_factor = 1.0\n",
        "    if pitch_angle > 20:  # 20도 이상에서만 최소 조정\n",
        "        pitch_factor = max(0.95, 1.0 - (pitch_angle - 20) * 0.005)  # 최대 5%만 완화\n",
        "\n",
        "    # 적응형 임계값 적용\n",
        "    adj_high = thresholds['high_threshold'] * pitch_factor\n",
        "    adj_medium = thresholds['medium_threshold'] * pitch_factor\n",
        "    adj_low = thresholds['low_threshold'] * pitch_factor\n",
        "    adj_min = thresholds['min_threshold'] * pitch_factor\n",
        "\n",
        "    # 4단계 눈뜸 판정\n",
        "    level_1 = (basic_avg_ear > adj_high and\n",
        "               enhanced_avg_ear > adj_high * 0.9 and\n",
        "               basic_left_ear > adj_medium and\n",
        "               basic_right_ear > adj_medium and\n",
        "               ear_difference < 0.08)\n",
        "\n",
        "    level_2 = (basic_avg_ear > adj_medium and\n",
        "               enhanced_avg_ear > adj_medium * 0.8 and\n",
        "               basic_left_ear > adj_low and\n",
        "               basic_right_ear > adj_low and\n",
        "               ear_difference < 0.12)\n",
        "\n",
        "    level_3 = (basic_avg_ear > adj_low and\n",
        "               basic_left_ear > adj_min and\n",
        "               basic_right_ear > adj_min and\n",
        "               ear_difference < 0.15)\n",
        "\n",
        "    level_4 = (basic_avg_ear > adj_min and\n",
        "               basic_left_ear > adj_min * 0.8 and\n",
        "               basic_right_ear > adj_min * 0.8)\n",
        "\n",
        "    # 레벨별 점수 부여\n",
        "    if level_1:\n",
        "        eye_level = 4\n",
        "    elif level_2:\n",
        "        eye_level = 3\n",
        "    elif level_3:\n",
        "        eye_level = 2\n",
        "    elif level_4:\n",
        "        eye_level = 1\n",
        "    else:\n",
        "        eye_level = 0\n",
        "\n",
        "    return eye_level, {\n",
        "        'basic_ear': basic_avg_ear,\n",
        "        'enhanced_ear': enhanced_avg_ear,\n",
        "        'left_ear': basic_left_ear,\n",
        "        'right_ear': basic_right_ear,\n",
        "        'ear_diff': ear_difference,\n",
        "        'eye_level': eye_level,\n",
        "        'pitch_factor': pitch_factor,\n",
        "        'thresholds_used': {\n",
        "            'high': adj_high,\n",
        "            'medium': adj_medium,\n",
        "            'low': adj_low,\n",
        "            'min': adj_min\n",
        "        }\n",
        "    }\n",
        "\n",
        "def frontal_score_strict_pitch(c):\n",
        "    \"\"\"피치 제한 강화된 정면성 평가 함수\"\"\"\n",
        "\n",
        "    yaw_angle = abs(c['yaw'])\n",
        "    pitch_angle = c['pitch']\n",
        "\n",
        "    # 엄격한 각도 제한 (피치 관대하게 하지 않음)\n",
        "    if yaw_angle > YAW_T:  # 25도\n",
        "        return -1000\n",
        "    if abs(pitch_angle) > PITCH_T:  # ±25도 (엄격)\n",
        "        return -1000\n",
        "\n",
        "    # 기본 페널티 (피치에 더 큰 가중치)\n",
        "    yaw_penalty = yaw_angle * 0.8\n",
        "    pitch_penalty = abs(pitch_angle) * 1.2  # 피치 페널티 증가\n",
        "\n",
        "    # 고개 숙임 보너스 최소화\n",
        "    head_down_bonus = 0\n",
        "    if -15 <= pitch_angle <= -5:  # 아주 제한적인 범위에서만\n",
        "        head_down_bonus = HEAD_DOWN_BONUS * 0.5  # 보너스도 절반으로\n",
        "\n",
        "    # 눈뜸 레벨 보너스\n",
        "    eye_level = c.get('eye_level', 0)\n",
        "    eye_bonus = eye_level * 12  # 눈뜸이 더 중요\n",
        "\n",
        "    bonus = eye_bonus + (head_down_bonus if pitch_angle < 0 else 0)\n",
        "\n",
        "    return -(0.5 * yaw_penalty + 0.5 * pitch_penalty) + bonus\n",
        "\n",
        "def calculate_final_quality_score(pitch, yaw, eye_level, ear_details):\n",
        "    \"\"\"최종 품질 점수 계산 - 피치 페널티 강화\"\"\"\n",
        "\n",
        "    # 각도 점수 (피치에 더 큰 페널티)\n",
        "    yaw_score = max(0, 100 - abs(yaw) * 2.0)\n",
        "    pitch_score = max(0, 100 - abs(pitch) * 2.5)  # 피치 페널티 증가\n",
        "    angle_score = (yaw_score + pitch_score) / 2\n",
        "\n",
        "    # 눈뜸 레벨 점수 (50% 기준이므로 더 관대)\n",
        "    eye_score = eye_level * 25\n",
        "\n",
        "    # EAR 품질 점수\n",
        "    ear_quality = min(100, ear_details['basic_ear'] * 300)\n",
        "\n",
        "    # 종합 점수 (눈뜸 비중 증가)\n",
        "    total_score = (\n",
        "        angle_score * 0.3 +    # 각도 30%\n",
        "        eye_score * 0.5 +      # 눈뜸 50% (증가)\n",
        "        ear_quality * 0.2      # EAR 품질 20%\n",
        "    )\n",
        "\n",
        "    return total_score\n",
        "\n",
        "# 경로 설정\n",
        "INPUT_ROOT = \"/content/extract_frames\"\n",
        "OUTPUT_ROOT = \"/content/alignmented_frame\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "file_ext = \".jpg\"\n",
        "video_dirs = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
        "missing_videos = []\n",
        "detailed_log = []\n",
        "best_images = []\n",
        "best_names = []\n",
        "\n",
        "print(f\"📦 총 {len(video_dirs)}개 영상 처리 시작\")\n",
        "print(f\"🎯 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (50% 기준으로 완화)\")\n",
        "print(f\"📐 각도 제한: Yaw ±{YAW_T}°, Pitch ±{PITCH_T}° (피치 제한 강화)\")\n",
        "print(f\"🎁 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소화)\")\n",
        "\n",
        "for video_name in tqdm(video_dirs, desc=\"🎯 Strict pitch + 50% eye threshold\"):\n",
        "    input_dir = os.path.join(INPUT_ROOT, video_name)\n",
        "\n",
        "    # 1단계: 모든 프레임의 EAR 값 수집\n",
        "    all_ear_values = []\n",
        "    frame_data = []\n",
        "\n",
        "    for f in sorted(os.listdir(input_dir)):\n",
        "        if not f.lower().endswith(file_ext):\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(input_dir, f)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        lm = get_mediapipe_landmarks(img)\n",
        "        if lm is None:\n",
        "            continue\n",
        "\n",
        "        rv = estimate_pose_mediapipe(lm, img.shape)\n",
        "        if rv is None:\n",
        "            continue\n",
        "\n",
        "        pitch, yaw, _ = rotation_vector_to_euler(rv)\n",
        "\n",
        "        # 엄격한 각도 제한\n",
        "        if abs(yaw) > YAW_T * 1.5 or abs(pitch) > PITCH_T * 1.5:\n",
        "            continue\n",
        "\n",
        "        # EAR 계산\n",
        "        left_eye = lm[CORE_LEFT_EYE]\n",
        "        right_eye = lm[CORE_RIGHT_EYE]\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        all_ear_values.append(avg_ear)\n",
        "\n",
        "        # 프레임 데이터 저장\n",
        "        x1, y1 = lm[:,0].min(), lm[:,1].min()\n",
        "        x2, y2 = lm[:,0].max(), lm[:,1].max()\n",
        "        face_area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "        frame_data.append({\n",
        "            'img': img,\n",
        "            'filename': f,\n",
        "            'landmarks': lm,\n",
        "            'pitch': pitch,\n",
        "            'yaw': yaw,\n",
        "            'avg_ear': avg_ear,\n",
        "            'cx': cx,\n",
        "            'cy': cy,\n",
        "            'face_area': face_area\n",
        "        })\n",
        "\n",
        "    if not all_ear_values:\n",
        "        missing_videos.append(video_name)\n",
        "        detailed_log.append({\n",
        "            'video_name': video_name,\n",
        "            'total_frames': 0,\n",
        "            'selected': False,\n",
        "            'selection_level': 0,  # KeyError 방지를 위해 추가\n",
        "            'reason': 'No valid frames found'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 2단계: 적응형 임계값 계산 (50% 기준)\n",
        "    thresholds = calculate_adaptive_ear_thresholds(all_ear_values)\n",
        "\n",
        "    # 3단계: 4단계 후보 분류\n",
        "    level_4_candidates = []\n",
        "    level_3_candidates = []\n",
        "    level_2_candidates = []\n",
        "    level_1_candidates = []\n",
        "\n",
        "    for frame in frame_data:\n",
        "        # 엄격한 피치 제한 적용\n",
        "        if abs(frame['pitch']) > PITCH_T:\n",
        "            continue\n",
        "\n",
        "        eye_level, eye_details = is_eye_open_adaptive(\n",
        "            frame['landmarks'], thresholds, abs(frame['pitch'])\n",
        "        )\n",
        "\n",
        "        if eye_level == 0:\n",
        "            continue\n",
        "\n",
        "        candidate = {\n",
        "            'img': frame['img'],\n",
        "            'filename': frame['filename'],\n",
        "            'pitch': frame['pitch'],\n",
        "            'yaw': frame['yaw'],\n",
        "            'cx': frame['cx'],\n",
        "            'cy': frame['cy'],\n",
        "            'face_area': frame['face_area'],\n",
        "            'w': frame['img'].shape[1],\n",
        "            'h': frame['img'].shape[0],\n",
        "            'eye_level': eye_level,\n",
        "            'eye_details': eye_details,\n",
        "            'quality_score': calculate_final_quality_score(\n",
        "                frame['pitch'], frame['yaw'], eye_level, eye_details\n",
        "            )\n",
        "        }\n",
        "\n",
        "        if eye_level == 4:\n",
        "            level_4_candidates.append(candidate)\n",
        "        elif eye_level == 3:\n",
        "            level_3_candidates.append(candidate)\n",
        "        elif eye_level == 2:\n",
        "            level_2_candidates.append(candidate)\n",
        "        else:\n",
        "            level_1_candidates.append(candidate)\n",
        "\n",
        "    # 4단계: 최적 프레임 선택\n",
        "    best_img = None\n",
        "    best_filename = None\n",
        "    selection_reason = \"No suitable frames\"\n",
        "    selection_level = 0\n",
        "\n",
        "    if level_4_candidates:\n",
        "        best = max(level_4_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 4: Selected from {len(level_4_candidates)} highest quality candidates\"\n",
        "        selection_level = 4\n",
        "\n",
        "    elif level_3_candidates:\n",
        "        best = max(level_3_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 3: Selected from {len(level_3_candidates)} high quality candidates\"\n",
        "        selection_level = 3\n",
        "\n",
        "    elif level_2_candidates:\n",
        "        best = max(level_2_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 2: Selected from {len(level_2_candidates)} medium quality candidates\"\n",
        "        selection_level = 2\n",
        "\n",
        "    elif level_1_candidates:\n",
        "        best = max(level_1_candidates, key=lambda x: x['quality_score'])\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 1: Selected from {len(level_1_candidates)} minimum quality candidates\"\n",
        "        selection_level = 1\n",
        "\n",
        "    elif frame_data:\n",
        "        # 최후의 수단: 가장 품질 좋은 프레임 무조건 선택\n",
        "        best_frame = max(frame_data, key=lambda x: x['avg_ear'])\n",
        "        best_img = best_frame['img']\n",
        "        best_filename = best_frame['filename']\n",
        "        selection_reason = f\"Emergency: Selected best EAR frame ({best_frame['avg_ear']:.3f})\"\n",
        "        selection_level = 0\n",
        "\n",
        "    # KeyError 방지를 위한 안전한 로그 기록\n",
        "    detailed_log.append({\n",
        "        'video_name': video_name,\n",
        "        'total_frames': len(frame_data),\n",
        "        'level_4_candidates': len(level_4_candidates),\n",
        "        'level_3_candidates': len(level_3_candidates),\n",
        "        'level_2_candidates': len(level_2_candidates),\n",
        "        'level_1_candidates': len(level_1_candidates),\n",
        "        'selected': best_filename is not None,\n",
        "        'selection_level': selection_level,  # 항상 포함\n",
        "        'best_filename': best_filename,\n",
        "        'reason': selection_reason,\n",
        "        'ear_thresholds': thresholds,\n",
        "        'quality_score': best.get('quality_score', 0) if 'best' in locals() else 0\n",
        "    })\n",
        "\n",
        "    # 프레임 저장\n",
        "    if best_img is not None:\n",
        "        save_path = os.path.join(OUTPUT_ROOT, f\"{video_name}.jpg\")\n",
        "        cv2.imwrite(save_path, best_img)\n",
        "\n",
        "        if selection_level <= 1:\n",
        "            print(f\"⚠️  {video_name}: Low quality selection (Level {selection_level})\")\n",
        "    else:\n",
        "        missing_videos.append(video_name)\n",
        "\n",
        "# 결과 저장\n",
        "if missing_videos:\n",
        "    df_missing = pd.DataFrame(missing_videos, columns=[\"video_name\"])\n",
        "    df_missing.to_csv(\"no_frame_found.csv\", index=False)\n",
        "    print(f\"❗ {len(missing_videos)}개 영상에서 프레임을 찾지 못함\")\n",
        "\n",
        "df_log = pd.DataFrame(detailed_log)\n",
        "df_log.to_csv(\"strict_pitch_50percent_eye_log.csv\", index=False)\n",
        "print(f\"📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\")\n",
        "\n",
        "# KeyError 방지된 안전한 통계 출력\n",
        "success_rate = (len(video_dirs) - len(missing_videos)) / len(video_dirs) * 100 if video_dirs else 0\n",
        "\n",
        "# .get() 메서드 사용으로 KeyError 방지\n",
        "level_4_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 4)\n",
        "level_3_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 3)\n",
        "level_2_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 2)\n",
        "level_1_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 1)\n",
        "emergency_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 0)\n",
        "\n",
        "print(f\"✅ 성공률: {success_rate:.1f}% ({len(video_dirs) - len(missing_videos)}/{len(video_dirs)})\")\n",
        "print(f\"🏆 Level 4 (최고품질): {level_4_usage}개\")\n",
        "print(f\"🥈 Level 3 (고품질): {level_3_usage}개\")\n",
        "print(f\"🥉 Level 2 (중품질): {level_2_usage}개\")\n",
        "print(f\"📉 Level 1 (최소품질): {level_1_usage}개\")\n",
        "print(f\"🚨 Emergency (강제선택): {emergency_usage}개\")\n",
        "\n",
        "print(f\"\\n📈 품질 분포:\")\n",
        "print(f\"   - 고품질 이상 (Level 3+): {(level_4_usage + level_3_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 중품질 이상 (Level 2+): {(level_4_usage + level_3_usage + level_2_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 최소품질 이상 (Level 1+): {(len(video_dirs) - emergency_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\n🎯 설정 요약:\")\n",
        "print(f\"   - 피치 제한: ±{PITCH_T}° (엄격)\")\n",
        "print(f\"   - 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (관대)\")\n",
        "print(f\"   - 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlELfbUkEFea",
        "outputId": "3b339bfc-490d-446b-ff1f-2cecaf812baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 총 1개 영상 처리 시작\n",
            "🎯 눈뜸 기준: 상위 37% (50% 기준으로 완화)\n",
            "📐 각도 제한: Yaw ±25°, Pitch ±25° (피치 제한 강화)\n",
            "🎁 고개 숙임 보너스: 1점 (최소화)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🎯 Strict pitch + 50% eye threshold: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\n",
            "✅ 성공률: 100.0% (1/1)\n",
            "🏆 Level 4 (최고품질): 1개\n",
            "🥈 Level 3 (고품질): 0개\n",
            "🥉 Level 2 (중품질): 0개\n",
            "📉 Level 1 (최소품질): 0개\n",
            "🚨 Emergency (강제선택): 0개\n",
            "\n",
            "📈 품질 분포:\n",
            "   - 고품질 이상 (Level 3+): 100.0%\n",
            "   - 중품질 이상 (Level 2+): 100.0%\n",
            "   - 최소품질 이상 (Level 1+): 100.0%\n",
            "\n",
            "🎯 설정 요약:\n",
            "   - 피치 제한: ±25° (엄격)\n",
            "   - 눈뜸 기준: 상위 37% (관대)\n",
            "   - 고개 숙임 보너스: 1점 (최소)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "H_23qUpRqSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af656eb2-fb7c-4656-a98d-ac332e1e3d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image crop"
      ],
      "metadata": {
        "id": "22A2atJxxcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan3-editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W19HlMQIxcMs",
        "outputId": "0517ea20-f566-46b6-d1ff-60623e366f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3-editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/stylegan3-editing')"
      ],
      "metadata": {
        "id": "UE0wMtQ79bS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "base_raw_root = \"/content/alignmented_frame\"\n",
        "aligned_root = f\"{base_raw_root}_aligned\"\n",
        "cropped_root = f\"{base_raw_root}_croped\"\n",
        "transform_root = f\"{base_raw_root}_transforms\"\n",
        "\n",
        "print(\"🚀 Aligning all images...\")\n",
        "# 실행 명령어에 PYTHONPATH를 추가하여 모듈을 찾을 경로를 알려줍니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode align \\\n",
        "    --root_path \"{base_raw_root}\"\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Cropping all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode crop \\\n",
        "    --root_path \"{base_raw_root}\" \\\n",
        "    --random_shift 0.05\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Computing transforms for all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/compute_landmarks_transforms.py \\\n",
        "    --raw_root \"{base_raw_root}\" \\\n",
        "    --aligned_root \"{aligned_root}\" \\\n",
        "    --cropped_root \"{cropped_root}\" \\\n",
        "    --output_root \"{transform_root}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kzg1k-FxgA2",
        "outputId": "6381f614-537c-4ba5-ab2b-66e49158d66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Aligning all images...\n",
            "1\n",
            "Running on 1 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #1 images\n",
            "\tDone!\n",
            "Mischief managed in -1.8908767700195312s\n",
            "🔁 Cropping all images...\n",
            "1\n",
            "Running on 1 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #1 images\n",
            "\tDone!\n",
            "Mischief managed in -1.5386278629302979s\n",
            "🔁 Computing transforms for all images...\n",
            "Computing landmarks transforms...\n",
            "100% 1/1 [00:02<00:00,  2.10s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 설정\n",
        "input_root = \"/content/alignmented_frame_croped\"\n",
        "transforms_root = \"/content/alignmented_frame_transforms/landmarks_transforms.npy\"\n",
        "output_root = \"/content/experiments/restyle_e4e_sg3\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "\n",
        "# output 디렉토리 생성\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "print(\"🚀 Inverting video\")\n",
        "\n",
        "!python {script_path} \\\n",
        "    --output_path \"{output_root}\" \\\n",
        "    --checkpoint_path \"{ckpt_path}\" \\\n",
        "    --data_path \"{input_root}\" \\\n",
        "    --test_batch_size 4 \\\n",
        "    --test_workers 4 \\\n",
        "    --n_iters_per_batch 3 \\\n",
        "    --landmarks_transforms_path \"{transforms_root}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdozUaBz7ja",
        "outputId": "3c0e4284-d69f-4823-c647-537309740876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Inverting video\n",
            "Loading ReStyle e4e from checkpoint: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "Loading StyleGAN3 generator from path: None\n",
            "Done!\n",
            "Model successfully loaded!\n",
            "Loading dataset for ffhq_encode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 1/1 [00:02<00:00,  2.12s/it]\n",
            "Runtime 1.7256+-0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save CSV"
      ],
      "metadata": {
        "id": "BAaQSZUwoGsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load latent dictionary\n",
        "latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "latent_dict = np.load(latent_path, allow_pickle=True).item()\n",
        "\n",
        "# 2. 정렬된 파일 리스트 확보\n",
        "filenames = sorted(latent_dict.keys())\n",
        "\n",
        "# 3. 각 latent에서 마지막 step → 평균 → (512,)\n",
        "latents = []\n",
        "for key in filenames:\n",
        "    latent = latent_dict[key][-1]  # 마지막 step (18, 512)\n",
        "    mean_latent = latent.mean(axis=0).astype('float32')  # (512,)\n",
        "    latents.append(mean_latent)\n",
        "\n",
        "latents = np.stack(latents)  # shape: (N, 512)\n",
        "\n",
        "# 4. cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(latents)  # shape: (N, N)\n",
        "\n",
        "# 5. 각 query 파일마다 top-3 유사한 match + score 저장\n",
        "rows = []\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    sims = sim_matrix[i].copy()\n",
        "    sims[i] = -np.inf  # 자기 자신 제외\n",
        "    top3_idx = np.argsort(sims)[::-1][:3]\n",
        "    row = {\n",
        "        \"query\": filenames[i],\n",
        "        \"top1\": filenames[top3_idx[0]],\n",
        "        \"top2\": filenames[top3_idx[1]],\n",
        "        \"top3\": filenames[top3_idx[2]],\n",
        "        \"top1val\": round(float(sims[top3_idx[0]]), 6),\n",
        "        \"top2val\": round(float(sims[top3_idx[1]]), 6),\n",
        "        \"top3val\": round(float(sims[top3_idx[2]]), 6),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 6. Save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"video_similarity_top3_compact.csv\", index=False)\n",
        "\n",
        "print(\"✅ Saved to video_similarity_top3_compact.csv\")\n"
      ],
      "metadata": {
        "id": "WjMFJ5i2oE78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "e236ade2-a734-47ee-8002-da646861d317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for axis 0 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-14-2913793647.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"top1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop3_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;34m\"top2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop3_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;34m\"top3\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop3_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"top1val\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop3_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall \"numpy<2.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "1GMV1-M-n0K1",
        "outputId": "78c33a66-d7cc-4170-8093-0c88885c8b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2.0\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a2bd548b26024aecab42ba24fee5b4aa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q insightface==0.7.3 onnxruntime moviepy opencv-python imageio==2.34.0 scikit-video\n",
        "!git clone -q https://github.com/woctezuma/SimSwap.git /content/SimSwap\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "os.makedirs('/content/arcface_model', exist_ok=True)\n",
        "os.makedirs('/content/SimSwap/parsing_model/checkpoint', exist_ok=True)\n",
        "os.makedirs('/content/SimSwap/checkpoints', exist_ok=True)\n",
        "os.makedirs('/content/SimSwap/insightface_func/models', exist_ok=True)\n",
        "\n",
        "!wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/1.0/arcface_checkpoint.tar -O /content/arcface_model/arcface_checkpoint.tar\n",
        "!wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/checkpoints.zip -O /content/checkpoints.zip\n",
        "!wget -q https://github.com/neuralchen/SimSwap/releases/download/1.0/79999_iter.pth -O /content/SimSwap/parsing_model/checkpoint/79999_iter.pth\n",
        "!wget -q https://github.com/woctezuma/SimSwap-colab/releases/download/antelope/antelope.zip -O /content/antelope.zip\n",
        "\n",
        "!tar -xf /content/arcface_model/arcface_checkpoint.tar -C /content/arcface_model\n",
        "!unzip -q /content/checkpoints.zip -d /content/SimSwap/checkpoints\n",
        "!unzip -q /content/antelope.zip -d /content/SimSwap/insightface_func/models/\n",
        "\n",
        "!wget -q https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip -O /content/buffalo_l.zip\n",
        "!unzip -q /content/buffalo_l.zip -d /content/SimSwap/insightface_func/models/antelope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCFEDIxZmkq",
        "outputId": "71d74a60-5eb7-4dbd-da8e-50f3571bf3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m411.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 6.31.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.31.1 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mtar: This does not look like a tar archive\n",
            "tar: Skipping to next header\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/hzwer/Practical-RIFE.git\n",
        "%cd Practical-RIFE\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -q gdown opencv-python numpy tqdm\n",
        "\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS/view\" -O RIFE_trained_model_HDv3.zip\n",
        "!unzip -q RIFE_trained_model_HDv3.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dxEeiNIpKaS",
        "outputId": "a6ce4b00-a9f0-458a-aadc-c1bd924aefb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'Practical-RIFE' already exists and is not an empty directory.\n",
            "/content/Practical-RIFE\n",
            "Requirement already satisfied: numpy<=1.23.5,>=1.16 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: sk-video>=1.1.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.1.10)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.15.2+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sk-video>=1.1.10->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->-r requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.3.0->-r requirements.txt (line 4)) (15.0.7)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.34.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.7.0->-r requirements.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS\n",
            "From (redirected): https://drive.google.com/uc?id=1l5u6G8vEkPAT7cYYWwzB6OG8vwBYrxiS&confirm=t&uuid=6e6e74fc-5b21-4b1a-8ae5-a8eab40e3fa5\n",
            "To: /content/Practical-RIFE/RIFE_trained_model_HDv3.zip\n",
            "100% 38.1M/38.1M [00:00<00:00, 45.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "SimSwap GPU 고속 자동 파이프라인\n",
        "GPU 코어 2개를 활용한 최적화 버전 + RIFE 프레임 보간\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import subprocess\n",
        "import warnings\n",
        "import threading\n",
        "import queue\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "# 환경 설정\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # GPU 2개 사용\n",
        "\n",
        "\n",
        "class SimSwapSetup:\n",
        "    \"\"\"SimSwap 호환성 수정 및 설정\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def fix_compatibility():\n",
        "        \"\"\"SimSwap 호환성 수정\"\"\"\n",
        "        print(\"🔧 GPU 호환성 수정 중...\")\n",
        "\n",
        "        os.chdir('/content/SimSwap')\n",
        "\n",
        "        # PyTorch 호환성 수정\n",
        "        os.system(\"sed -i.bak 's/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"))/torch.load(netArc_checkpoint, map_location=torch.device(\\\"cpu\\\"), weights_only=False)/' models/fs_model.py\")\n",
        "\n",
        "        # 감지 크기 수정\n",
        "        os.system(\"sed -i 's/det_size=(640,640)/det_size=(224,224)/' test_wholeimage_swapsingle.py\")\n",
        "\n",
        "        print(\"✅ GPU 호환성 수정 완료\")\n",
        "\n",
        "    @staticmethod\n",
        "    def verify_installation():\n",
        "        \"\"\"설치 상태 확인\"\"\"\n",
        "        required_paths = [\n",
        "            '/content/SimSwap',\n",
        "            '/content/arcface_model/arcface_checkpoint.tar',\n",
        "            '/content/SimSwap/parsing_model/checkpoint/79999_iter.pth',\n",
        "            '/content/SimSwap/checkpoints',\n",
        "            '/content/SimSwap/insightface_func/models/antelope',\n",
        "            '/content/Practical-RIFE'  # RIFE 경로 추가\n",
        "        ]\n",
        "\n",
        "        return all(os.path.exists(path) for path in required_paths)\n",
        "\n",
        "\n",
        "class FileManager:\n",
        "    \"\"\"파일 매칭 및 관리 - 고속화\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_number_from_filename(filename: str) -> Optional[int]:\n",
        "        \"\"\"파일명에서 숫자 추출\"\"\"\n",
        "        numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "        return int(numbers[0]) if numbers else None\n",
        "\n",
        "    @classmethod\n",
        "    def get_video_image_pairs(cls, video_dir: str, image_dir: str) -> List[Dict]:\n",
        "        \"\"\"영상과 이미지 파일들을 번호로 매칭\"\"\"\n",
        "        if not os.path.exists(video_dir) or not os.path.exists(image_dir):\n",
        "            return []\n",
        "\n",
        "        # 병렬로 파일 수집\n",
        "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "            video_future = executor.submit(glob, os.path.join(video_dir, \"*.mp4\"))\n",
        "            image_future = executor.submit(lambda:\n",
        "                glob(os.path.join(image_dir, \"*.jpg\")) +\n",
        "                glob(os.path.join(image_dir, \"*.png\"))\n",
        "            )\n",
        "\n",
        "            video_files = video_future.result()\n",
        "            image_files = image_future.result()\n",
        "\n",
        "        print(f\"📹 영상 파일: {len(video_files)}개\")\n",
        "        print(f\"🖼️ 이미지 파일: {len(image_files)}개\")\n",
        "\n",
        "        # 번호별로 매칭 (병렬)\n",
        "        def process_files(files, is_video=True):\n",
        "            result = {}\n",
        "            for file_path in files:\n",
        "                filename = os.path.basename(file_path)\n",
        "                number = cls.extract_number_from_filename(filename)\n",
        "                if number is not None:\n",
        "                    result[number] = file_path\n",
        "            return result\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "            video_future = executor.submit(process_files, video_files, True)\n",
        "            image_future = executor.submit(process_files, image_files, False)\n",
        "\n",
        "            video_dict = video_future.result()\n",
        "            image_dict = image_future.result()\n",
        "\n",
        "        # 매칭 쌍 생성\n",
        "        pairs = []\n",
        "        for number in sorted(set(video_dict.keys()) & set(image_dict.keys())):\n",
        "            pairs.append({\n",
        "                'number': number,\n",
        "                'video_path': video_dict[number],\n",
        "                'image_path': image_dict[number],\n",
        "                'video_name': os.path.splitext(os.path.basename(video_dict[number]))[0],\n",
        "                'image_name': os.path.splitext(os.path.basename(image_dict[number]))[0]\n",
        "            })\n",
        "\n",
        "        print(f\"🎯 매칭된 쌍: {len(pairs)}개\")\n",
        "        return pairs\n",
        "\n",
        "\n",
        "class GPUVideoProcessor:\n",
        "    \"\"\"GPU 가속 비디오 처리\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_frames_gpu(video_path: str, frame_dir: str, interval: int = 5) -> Tuple[Optional[float], Optional[float]]:\n",
        "        \"\"\"GPU 가속 프레임 추출\"\"\"\n",
        "        os.makedirs(frame_dir, exist_ok=True)\n",
        "\n",
        "        # 비디오 정보 획득\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            return None, None\n",
        "\n",
        "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        cap.release()\n",
        "\n",
        "        new_fps = original_fps / interval\n",
        "\n",
        "        # GPU 가속 FFmpeg 명령어\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-hwaccel', 'cuda',  # GPU 하드웨어 가속\n",
        "            '-hwaccel_output_format', 'cuda',\n",
        "            '-i', video_path,\n",
        "            '-vf', f'select=not(mod(n\\\\,{interval})),hwdownload,format=nv12',\n",
        "            '-vsync', 'vfr',\n",
        "            '-q:v', '2',\n",
        "            '-threads', '8',  # 멀티스레딩\n",
        "            '-y',\n",
        "            os.path.join(frame_dir, 'frame_%04d.jpg')\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            frame_count = len([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "            print(f\"  ✅ GPU로 {frame_count}개 프레임 추출 (원본: {original_fps:.1f}fps → 새로운: {new_fps:.1f}fps)\")\n",
        "            return original_fps, new_fps\n",
        "        else:\n",
        "            print(\"  ❌ GPU FFmpeg 실패, CPU 모드로 대체\")\n",
        "            return GPUVideoProcessor._extract_frames_cpu_fallback(video_path, frame_dir, interval)\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_frames_cpu_fallback(video_path: str, frame_dir: str, interval: int) -> Tuple[Optional[float], Optional[float]]:\n",
        "        \"\"\"CPU 백업 프레임 추출\"\"\"\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', video_path,\n",
        "            '-vf', f'select=not(mod(n\\\\,{interval}))',\n",
        "            '-vsync', 'vfr',\n",
        "            '-q:v', '2',\n",
        "            '-threads', '0',  # 모든 CPU 코어 사용\n",
        "            '-y',\n",
        "            os.path.join(frame_dir, 'frame_%04d.jpg')\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            cap.release()\n",
        "\n",
        "            frame_count = len([f for f in os.listdir(frame_dir) if f.endswith('.jpg')])\n",
        "            print(f\"  ✅ CPU로 {frame_count}개 프레임 추출\")\n",
        "            return original_fps, original_fps / interval\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    @staticmethod\n",
        "    def create_video_gpu(frame_dir: str, output_path: str, fps: float) -> bool:\n",
        "        \"\"\"GPU 가속 비디오 생성\"\"\"\n",
        "        if not os.path.exists(frame_dir):\n",
        "            return False\n",
        "\n",
        "        # 결과 이미지 수집\n",
        "        result_images = []\n",
        "        subdirs = sorted([d for d in os.listdir(frame_dir) if os.path.isdir(os.path.join(frame_dir, d))])\n",
        "\n",
        "        temp_dir = os.path.join(frame_dir, 'temp_sequence')\n",
        "        os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "        # 이미지들을 연속된 이름으로 복사\n",
        "        for i, subdir in enumerate(subdirs):\n",
        "            subdir_path = os.path.join(frame_dir, subdir)\n",
        "            image_files = [f for f in os.listdir(subdir_path) if f.lower().endswith(('.jpg', '.png'))]\n",
        "            if image_files:\n",
        "                src = os.path.join(subdir_path, image_files[0])\n",
        "                dst = os.path.join(temp_dir, f'img_{i:04d}.jpg')\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "        if not os.listdir(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "            return False\n",
        "\n",
        "        # GPU 가속 비디오 생성\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-hwaccel', 'cuda',\n",
        "            '-framerate', str(fps),\n",
        "            '-i', os.path.join(temp_dir, 'img_%04d.jpg'),\n",
        "            '-c:v', 'h264_nvenc',  # GPU 인코더\n",
        "            '-preset', 'p1',  # 가장 빠른 프리셋\n",
        "            '-crf', '23',\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-y', output_path\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        # CPU 백업\n",
        "        if result.returncode != 0:\n",
        "            cmd = [\n",
        "                'ffmpeg', '-framerate', str(fps),\n",
        "                '-i', os.path.join(temp_dir, 'img_%04d.jpg'),\n",
        "                '-c:v', 'libx264', '-preset', 'ultrafast',\n",
        "                '-crf', '23', '-pix_fmt', 'yuv420p',\n",
        "                '-threads', '0',\n",
        "                '-y', output_path\n",
        "            ]\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        # 임시 디렉토리 정리\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"  ✅ GPU 비디오 생성 완료: {os.path.basename(output_path)}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"  ❌ 비디오 생성 실패\")\n",
        "            return False\n",
        "\n",
        "\n",
        "class RIFEInterpolator:\n",
        "    \"\"\"RIFE 프레임 보간 처리\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rife_path = '/content/Practical-RIFE'\n",
        "        self.inference_script = os.path.join(self.rife_path, 'inference_video.py')\n",
        "\n",
        "    def interpolate_video(self, input_video: str, output_video: str, target_fps: Optional[float] = None) -> bool:\n",
        "        \"\"\"RIFE를 사용한 비디오 프레임 보간\"\"\"\n",
        "        if not os.path.exists(self.inference_script):\n",
        "            print(f\"  ❌ RIFE가 설치되지 않음: {self.inference_script}\")\n",
        "            return False\n",
        "\n",
        "        if not os.path.exists(input_video):\n",
        "            print(f\"  ❌ 입력 비디오가 존재하지 않음: {input_video}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"  🎬 RIFE 프레임 보간 시작...\")\n",
        "        print(f\"    입력: {os.path.basename(input_video)}\")\n",
        "        print(f\"    출력: {os.path.basename(output_video)}\")\n",
        "\n",
        "        # 입력 비디오의 FPS 확인\n",
        "        cap = cv2.VideoCapture(input_video)\n",
        "        current_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        cap.release()\n",
        "\n",
        "        # RIFE 명령어 구성\n",
        "        cmd = [\n",
        "            'python', self.inference_script,\n",
        "            '--video', input_video,\n",
        "            '--output', output_video\n",
        "        ]\n",
        "\n",
        "        # 목표 FPS가 지정된 경우 --fps 인자 사용\n",
        "        if target_fps:\n",
        "            cmd.extend(['--fps', str(int(target_fps))])\n",
        "            print(f\"    목표 FPS: {target_fps:.1f} (현재: {current_fps:.1f})\")\n",
        "        else:\n",
        "            # 기본적으로 2배속 처리 (30fps로 설정)\n",
        "            cmd.extend(['--fps', '30'])\n",
        "            print(f\"    기본 FPS: 30 (현재: {current_fps:.1f})\")\n",
        "\n",
        "        # GPU 사용 설정\n",
        "        env = os.environ.copy()\n",
        "        env['CUDA_VISIBLE_DEVICES'] = '0'  # RIFE는 단일 GPU 사용\n",
        "\n",
        "        try:\n",
        "            # RIFE 실행\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True,\n",
        "                                  cwd=self.rife_path, env=env, timeout=600)  # 10분 타임아웃\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                if os.path.exists(output_video):\n",
        "                    # 결과 FPS 확인\n",
        "                    cap = cv2.VideoCapture(output_video)\n",
        "                    final_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "                    cap.release()\n",
        "\n",
        "                    print(f\"  ✅ RIFE 보간 완료 (최종 FPS: {final_fps:.1f})\")\n",
        "                    return True\n",
        "                else:\n",
        "                    print(f\"  ❌ RIFE 출력 파일이 생성되지 않음\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"  ❌ RIFE 실행 실패:\")\n",
        "                if result.stdout.strip():\n",
        "                    print(f\"    stdout: {result.stdout}\")\n",
        "                if result.stderr.strip():\n",
        "                    print(f\"    stderr: {result.stderr}\")\n",
        "                return False\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"  ❌ RIFE 실행 타임아웃 (10분 초과)\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ RIFE 실행 중 예외 발생: {e}\")\n",
        "            return False\n",
        "\n",
        "class DualGPUSimSwapProcessor:\n",
        "    \"\"\"듀얼 GPU SimSwap 처리\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.arcface_path = '/content/arcface_model/arcface_checkpoint.tar'\n",
        "        self.checkpoints_dir = '/content/SimSwap/checkpoints'\n",
        "\n",
        "        if os.path.exists('/content/SimSwap'):\n",
        "            os.chdir('/content/SimSwap')\n",
        "        else:\n",
        "            raise FileNotFoundError(\"SimSwap이 설치되지 않았습니다\")\n",
        "\n",
        "        # GPU 작업 큐 설정\n",
        "        self.gpu0_queue = queue.Queue()\n",
        "        self.gpu1_queue = queue.Queue()\n",
        "        self.result_queue = queue.Queue()\n",
        "\n",
        "    def gpu_worker(self, gpu_id: int, task_queue: queue.Queue):\n",
        "        \"\"\"GPU별 워커 스레드\"\"\"\n",
        "        while True:\n",
        "            try:\n",
        "                task = task_queue.get(timeout=1.0)\n",
        "                if task is None:  # 종료 신호\n",
        "                    break\n",
        "\n",
        "                source_img, frame_path, result_subdir, frame_idx = task\n",
        "\n",
        "                # GPU 지정 환경변수\n",
        "                env = os.environ.copy()\n",
        "                env['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
        "\n",
        "                cmd = [\n",
        "                    'python', 'test_wholeimage_swapsingle.py',\n",
        "                    '--crop_size', '224',\n",
        "                    '--use_mask',\n",
        "                    '--no_simswaplogo',\n",
        "                    '--name', 'people',\n",
        "                    '--Arc_path', self.arcface_path,\n",
        "                    '--pic_a_path', source_img,\n",
        "                    '--pic_b_path', frame_path,\n",
        "                    '--pic_specific_path', frame_path,\n",
        "                    '--output_path', result_subdir,\n",
        "                    '--checkpoints_dir', self.checkpoints_dir\n",
        "                ]\n",
        "\n",
        "                result = subprocess.run(cmd, capture_output=True, text=True, env=env)\n",
        "\n",
        "                success = False\n",
        "                if result.returncode == 0:\n",
        "                    result_files = [f for f in os.listdir(result_subdir)\n",
        "                                  if f.lower().endswith(('.jpg', '.png'))]\n",
        "                    if result_files:\n",
        "                        success = True\n",
        "\n",
        "                self.result_queue.put((frame_idx, success))\n",
        "                task_queue.task_done()\n",
        "\n",
        "            except queue.Empty:\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                self.result_queue.put((frame_idx if 'frame_idx' in locals() else -1, False))\n",
        "                if 'task_queue' in locals():\n",
        "                    task_queue.task_done()\n",
        "\n",
        "    def process_frames_dual_gpu(self, source_img: str, frame_dir: str, output_dir: str) -> int:\n",
        "        \"\"\"듀얼 GPU 프레임 처리\"\"\"\n",
        "        if not os.path.exists(source_img):\n",
        "            return 0\n",
        "\n",
        "        frames = sorted([f for f in os.listdir(frame_dir) if f.lower().endswith('.jpg')])\n",
        "        if not frames:\n",
        "            return 0\n",
        "\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"  📸 소스 이미지: {os.path.basename(source_img)}\")\n",
        "        print(f\"  🎬 처리할 프레임: {len(frames)}개\")\n",
        "        print(f\"  🚀 듀얼 GPU 처리 시작...\")\n",
        "\n",
        "        # 작업 분배\n",
        "        for i, frame_name in enumerate(frames):\n",
        "            frame_path = os.path.join(frame_dir, frame_name)\n",
        "            result_subdir = os.path.join(output_dir, f'frame_{i:04d}')\n",
        "            os.makedirs(result_subdir, exist_ok=True)\n",
        "\n",
        "            # 라운드 로빈으로 GPU에 분배\n",
        "            if i % 2 == 0:\n",
        "                self.gpu0_queue.put((source_img, frame_path, result_subdir, i))\n",
        "            else:\n",
        "                self.gpu1_queue.put((source_img, frame_path, result_subdir, i))\n",
        "\n",
        "        # GPU 워커 스레드 시작\n",
        "        gpu0_thread = threading.Thread(target=self.gpu_worker, args=(0, self.gpu0_queue))\n",
        "        gpu1_thread = threading.Thread(target=self.gpu_worker, args=(1, self.gpu1_queue))\n",
        "\n",
        "        gpu0_thread.start()\n",
        "        gpu1_thread.start()\n",
        "\n",
        "        # 진행 상황 모니터링\n",
        "        success_count = 0\n",
        "        completed = 0\n",
        "\n",
        "        with tqdm(total=len(frames), desc=\"듀얼 GPU SimSwap\") as pbar:\n",
        "            while completed < len(frames):\n",
        "                try:\n",
        "                    frame_idx, success = self.result_queue.get(timeout=30.0)\n",
        "                    if success:\n",
        "                        success_count += 1\n",
        "                    completed += 1\n",
        "                    pbar.update(1)\n",
        "                except queue.Empty:\n",
        "                    print(\"  ⚠️ GPU 처리 타임아웃, 계속 진행...\")\n",
        "                    break\n",
        "\n",
        "        # 워커 스레드 종료\n",
        "        self.gpu0_queue.put(None)\n",
        "        self.gpu1_queue.put(None)\n",
        "        gpu0_thread.join(timeout=10)\n",
        "        gpu1_thread.join(timeout=10)\n",
        "\n",
        "        print(f\"  ✅ 듀얼 GPU 성공: {success_count}/{len(frames)}\")\n",
        "        return success_count\n",
        "\n",
        "\n",
        "class GPUSimSwapPipeline:\n",
        "    \"\"\"GPU 가속 SimSwap 파이프라인 + RIFE 보간\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.video_processor = GPUVideoProcessor()\n",
        "        self.simswap_processor = DualGPUSimSwapProcessor()\n",
        "        self.rife_interpolator = RIFEInterpolator()\n",
        "\n",
        "        # 초기 설정\n",
        "        SimSwapSetup.fix_compatibility()\n",
        "\n",
        "        print(\"🚀 듀얼 GPU + RIFE 파이프라인 초기화 완료\")\n",
        "\n",
        "    def process_single_pair(self, video_path: str, image_path: str, output_dir: str,\n",
        "                          frame_interval: int = 5) -> Tuple[bool, Optional[str]]:\n",
        "        \"\"\"GPU 가속 단일 쌍 처리\"\"\"\n",
        "\n",
        "        frame_dir = os.path.join(output_dir, \"frames\")\n",
        "        swap_dir = os.path.join(output_dir, \"swapped\")\n",
        "\n",
        "        try:\n",
        "            # 1. GPU 가속 프레임 추출\n",
        "            print(\"  1️⃣ GPU 가속 프레임 추출\")\n",
        "            original_fps, new_fps = self.video_processor.extract_frames_gpu(\n",
        "                video_path, frame_dir, frame_interval\n",
        "            )\n",
        "            if original_fps is None:\n",
        "                return False, None\n",
        "\n",
        "            # 2. 듀얼 GPU SimSwap 처리\n",
        "            print(\"  2️⃣ 듀얼 GPU 얼굴 교체\")\n",
        "            success_count = self.simswap_processor.process_frames_dual_gpu(\n",
        "                image_path, frame_dir, swap_dir\n",
        "            )\n",
        "            if success_count == 0:\n",
        "                return False, None\n",
        "\n",
        "            # 3. GPU 가속 비디오 생성\n",
        "            print(\"  3️⃣ GPU 가속 비디오 생성\")\n",
        "            base_video = os.path.join(output_dir, \"base_video.mp4\")\n",
        "            if not self.video_processor.create_video_gpu(swap_dir, base_video, new_fps):\n",
        "                return False, None\n",
        "\n",
        "            return True, base_video\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ GPU 처리 중 오류: {e}\")\n",
        "            return False, None\n",
        "\n",
        "    def process_all_pairs(self, video_dir: str, image_dir: str, output_base_dir: str,\n",
        "                         frame_interval: int = 5, use_rife_interpolation: bool = True):\n",
        "        \"\"\"GPU 가속 전체 처리 + RIFE 보간\"\"\"\n",
        "\n",
        "        print(\"=== GPU 가속 SimSwap + RIFE 자동 파이프라인 시작 ===\")\n",
        "        print(f\"🎮 GPU 코어: 2개 (듀얼 GPU 처리)\")\n",
        "        print(f\"📁 영상 디렉토리: {video_dir}\")\n",
        "        print(f\"🖼️ 이미지 디렉토리: {image_dir}\")\n",
        "        print(f\"💾 출력 디렉토리: {output_base_dir}\")\n",
        "        print(f\"⚙️ 프레임 간격: {frame_interval}\")\n",
        "        print(f\"🎬 RIFE 보간 사용: {'예' if use_rife_interpolation else '아니오'}\")\n",
        "\n",
        "        # 설치 상태 확인\n",
        "        if not SimSwapSetup.verify_installation():\n",
        "            print(\"❌ SimSwap 또는 RIFE 설치가 완료되지 않았습니다\")\n",
        "            return\n",
        "\n",
        "        # 매칭 쌍 찾기\n",
        "        pairs = FileManager.get_video_image_pairs(video_dir, image_dir)\n",
        "        if not pairs:\n",
        "            print(\"❌ 매칭되는 영상-이미지 쌍을 찾을 수 없습니다\")\n",
        "            return\n",
        "\n",
        "        os.makedirs(output_base_dir, exist_ok=True)\n",
        "        success_count = 0\n",
        "\n",
        "        for i, pair in enumerate(pairs, 1):\n",
        "            print(f\"\\n📋 [{i}/{len(pairs)}] GPU 가속 + RIFE 처리 중...\")\n",
        "            print(f\"  📹 영상: {os.path.basename(pair['video_path'])}\")\n",
        "            print(f\"  🖼️ 이미지: {os.path.basename(pair['image_path'])}\")\n",
        "\n",
        "            # 출력 디렉토리 설정\n",
        "            pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "            pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "\n",
        "            # GPU 가속 처리 실행\n",
        "            start_time = time.time()\n",
        "            success, base_video = self.process_single_pair(\n",
        "                pair['video_path'], pair['image_path'], pair_output_dir, frame_interval\n",
        "            )\n",
        "\n",
        "            if not success:\n",
        "                print(f\"  ❌ 쌍 {pair['number']} 처리 실패\")\n",
        "                continue\n",
        "\n",
        "            # RIFE 프레임 보간 처리 (옵션)\n",
        "            final_video = base_video\n",
        "            if use_rife_interpolation:\n",
        "                print(\"  4️⃣ RIFE 프레임 보간\")\n",
        "\n",
        "                # 원본 영상의 FPS 확인\n",
        "                cap = cv2.VideoCapture(pair['video_path'])\n",
        "                original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "                cap.release()\n",
        "\n",
        "                rife_output = os.path.join(pair_output_dir, f\"{pair_name}_rife.mp4\")\n",
        "\n",
        "                # RIFE 보간 실행\n",
        "                if self.rife_interpolator.interpolate_video(base_video, rife_output, original_fps):\n",
        "                    final_video = rife_output\n",
        "                    print(f\"  ✅ RIFE 보간 완료\")\n",
        "                else:\n",
        "                    print(f\"  ⚠️ RIFE 보간 실패, 기본 비디오 사용\")\n",
        "\n",
        "            elapsed_time = time.time() - start_time\n",
        "            print(f\"  🎉 완료: {os.path.basename(final_video)} ({elapsed_time:.1f}초)\")\n",
        "            success_count += 1\n",
        "\n",
        "        print(f\"\\n🎉 GPU 가속 + RIFE 처리 완료! {success_count}/{len(pairs)}개 성공\")\n",
        "        print(f\"📂 결과 저장 위치: {output_base_dir}\")\n",
        "\n",
        "\n",
        "# GPU 가속 + RIFE 실행 함수\n",
        "def run_gpu_simswap_with_rife(\n",
        "    video_dir: str = \"/content/input_videos\",\n",
        "    image_dir: str = \"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "    output_dir: str = \"/content/simswap_results\",\n",
        "    frame_interval: int = 5,\n",
        "    use_rife_interpolation: bool = True\n",
        "):\n",
        "    \"\"\"GPU 가속 SimSwap + RIFE 파이프라인 실행\"\"\"\n",
        "    pipeline = GPUSimSwapPipeline()\n",
        "    pipeline.process_all_pairs(\n",
        "        video_dir=video_dir,\n",
        "        image_dir=image_dir,\n",
        "        output_base_dir=output_dir,\n",
        "        frame_interval=frame_interval,\n",
        "        use_rife_interpolation=use_rife_interpolation\n",
        "    )\n",
        "\n",
        "\n",
        "# 메인 실행\n",
        "if __name__ == \"__main__\":\n",
        "    # GPU 가속 + RIFE 설정으로 실행\n",
        "    run_gpu_simswap_with_rife()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1kGVyXpoJG-",
        "outputId": "e2da3a6e-8520-412b-9102-65e8543b4dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 GPU 호환성 수정 중...\n",
            "✅ GPU 호환성 수정 완료\n",
            "🚀 듀얼 GPU + RIFE 파이프라인 초기화 완료\n",
            "=== GPU 가속 SimSwap + RIFE 자동 파이프라인 시작 ===\n",
            "🎮 GPU 코어: 2개 (듀얼 GPU 처리)\n",
            "📁 영상 디렉토리: /content/input_videos\n",
            "🖼️ 이미지 디렉토리: /content/experiments/restyle_e4e_sg3/inference_results/0\n",
            "💾 출력 디렉토리: /content/simswap_results\n",
            "⚙️ 프레임 간격: 5\n",
            "🎬 RIFE 보간 사용: 예\n",
            "📹 영상 파일: 1개\n",
            "🖼️ 이미지 파일: 1개\n",
            "🎯 매칭된 쌍: 1개\n",
            "\n",
            "📋 [1/1] GPU 가속 + RIFE 처리 중...\n",
            "  📹 영상: 0002.mp4\n",
            "  🖼️ 이미지: 0002.jpg\n",
            "  1️⃣ GPU 가속 프레임 추출\n",
            "  ✅ GPU로 62개 프레임 추출 (원본: 30.0fps → 새로운: 6.0fps)\n",
            "  2️⃣ 듀얼 GPU 얼굴 교체\n",
            "  📸 소스 이미지: 0002.jpg\n",
            "  🎬 처리할 프레임: 62개\n",
            "  🚀 듀얼 GPU 처리 시작...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "듀얼 GPU SimSwap: 100%|██████████| 62/62 [06:01<00:00,  5.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ 듀얼 GPU 성공: 31/62\n",
            "  3️⃣ GPU 가속 비디오 생성\n",
            "  ✅ GPU 비디오 생성 완료: base_video.mp4\n",
            "  4️⃣ RIFE 프레임 보간\n",
            "  🎬 RIFE 프레임 보간 시작...\n",
            "    입력: base_video.mp4\n",
            "    출력: pair_002_0002_rife.mp4\n",
            "    목표 FPS: 30.0 (현재: 6.0)\n",
            "  ✅ RIFE 보간 완료 (최종 FPS: 30.0)\n",
            "  ✅ RIFE 보간 완료\n",
            "  🎉 완료: pair_002_0002_rife.mp4 (371.7초)\n",
            "\n",
            "🎉 GPU 가속 + RIFE 처리 완료! 1/1개 성공\n",
            "📂 결과 저장 위치: /content/simswap_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"numpy<2.0\" --force-reinstall"
      ],
      "metadata": {
        "id": "kDcVGsJyRtKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚙️ CUDA 확인용 PyTorch 설치\n",
        "pip install torch torchvision\n",
        "\n",
        "# 🔧 호환성 문제 해결 및 필수 패키지 설치\n",
        "pip install pretrainedmodels\n",
        "pip install efficientnet-pytorch\n",
        "pip install kornia  # torchgeometry의 대체 패키지\n",
        "\n",
        "# 🧩 AdversarialDeepFakes 종속 패키지 설치\n",
        "pip install opencv-python\n",
        "pip install scipy\n",
        "pip install scikit-image\n",
        "pip install moviepy\n",
        "pip install imageio\n",
        "pip install matplotlib\n",
        "pip install tqdm\n",
        "pip install dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fmDR3ZDHM7Ye",
        "outputId": "dbf46a02-152d-4348-9948-ffa4d782af4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'AdversarialDeepFakes' already exists and is not an empty directory.\n",
            "/content/AdversarialDeepFakes\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Collecting numpy>=1.24 (from scikit-image)\n",
            "  Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.34.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 6.31.1 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.0 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e5d8a507a56a40f09876eaf1af4a6cd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.3.0)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.34.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.6.15)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.34.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (2.3.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (15.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚙️ CUDA 확인\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# 📁 MesoNet 모델 다운로드 (이미 있는 링크 사용)\n",
        "!mkdir -p faceforensics++_models_subset/face_detection/Meso\n",
        "!wget -O faceforensics++_models_subset/face_detection/Meso/Meso4_deepfake.pkl \\\n",
        "  \"https://github.com/HongguLiu/MesoNet-Pytorch/blob/master/output/Mesonet/best.pkl?raw=true\"\n",
        "\n",
        "# 모델 파일 확인\n",
        "if os.path.exists('faceforensics++_models_subset/face_detection/Meso/Meso4_deepfake.pkl'):\n",
        "    file_size = os.path.getsize('faceforensics++_models_subset/face_detection/Meso/Meso4_deepfake.pkl')\n",
        "    print(f\"✅ MesoNet 모델 파일 크기: {file_size:,} bytes\")\n",
        "else:\n",
        "    print(\"❌ MesoNet 모델 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "# 🔧 의존성 설치\n",
        "!pip install \"numpy<2.0\" --force-reinstall\n",
        "!pip install pretrainedmodels efficientnet-pytorch kornia\n",
        "\n",
        "# 🔄 torchgeometry를 kornia로 대체\n",
        "import fileinput\n",
        "robust_transforms_path = \"/content/AdversarialDeepFakes/robust_transforms.py\"\n",
        "if os.path.exists(robust_transforms_path):\n",
        "    with fileinput.FileInput(robust_transforms_path, inplace=True) as file:\n",
        "        for line in file:\n",
        "            if \"import torchgeometry as tgm\" in line:\n",
        "                print(\"import kornia as tgm\")\n",
        "            else:\n",
        "                print(line, end='')\n",
        "    print(\"✅ torchgeometry를 kornia로 대체 완료\")# ⚙️ CUDA 확인\n",
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "# 📁 XceptionNet 모델 다운로드\n",
        "!mkdir -p faceforensics++_models_subset/xception\n",
        "!wget -O faceforensics++_models_subset/xception/all_c23.p https://www.dropbox.com/s/0t2k23t3bzs3j7f/all_c23.p?dl=1\n",
        "\n",
        "# 🔧 NumPy 호환성 문제 해결 및 누락된 의존성 설치\n",
        "!pip install \"numpy<2.0\" --force-reinstall\n",
        "!pip install pretrainedmodels\n",
        "!pip install efficientnet-pytorch\n",
        "!pip install kornia  # torchgeometry의 후속 패키지\n",
        "\n",
        "# 🔄 torchgeometry를 kornia로 대체하기 위한 코드 수정\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "# robust_transforms.py에서 torchgeometry를 kornia로 변경\n",
        "robust_transforms_path = \"/content/AdversarialDeepFakes/robust_transforms.py\"\n",
        "if os.path.exists(robust_transforms_path):\n",
        "    with fileinput.FileInput(robust_transforms_path, inplace=True) as file:\n",
        "        for line in file:\n",
        "            if \"import torchgeometry as tgm\" in line:\n",
        "                print(\"import kornia as tgm\")\n",
        "            else:\n",
        "                print(line, end='')\n",
        "    print(\"✅ torchgeometry를 kornia로 대체 완료\")\n",
        "\n",
        "# 파이썬 재시작을 위한 환경 재설정\n",
        "print(\"🔄 환경 재설정 중...\")\n",
        "\n",
        "# 🎬 SimSwap 결과 영상들에 적대적 공격 적용\n",
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "# SimSwap 결과 폴더에서 RIFE 보간된 영상들 찾기\n",
        "simswap_results_dir = \"/content/simswap_results\"\n",
        "rife_videos = []\n",
        "\n",
        "# 모든 pair 폴더를 돌면서 _rife.mp4 파일들 찾기\n",
        "if os.path.exists(simswap_results_dir):\n",
        "    for item in os.listdir(simswap_results_dir):\n",
        "        pair_path = os.path.join(simswap_results_dir, item)\n",
        "        if os.path.isdir(pair_path):\n",
        "            # 각 폴더에서 _rife.mp4로 끝나는 파일들 찾기\n",
        "            rife_files = glob(os.path.join(pair_path, \"*_rife.mp4\"))\n",
        "            if rife_files:\n",
        "                rife_videos.extend(rife_files)\n",
        "            else:\n",
        "                # RIFE 파일이 없으면 base_video.mp4 사용\n",
        "                base_video = os.path.join(pair_path, \"base_video.mp4\")\n",
        "                if os.path.exists(base_video):\n",
        "                    rife_videos.append(base_video)\n",
        "\n",
        "print(f\"🎯 발견된 RIFE 영상 파일: {len(rife_videos)}개\")\n",
        "for video in rife_videos:\n",
        "    print(f\"  - {os.path.basename(video)}\")\n",
        "\n",
        "# 📦 각 영상에 적대적 공격 적용\n",
        "final_output_dir = \"/content/adversarial_final_results\"\n",
        "!mkdir -p {final_output_dir}\n",
        "\n",
        "for i, video_path in enumerate(rife_videos, 1):\n",
        "    print(f\"\\n🔥 [{i}/{len(rife_videos)}] 적대적 공격 적용 중: {os.path.basename(video_path)}\")\n",
        "\n",
        "    temp_output = f\"temp_adv_{i}\"\n",
        "    !mkdir -p {temp_output}\n",
        "\n",
        "    # 🔥 CNN + RNN 탐지기를 우회하기 위한 최적화된 적대적 공격 실행\n",
        "    # 절대 경로로 모델 파일 지정\n",
        "    !cd /content/AdversarialDeepFakes && python attack.py \\\n",
        "      -i {video_path} \\\n",
        "      -mi /content/faceforensics++_models_subset/face_detection/Meso/Meso4_deepfake.pkl \\\n",
        "      -mt meso \\\n",
        "      -o /content/{temp_output} \\\n",
        "      -a black_box_robust \\\n",
        "      --cuda \\\n",
        "      --compress\n",
        "\n",
        "    # 결과를 최종 폴더로 이동\n",
        "    for result_file in os.listdir(temp_output):\n",
        "        if result_file.endswith(('.mp4', '.avi')):\n",
        "            original_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "            new_name = f\"{original_name}_adversarial.mp4\"\n",
        "            shutil.copy(\n",
        "                os.path.join(temp_output, result_file),\n",
        "                os.path.join(final_output_dir, new_name)\n",
        "            )\n",
        "            print(f\"  ✅ 저장완료: {new_name}\")\n",
        "\n",
        "    # 임시 폴더 정리\n",
        "    shutil.rmtree(temp_output)\n",
        "\n",
        "print(f\"\\n🎉 모든 적대적 공격 완료!\")\n",
        "print(f\"📂 최종 결과 저장 위치: {final_output_dir}\")\n",
        "print(f\"📊 생성된 파일 수: {len(os.listdir(final_output_dir))}개\")\n",
        "print(f\"💡 다운로드는 별도 코드로 실행하세요!\")"
      ],
      "metadata": {
        "id": "YrfJSsFONTpQ",
        "outputId": "71ca4453-cb31-4fde-8cbc-fafd99b9ac63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ MesoNet 모델 로딩 코드 수정 완료\n"
          ]
        }
      ]
    }
  ]
}