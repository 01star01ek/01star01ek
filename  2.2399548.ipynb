{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%202.2399548.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로딩"
      ],
      "metadata": {
        "id": "FnfNNJz2BwN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data():\n",
        "    train_path = '/content/u.base'\n",
        "    test_path = '/content/u.test'\n",
        "\n",
        "    # Load training and testing data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Determine the number of users and movies\n",
        "    num_users = max(train_data['user_id'].max(), test_data['user_id'].max())\n",
        "    num_movies = max(train_data['item_id'].max(), test_data['item_id'].max())\n",
        "\n",
        "    # Convert to zero-based index\n",
        "    train_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['user_id', 'item_id']] -= 1\n",
        "    test_data[['rating']] = 1 # NaN을 모두 1로 바꿔줌\n",
        "\n",
        "    train, valid = train_test_split(train_data, test_size=0.1, random_state = 1234)\n",
        "\n",
        "    # Create matrices\n",
        "    train_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "    valid_ratings_matrix = np.zeros((num_users, num_movies))\n",
        "\n",
        "\n",
        "    for row in train.itertuples():\n",
        "        train_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "    for row in valid.itertuples():\n",
        "        valid_ratings_matrix[row.user_id, row.item_id] = (row.rating - 1) / 4.0\n",
        "\n",
        "    return num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data\n"
      ],
      "metadata": {
        "id": "p2EvqZIaudah"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation 평가"
      ],
      "metadata": {
        "id": "DhrtYhPjB0yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation 평가\n",
        "def eval(model, train_data, valid_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = np.where(valid_data > 0)\n",
        "\n",
        "    # 예측값을 원래 스케일로 복원 (0-1 -> 1-5)\n",
        "    pred_original_scale = pred_u_score * 4.0 + 1.0\n",
        "    valid_original_scale = valid_data * 4.0 + 1.0\n",
        "\n",
        "    # RMSE 계산\n",
        "    rmse = np.sqrt(mean_squared_error(valid_original_scale[target_item], pred_original_scale[target_item]))\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "53KhetYhBsVP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델"
      ],
      "metadata": {
        "id": "3h2XEB-lB3NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = sigmoid(x)\n",
        "        self.out = out\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = dout * (1.0 - self.out) * self.out\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "\n",
        "        self.x = None\n",
        "        self.original_x_shape = None\n",
        "        # 가중치와 편향 매개변수의 미분\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 텐서 대응\n",
        "        self.original_x_shape = x.shape\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        self.x = x\n",
        "\n",
        "        out = np.dot(self.x, self.W) + self.b\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
        "        return dx\n",
        "\n",
        "\n",
        "\n",
        "class MSELoss:\n",
        "    def __init__(self, weight_decay_lambda=0.01):\n",
        "        self.loss = None # 손실함수\n",
        "        self.y = None    # 출력\n",
        "        self.t = None    # 정답 레이블\n",
        "        self.t_mask = None   # 정답에서 0이 아닌 부분만 loss 계산\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "\n",
        "    def forward(self, x, t, params=None):\n",
        "        self.t = t\n",
        "        self.t_mask = np.where( t >= 0.5)\n",
        "        self.y = x\n",
        "        self.loss = (self.y - self.t)**2\n",
        "        loss = np.mean(self.loss[self.t_mask]) * 0.5\n",
        "\n",
        "        if params is not None and self.weight_decay_lambda > 0:\n",
        "            weight_decay = 0\n",
        "            for idx in range(1, len(params)//2 + 1):\n",
        "                weight_key = 'W' + str(idx)\n",
        "                if weight_key in params:\n",
        "                    W = params[weight_key]\n",
        "                    weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2)\n",
        "            loss += weight_decay\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dx = ( self.y - self.t) / len(self.y[self.t_mask])\n",
        "        return dx\n"
      ],
      "metadata": {
        "id": "GYuA47b3ZYej"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class MultiLayerNet:\n",
        "    \"\"\"완전연결 다층 신경망\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size_list, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size_list = hidden_size_list\n",
        "        self.hidden_layer_num = len(hidden_size_list)\n",
        "        self.params = {}\n",
        "\n",
        "        # 가중치 초기화\n",
        "        self.__init_weight()\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        for idx in range(1, self.hidden_layer_num+1):\n",
        "            self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "                                                      self.params['b' + str(idx)])\n",
        "            self.layers['Activation_function' + str(idx)] =Relu()\n",
        "\n",
        "        idx = self.hidden_layer_num + 1\n",
        "        self.layers['Affine' + str(idx)] = Affine(self.params['W' + str(idx)],\n",
        "            self.params['b' + str(idx)])\n",
        "\n",
        "        self.last_layer = MSELoss()\n",
        "\n",
        "    def __init_weight(self):\n",
        "      layer_sizes = [self.input_size]\n",
        "      for hidden_size in self.hidden_size_list:\n",
        "          layer_sizes.append(hidden_size)\n",
        "      layer_sizes.append(self.output_size)\n",
        "\n",
        "\n",
        "      for i in range(1, len(layer_sizes)):\n",
        "          prev_size = layer_sizes[i-1]\n",
        "          current_size = layer_sizes[i]\n",
        "\n",
        "          xavier_scale = np.sqrt(2.0 / (prev_size + current_size))\n",
        "\n",
        "          weight_key = 'W' + str(i)\n",
        "          self.params[weight_key] = xavier_scale * np.random.randn(prev_size, current_size)\n",
        "\n",
        "          bias_key = 'b' + str(i)\n",
        "          self.params[bias_key] = np.zeros(current_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        \"\"\"손실 함수를 구한다.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        손실 함수의 값\n",
        "        \"\"\"\n",
        "        y = self.predict(x)\n",
        "\n",
        "        return self.last_layer.forward(y, t, self.params)\n",
        "\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        \"\"\"기울기를 구한다(오차역전파법).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : 입력 데이터\n",
        "        t : 정답 레이블\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        각 층의 기울기를 담은 딕셔너리(dictionary) 변수\n",
        "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
        "            grads['b1']、grads['b2']、... 각 층의 편향\n",
        "        \"\"\"\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 결과 저장\n",
        "        grads = {}\n",
        "        for idx in range(1, self.hidden_layer_num+2):\n",
        "            grads['W' + str(idx)] = self.layers['Affine' + str(idx)].dW\n",
        "            grads['b' + str(idx)] = self.layers['Affine' + str(idx)].db\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "tnhB1vd3CGIX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ],
      "metadata": {
        "id": "sI6-Qu3JCP59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Adam:\n",
        "\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "    def update(self, params, grads):\n",
        "\n",
        "        if self.m is None or self.v is None:\n",
        "            self.m, self.v = {}, {}\n",
        "            for key in params.keys():\n",
        "                self.m[key] = np.zeros_like(params[key])\n",
        "                self.v[key] = np.zeros_like(params[key])\n",
        "\n",
        "        self.iter += 1\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.m[key] = self.beta1 * self.m[key] + (1.0 - self.beta1) * grads[key]\n",
        "            self.v[key] = self.beta2 * self.v[key] + (1.0 - self.beta2) * (grads[key] ** 2)\n",
        "            m_corrected = self.m[key] / (1.0 - self.beta1 ** self.iter)\n",
        "            v_corrected = self.v[key] / (1.0 - self.beta2 ** self.iter)\n",
        "            params[key] -= self.lr * m_corrected / (np.sqrt(v_corrected) + self.epsilon)"
      ],
      "metadata": {
        "id": "vyN7VyTlCSo6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission 만들기\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pandas import DataFrame\n",
        "def make_submission(model, train_data, test_data):\n",
        "    pred_u_score = model.predict(train_data)\n",
        "    target_item = (test_data['user_id'].to_numpy(), test_data['item_id'].to_numpy())\n",
        "\n",
        "    pred_original_scale = pred_u_score[target_item] * 4.0 + 1.0\n",
        "    pred_original_scale = np.clip(pred_original_scale, 1.0, 5.0)\n",
        "\n",
        "    results = pd.DataFrame()\n",
        "    results[\"target_id\"] = test_data[\"target_id\"]\n",
        "    results[\"rating\"] = pred_original_scale\n",
        "    print(results.head())  # 결과 확인용\n",
        "    results.to_csv('/content/submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DgX4D_md-FwP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "zcb7o5gbCjsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# colab에서 나오는 warning들을 무시\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 결과 재현을 위해 Seed를 고정\n",
        "def seed_everything(random_seed):\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "seed = 1\n",
        "seed_everything(seed)\n",
        "\n",
        "\n",
        "# 0. 데이터 읽기==========\n",
        "num_users, num_movies, train_ratings_matrix, valid_ratings_matrix, test_data = load_data()\n",
        "\n",
        "\n",
        "# 1. 실험용 설정==========\n",
        "train_size = num_users\n",
        "max_epochs = 30\n",
        "batch_size = 60\n",
        "initial_lr = 0.001\n",
        "decay_rate = 0.97\n",
        "patience = 10\n",
        "\n",
        "optimizers = Adam(lr=initial_lr, beta1=0.9, beta2=0.999)\n",
        "train_loss = []\n",
        "Model = MultiLayerNet(\n",
        "        input_size=num_movies, hidden_size_list=[40, 30],\n",
        "        output_size=num_movies)\n",
        "\n",
        "\n",
        "# 2. 훈련 시작==========\n",
        "best_rmse = float('inf')\n",
        "best_epoch = 0\n",
        "best_params = {}\n",
        "counter = 0\n",
        "\n",
        "for i in range(max_epochs):\n",
        "    if i > 10:\n",
        "      optimizers.lr = initial_lr * (decay_rate ** (i-10))\n",
        "\n",
        "    shuffled_user_index = np.asarray(range(num_users))\n",
        "    np.random.shuffle(shuffled_user_index)\n",
        "\n",
        "    batch_num = int(num_users / batch_size) + 1\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for b_idx in range(batch_num):\n",
        "        batch_idx = shuffled_user_index[b_idx*batch_size : (b_idx+1)*batch_size]\n",
        "        if len(batch_idx) == 0:\n",
        "            continue\n",
        "\n",
        "        x_batch = train_ratings_matrix[batch_idx]\n",
        "\n",
        "        grads = Model.gradient(x_batch, x_batch)\n",
        "        optimizers.update(Model.params, grads)\n",
        "\n",
        "        loss = Model.loss(x_batch, x_batch)\n",
        "        train_loss.append(loss)\n",
        "        epoch_loss += loss\n",
        "\n",
        "    avg_loss = epoch_loss / batch_num if batch_num > 0 else 0\n",
        "    print(\"epoch:\" + str(i+1) + \"  loss:\" + str(loss))\n",
        "\n",
        "    current_rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "    print(\"validation rmse:\", current_rmse)\n",
        "\n",
        "    if current_rmse < best_rmse:\n",
        "        print(f\"성능 good RMSE: {best_rmse:.4f} -> {current_rmse:.4f}\")\n",
        "        best_rmse = current_rmse\n",
        "        best_epoch = i\n",
        "\n",
        "        best_params = {}\n",
        "        for key, val in Model.params.items():\n",
        "            best_params[key] = val.copy()\n",
        "\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"성능 bad {counter}/{patience}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {i+1}!\")\n",
        "        print(f\"Best epoch was {best_epoch+1} with RMSE {best_rmse:.4f}\")\n",
        "        break\n",
        "\n",
        "if best_params:\n",
        "    print(f\"최고 성능 모델 복원(에폭 {best_epoch+1})\")\n",
        "    for key in Model.params:\n",
        "        Model.params[key] = best_params[key]\n",
        "\n",
        "# 3. 평가==========\n",
        "rmse = eval(Model, train_ratings_matrix, valid_ratings_matrix)\n",
        "print( \"============================\")\n",
        "print( \"=========== rmse ===========\")\n",
        "print(str(rmse))\n",
        "\n",
        "\n",
        "# # 4. submission만들기==========\n",
        "make_submission(Model, train_ratings_matrix, test_data)"
      ],
      "metadata": {
        "id": "3Te9mcuVBrNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7faedc12-f3c1-469b-9ef2-fd58a4d22e1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1  loss:1.0838344707696024\n",
            "validation rmse: 2.634089832368942\n",
            "성능 good RMSE: inf -> 2.6341\n",
            "epoch:2  loss:1.0273404008537417\n",
            "validation rmse: 2.3488407243575624\n",
            "성능 good RMSE: 2.6341 -> 2.3488\n",
            "epoch:3  loss:1.031708988630329\n",
            "validation rmse: 2.3169989507318043\n",
            "성능 good RMSE: 2.3488 -> 2.3170\n",
            "epoch:4  loss:0.9967510272684623\n",
            "validation rmse: 2.2827068124594385\n",
            "성능 good RMSE: 2.3170 -> 2.2827\n",
            "epoch:5  loss:1.0037297225392203\n",
            "validation rmse: 2.24908877083001\n",
            "성능 good RMSE: 2.2827 -> 2.2491\n",
            "epoch:6  loss:1.039983964435678\n",
            "validation rmse: 2.216837080166916\n",
            "성능 good RMSE: 2.2491 -> 2.2168\n",
            "epoch:7  loss:1.0032588956839374\n",
            "validation rmse: 2.1707818160428074\n",
            "성능 good RMSE: 2.2168 -> 2.1708\n",
            "epoch:8  loss:1.0152918334789396\n",
            "validation rmse: 2.1567197932241715\n",
            "성능 good RMSE: 2.1708 -> 2.1567\n",
            "epoch:9  loss:1.0234796926942704\n",
            "validation rmse: 2.145800426126373\n",
            "성능 good RMSE: 2.1567 -> 2.1458\n",
            "epoch:10  loss:1.00613582486013\n",
            "validation rmse: 2.14238596116963\n",
            "성능 good RMSE: 2.1458 -> 2.1424\n",
            "epoch:11  loss:1.0081221515416727\n",
            "validation rmse: 2.1276531038577313\n",
            "성능 good RMSE: 2.1424 -> 2.1277\n",
            "epoch:12  loss:1.0242155187930777\n",
            "validation rmse: 2.131044802295145\n",
            "성능 bad 1/10\n",
            "epoch:13  loss:1.0194865068076713\n",
            "validation rmse: 2.124312938213947\n",
            "성능 good RMSE: 2.1277 -> 2.1243\n",
            "epoch:14  loss:1.0326271408544885\n",
            "validation rmse: 2.1178334875308638\n",
            "성능 good RMSE: 2.1243 -> 2.1178\n",
            "epoch:15  loss:1.0294504380748883\n",
            "validation rmse: 2.1159849785968667\n",
            "성능 good RMSE: 2.1178 -> 2.1160\n",
            "epoch:16  loss:1.042617590243467\n",
            "validation rmse: 2.1120432997472056\n",
            "성능 good RMSE: 2.1160 -> 2.1120\n",
            "epoch:17  loss:1.0483767011359435\n",
            "validation rmse: 2.1079202683701572\n",
            "성능 good RMSE: 2.1120 -> 2.1079\n",
            "epoch:18  loss:1.065810208278278\n",
            "validation rmse: 2.113029673712589\n",
            "성능 bad 1/10\n",
            "epoch:19  loss:1.0669544718119086\n",
            "validation rmse: 2.109643669444233\n",
            "성능 bad 2/10\n",
            "epoch:20  loss:1.0830886748650779\n",
            "validation rmse: 2.1069961181133703\n",
            "성능 good RMSE: 2.1079 -> 2.1070\n",
            "epoch:21  loss:1.0862570717872018\n",
            "validation rmse: 2.1044748235099715\n",
            "성능 good RMSE: 2.1070 -> 2.1045\n",
            "epoch:22  loss:1.0825192126179262\n",
            "validation rmse: 2.1059535392322557\n",
            "성능 bad 1/10\n",
            "epoch:23  loss:1.0959003366166913\n",
            "validation rmse: 2.103412947112638\n",
            "성능 good RMSE: 2.1045 -> 2.1034\n",
            "epoch:24  loss:1.100233451283397\n",
            "validation rmse: 2.1056996114775575\n",
            "성능 bad 1/10\n",
            "epoch:25  loss:1.103341396832724\n",
            "validation rmse: 2.1091841402801905\n",
            "성능 bad 2/10\n",
            "epoch:26  loss:1.1096889196081492\n",
            "validation rmse: 2.1053123827910536\n",
            "성능 bad 3/10\n",
            "epoch:27  loss:1.0953902966779097\n",
            "validation rmse: 2.1045916510972233\n",
            "성능 bad 4/10\n",
            "epoch:28  loss:1.117710402528869\n",
            "validation rmse: 2.1097895486915146\n",
            "성능 bad 5/10\n",
            "epoch:29  loss:1.1172725188627748\n",
            "validation rmse: 2.108368918074269\n",
            "성능 bad 6/10\n",
            "epoch:30  loss:1.099127491020942\n",
            "validation rmse: 2.105837639553406\n",
            "성능 bad 7/10\n",
            "최고 성능 모델 복원(에폭 23)\n",
            "============================\n",
            "=========== rmse ===========\n",
            "2.105837639553406\n",
            "   target_id    rating\n",
            "0          1  1.196361\n",
            "1          2  1.496953\n",
            "2          3  2.689775\n",
            "3          4  2.252646\n",
            "4          5  1.290622\n"
          ]
        }
      ]
    }
  ]
}