{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy15bvILQzNu9U0IVK5LGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%EC%B5%9C%EC%A2%85%EC%9A%B0%EC%8A%B9%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnWtZK-jtsJ6",
        "outputId": "76b7c2fd-3779-49ea-988a-dc2198fd949d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.4.9)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (4.14.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.4.26)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1060438 sha256=f616035843089a8e68d930ae39e6db694ed463929ee69e7784c1558e6e910ca0\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.18.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_inswapper():\n",
        "    url = \"https://civitai.com/api/download/models/85159\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open('inswapper_128.onnx', 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(\"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}\")\n",
        "        return False\n",
        "\n",
        "download_inswapper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBeREbyCuiFr",
        "outputId": "71285790-8cb4-4c8c-cfe6-ac47b5403f79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "import os\n",
        "\n",
        "# ì„¤ì •\n",
        "app = FaceAnalysis()\n",
        "app.prepare(ctx_id=0, det_size=(320, 320))\n",
        "swapper = insightface.model_zoo.get_model('inswapper_128.onnx')\n",
        "\n",
        "# ì†ŒìŠ¤ ì´ë¯¸ì§€\n",
        "source_img = cv2.imread('source.png')\n",
        "source_faces = app.get(source_img)\n",
        "source_face = source_faces[0]\n",
        "\n",
        "# ë¹„ë””ì˜¤ ì²˜ë¦¬\n",
        "cap = cv2.VideoCapture('target.mp4')\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 10í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬\n",
        "    if frame_count % 10 == 0:\n",
        "        target_faces = app.get(frame)\n",
        "\n",
        "        if len(target_faces) > 0:\n",
        "            # ì–¼êµ´ í•©ì„±\n",
        "            result = swapper.get(frame, target_faces[0], source_face, paste_back=True)\n",
        "\n",
        "            # ì´ë¯¸ì§€ ì €ì¥\n",
        "            cv2.imwrite(f'output/frame_{saved_count:04d}.png', result)\n",
        "            saved_count += 1\n",
        "            print(f\"ì €ì¥: frame_{saved_count:04d}.png\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"ì™„ë£Œ! {saved_count}ê°œ ì´ë¯¸ì§€ ì €ì¥\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln9rNQv7txTk",
        "outputId": "ef4ef0dd-3af6-467a-f0d1-c3baf54bbc65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (320, 320)\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "inswapper-shape: [1, 3, 128, 128]\n",
            "ì €ì¥: frame_0001.png\n",
            "ì €ì¥: frame_0002.png\n",
            "ì €ì¥: frame_0003.png\n",
            "ì €ì¥: frame_0004.png\n",
            "ì €ì¥: frame_0005.png\n",
            "ì €ì¥: frame_0006.png\n",
            "ì €ì¥: frame_0007.png\n",
            "ì €ì¥: frame_0008.png\n",
            "ì €ì¥: frame_0009.png\n",
            "ì €ì¥: frame_0010.png\n",
            "ì €ì¥: frame_0011.png\n",
            "ì €ì¥: frame_0012.png\n",
            "ì €ì¥: frame_0013.png\n",
            "ì €ì¥: frame_0014.png\n",
            "ì €ì¥: frame_0015.png\n",
            "ì €ì¥: frame_0016.png\n",
            "ì €ì¥: frame_0017.png\n",
            "ì €ì¥: frame_0018.png\n",
            "ì €ì¥: frame_0019.png\n",
            "ì €ì¥: frame_0020.png\n",
            "ì €ì¥: frame_0021.png\n",
            "ì €ì¥: frame_0022.png\n",
            "ì €ì¥: frame_0023.png\n",
            "ì €ì¥: frame_0024.png\n",
            "ì €ì¥: frame_0025.png\n",
            "ì €ì¥: frame_0026.png\n",
            "ì €ì¥: frame_0027.png\n",
            "ì €ì¥: frame_0028.png\n",
            "ì €ì¥: frame_0029.png\n",
            "ì €ì¥: frame_0030.png\n",
            "ì €ì¥: frame_0031.png\n",
            "ì €ì¥: frame_0032.png\n",
            "ì €ì¥: frame_0033.png\n",
            "ì €ì¥: frame_0034.png\n",
            "ì €ì¥: frame_0035.png\n",
            "ì €ì¥: frame_0036.png\n",
            "ì™„ë£Œ! 36ê°œ ì´ë¯¸ì§€ ì €ì¥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "print(\"ì˜ìƒ ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°\n",
        "image_files = sorted(glob('output/frame_*.png'))\n",
        "if len(image_files) > 0:\n",
        "    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ í¬ê¸° í™•ì¸\n",
        "    first_img = cv2.imread(image_files[0])\n",
        "    height, width, _ = first_img.shape\n",
        "\n",
        "    # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter('final_result.mp4', fourcc, 30, (width, height))\n",
        "\n",
        "    # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì˜ìƒì— ì¶”ê°€\n",
        "    for img_path in image_files:\n",
        "        img = cv2.imread(img_path)\n",
        "        out.write(img)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"âœ… ì˜ìƒ ì™„ì„±! final_result.mp4 ({len(image_files)}ê°œ í”„ë ˆì„)\")\n",
        "else:\n",
        "    print(\"âŒ ì €ì¥ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GFRuhf_ztk6",
        "outputId": "a9f099d7-46e7-4389-cf08-f1f26dffe05d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì˜ìƒ ìƒì„± ì¤‘...\n",
            "âœ… ì˜ìƒ ì™„ì„±! final_result.mp4 (36ê°œ í”„ë ˆì„)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aslBCf8038t",
        "outputId": "090c899a-2040-4bf6-b3e8-ebc5d6ef9315"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=2a6f2be9ec541a3f655187985f9e59a500127d65d8fdc4b36dab8da35750079c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import GPUtil\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FrameInterpolationBenchmark:\n",
        "    def __init__(self, input_video_path, output_dir=\"benchmark_results\"):\n",
        "        \"\"\"\n",
        "        í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í‰ê°€ ì‹œìŠ¤í…œ\n",
        "\n",
        "        Args:\n",
        "            input_video_path: í…ŒìŠ¤íŠ¸í•  ì…ë ¥ ì˜ìƒ ê²½ë¡œ\n",
        "            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "        \"\"\"\n",
        "        self.input_video = input_video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.results = {}\n",
        "\n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
        "        self.get_video_info()\n",
        "\n",
        "        print(f\"ğŸ¬ ì…ë ¥ ì˜ìƒ: {input_video_path}\")\n",
        "        print(f\"ğŸ“Š ì˜ìƒ ì •ë³´: {self.video_info}\")\n",
        "\n",
        "    def get_video_info(self):\n",
        "        \"\"\"ì…ë ¥ ì˜ìƒ ì •ë³´ ë¶„ì„\"\"\"\n",
        "        cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "        self.video_info = {\n",
        "            'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "            'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "            'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "        }\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    def monitor_resources(self):\n",
        "        \"\"\"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§\"\"\"\n",
        "        cpu_percent = psutil.cpu_percent(interval=1)\n",
        "        memory = psutil.virtual_memory()\n",
        "\n",
        "        gpu_info = []\n",
        "        try:\n",
        "            gpus = GPUtil.getGPUs()\n",
        "            for gpu in gpus:\n",
        "                gpu_info.append({\n",
        "                    'name': gpu.name,\n",
        "                    'utilization': gpu.load * 100,\n",
        "                    'memory_used': gpu.memoryUsed,\n",
        "                    'memory_total': gpu.memoryTotal\n",
        "                })\n",
        "        except:\n",
        "            gpu_info = [{'name': 'N/A', 'utilization': 0, 'memory_used': 0, 'memory_total': 0}]\n",
        "\n",
        "        return {\n",
        "            'cpu_percent': cpu_percent,\n",
        "            'memory_percent': memory.percent,\n",
        "            'memory_used_gb': memory.used / (1024**3),\n",
        "            'gpu_info': gpu_info\n",
        "        }\n",
        "\n",
        "    def test_ffmpeg_minterpolate(self, target_fps=60):\n",
        "        \"\"\"FFmpeg minterpolate í…ŒìŠ¤íŠ¸\"\"\"\n",
        "        print(f\"\\nğŸ”„ FFmpeg minterpolate í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"ffmpeg_minterpolate_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', self.input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci',\n",
        "            '-y', output_path\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
        "\n",
        "                self.results['FFmpeg_minterpolate'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'target_fps': target_fps\n",
        "                }\n",
        "                print(f\"âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"âŒ ì‹¤íŒ¨: {result.stderr}\")\n",
        "                self.results['FFmpeg_minterpolate'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"âŒ ì‹œê°„ ì´ˆê³¼ (300ì´ˆ)\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_rife(self, multiplier=2):\n",
        "        \"\"\"RIFE í…ŒìŠ¤íŠ¸ (GitHubì—ì„œ í´ë¡  í•„ìš”)\"\"\"\n",
        "        print(f\"\\nğŸ”„ RIFE í…ŒìŠ¤íŠ¸ (multiplier: {multiplier})\")\n",
        "\n",
        "        rife_dir = \"ECCV2022-RIFE\"\n",
        "        if not os.path.exists(rife_dir):\n",
        "            print(\"âš ï¸  RIFE ì €ì¥ì†Œ í´ë¡  ì¤‘...\")\n",
        "            subprocess.run(['git', 'clone', 'https://github.com/megvii-research/ECCV2022-RIFE.git'])\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"rife_x{multiplier}.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'python', f'{rife_dir}/inference_video.py',\n",
        "            f'--exp={multiplier}',\n",
        "            f'--video={self.input_video}',\n",
        "            f'--output={output_path}'\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            os.chdir(rife_dir)\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n",
        "            os.chdir('..')\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(output_path):\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "                self.results['RIFE'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'multiplier': multiplier\n",
        "                }\n",
        "                print(f\"âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"âŒ ì‹¤íŒ¨: {result.stderr}\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"âŒ ì‹œê°„ ì´ˆê³¼ (600ì´ˆ)\")\n",
        "            self.results['RIFE'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['RIFE'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_frame_blending(self, target_fps=60):\n",
        "        \"\"\"ê°„ë‹¨í•œ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ê¸°ì¤€ì„ )\"\"\"\n",
        "        print(f\"\\nğŸ”„ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"frame_blending_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, target_fps,\n",
        "                                (self.video_info['width'], self.video_info['height']))\n",
        "\n",
        "            frames = []\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frames.append(frame)\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "            # í”„ë ˆì„ ê°„ ë¸”ë Œë”©ìœ¼ë¡œ ë³´ê°„\n",
        "            interpolation_factor = target_fps / self.video_info['fps']\n",
        "\n",
        "            for i in range(len(frames) - 1):\n",
        "                out.write(frames[i])\n",
        "\n",
        "                # ì¤‘ê°„ í”„ë ˆì„ë“¤ ìƒì„±\n",
        "                num_inter_frames = int(interpolation_factor) - 1\n",
        "                for j in range(1, num_inter_frames + 1):\n",
        "                    alpha = j / (num_inter_frames + 1)\n",
        "                    blended = cv2.addWeighted(frames[i], 1-alpha, frames[i+1], alpha, 0)\n",
        "                    out.write(blended)\n",
        "\n",
        "            if frames:\n",
        "                out.write(frames[-1])\n",
        "\n",
        "            out.release()\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            end_resources = self.monitor_resources()\n",
        "            file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "            self.results['Frame_Blending'] = {\n",
        "                'status': 'success',\n",
        "                'processing_time': processing_time,\n",
        "                'output_path': output_path,\n",
        "                'file_size_mb': file_size,\n",
        "                'start_resources': start_resources,\n",
        "                'end_resources': end_resources,\n",
        "                'target_fps': target_fps\n",
        "            }\n",
        "            print(f\"âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['Frame_Blending'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def calculate_quality_metrics(self, method_name, output_path):\n",
        "        \"\"\"í’ˆì§ˆ ì§€í‘œ ê³„ì‚° (PSNR, SSIM)\"\"\"\n",
        "        print(f\"\\nğŸ“Š {method_name} í’ˆì§ˆ ë¶„ì„...\")\n",
        "\n",
        "        try:\n",
        "            # ì›ë³¸ê³¼ ê²°ê³¼ ì˜ìƒì—ì„œ ìƒ˜í”Œ í”„ë ˆì„ ì¶”ì¶œ\n",
        "            original_frames = self.extract_sample_frames(self.input_video, num_samples=10)\n",
        "            result_frames = self.extract_sample_frames(output_path, num_samples=10)\n",
        "\n",
        "            if len(original_frames) == 0 or len(result_frames) == 0:\n",
        "                return None\n",
        "\n",
        "            psnr_scores = []\n",
        "            ssim_scores = []\n",
        "\n",
        "            # í¬ê¸° ë§ì¶”ê¸°\n",
        "            min_samples = min(len(original_frames), len(result_frames))\n",
        "\n",
        "            for i in range(min_samples):\n",
        "                orig = original_frames[i]\n",
        "                result = result_frames[i]\n",
        "\n",
        "                # í¬ê¸° ì¡°ì •\n",
        "                if orig.shape != result.shape:\n",
        "                    result = cv2.resize(result, (orig.shape[1], orig.shape[0]))\n",
        "\n",
        "                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
        "                orig_gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
        "                result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # PSNR ê³„ì‚°\n",
        "                psnr_val = psnr(orig_gray, result_gray, data_range=255)\n",
        "                psnr_scores.append(psnr_val)\n",
        "\n",
        "                # SSIM ê³„ì‚°\n",
        "                ssim_val = ssim(orig_gray, result_gray, data_range=255)\n",
        "                ssim_scores.append(ssim_val)\n",
        "\n",
        "            quality_metrics = {\n",
        "                'avg_psnr': np.mean(psnr_scores),\n",
        "                'avg_ssim': np.mean(ssim_scores),\n",
        "                'psnr_std': np.std(psnr_scores),\n",
        "                'ssim_std': np.std(ssim_scores)\n",
        "            }\n",
        "\n",
        "            self.results[method_name]['quality_metrics'] = quality_metrics\n",
        "            print(f\"   PSNR: {quality_metrics['avg_psnr']:.2f} Â± {quality_metrics['psnr_std']:.2f}\")\n",
        "            print(f\"   SSIM: {quality_metrics['avg_ssim']:.3f} Â± {quality_metrics['ssim_std']:.3f}\")\n",
        "\n",
        "            return quality_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_sample_frames(self, video_path, num_samples=10):\n",
        "        \"\"\"ì˜ìƒì—ì„œ ìƒ˜í”Œ í”„ë ˆì„ ì¶”ì¶œ\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if frame_count == 0:\n",
        "            cap.release()\n",
        "            return []\n",
        "\n",
        "        frames = []\n",
        "        step = max(1, frame_count // num_samples)\n",
        "\n",
        "        for i in range(0, frame_count, step):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "                if len(frames) >= num_samples:\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def run_all_tests(self):\n",
        "        \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
        "        print(\"ğŸš€ í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. FFmpeg minterpolate\n",
        "        self.test_ffmpeg_minterpolate(target_fps=60)\n",
        "\n",
        "        # 2. Frame Blending (ê¸°ì¤€ì„ )\n",
        "        self.test_frame_blending(target_fps=60)\n",
        "\n",
        "        # 3. RIFE (ì¡°ê±´ë¶€)\n",
        "        if self.should_test_rife():\n",
        "            self.test_rife(multiplier=2)\n",
        "        else:\n",
        "            print(\"\\nâš ï¸  RIFE í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ì˜ì¡´ì„± ì—†ìŒ)\")\n",
        "\n",
        "        # í’ˆì§ˆ ë¶„ì„\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ“Š í’ˆì§ˆ ë¶„ì„ ì‹œì‘...\")\n",
        "\n",
        "        for method, result in self.results.items():\n",
        "            if result.get('status') == 'success':\n",
        "                self.calculate_quality_metrics(method, result['output_path'])\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”\n",
        "        self.save_results()\n",
        "        self.create_comparison_report()\n",
        "\n",
        "    def should_test_rife(self):\n",
        "        \"\"\"RIFE í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\"\"\"\n",
        "        try:\n",
        "            # PyTorch ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸\n",
        "            import torch\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
        "        results_file = os.path.join(self.output_dir, \"benchmark_results.json\")\n",
        "\n",
        "        # datetime ê°ì²´ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "        serializable_results = {}\n",
        "        for method, result in self.results.items():\n",
        "            serializable_results[method] = {}\n",
        "            for key, value in result.items():\n",
        "                if isinstance(value, (dict, list, str, int, float, bool)) or value is None:\n",
        "                    serializable_results[method][key] = value\n",
        "                else:\n",
        "                    serializable_results[method][key] = str(value)\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'input_video_info': self.video_info,\n",
        "                'results': serializable_results\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}\")\n",
        "\n",
        "    def create_comparison_report(self):\n",
        "        \"\"\"ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ“Š ìµœì¢… ë¹„êµ ë¦¬í¬íŠ¸\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        successful_methods = {k: v for k, v in self.results.items() if v.get('status') == 'success'}\n",
        "\n",
        "        if not successful_methods:\n",
        "            print(\"âŒ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "            return\n",
        "\n",
        "        # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”\n",
        "        print(f\"{'ë°©ë²•':<20} {'ì²˜ë¦¬ì‹œê°„(ì´ˆ)':<12} {'íŒŒì¼í¬ê¸°(MB)':<12} {'PSNR':<8} {'SSIM':<8}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for method, result in successful_methods.items():\n",
        "            processing_time = result.get('processing_time', 0)\n",
        "            file_size = result.get('file_size_mb', 0)\n",
        "\n",
        "            quality = result.get('quality_metrics', {})\n",
        "            psnr_val = quality.get('avg_psnr', 0)\n",
        "            ssim_val = quality.get('avg_ssim', 0)\n",
        "\n",
        "            print(f\"{method:<20} {processing_time:<12.2f} {file_size:<12.2f} {psnr_val:<8.2f} {ssim_val:<8.3f}\")\n",
        "\n",
        "        # ì¶”ì²œ ê²°ê³¼\n",
        "        print(\"\\nğŸ† ì¶”ì²œ ê²°ê³¼:\")\n",
        "\n",
        "        # ì†ë„ ê¸°ì¤€ ìµœê³ \n",
        "        fastest = min(successful_methods.items(), key=lambda x: x[1].get('processing_time', float('inf')))\n",
        "        print(f\"   âš¡ ê°€ì¥ ë¹ ë¦„: {fastest[0]} ({fastest[1].get('processing_time', 0):.2f}ì´ˆ)\")\n",
        "\n",
        "        # í’ˆì§ˆ ê¸°ì¤€ ìµœê³  (SSIM)\n",
        "        quality_methods = {k: v for k, v in successful_methods.items() if v.get('quality_metrics')}\n",
        "        if quality_methods:\n",
        "            best_quality = max(quality_methods.items(),\n",
        "                             key=lambda x: x[1].get('quality_metrics', {}).get('avg_ssim', 0))\n",
        "            ssim_score = best_quality[1].get('quality_metrics', {}).get('avg_ssim', 0)\n",
        "            print(f\"   ğŸ¯ ìµœê³  í’ˆì§ˆ: {best_quality[0]} (SSIM: {ssim_score:.3f})\")\n",
        "\n",
        "        # íŒŒì¼ í¬ê¸° ìµœì í™”\n",
        "        smallest = min(successful_methods.items(), key=lambda x: x[1].get('file_size_mb', float('inf')))\n",
        "        print(f\"   ğŸ’¾ ìµœì†Œ ìš©ëŸ‰: {smallest[0]} ({smallest[1].get('file_size_mb', 0):.2f}MB)\")\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "def main():\n",
        "    # í…ŒìŠ¤íŠ¸í•  ì˜ìƒ ê²½ë¡œ\n",
        "    input_video = \"final_result.mp4\"  # ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  ì˜ìƒ ê²½ë¡œ ì…ë ¥\n",
        "\n",
        "    if not os.path.exists(input_video):\n",
        "        print(f\"âŒ ì…ë ¥ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_video}\")\n",
        "        print(\"í…ŒìŠ¤íŠ¸ìš© ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”!\")\n",
        "        return\n",
        "\n",
        "    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
        "    benchmark = FrameInterpolationBenchmark(input_video)\n",
        "    benchmark.run_all_tests()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B54CmXX90zjB",
        "outputId": "320343fc-b444-4a10-c7a0-b90068fa788b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¬ ì…ë ¥ ì˜ìƒ: final_result.mp4\n",
            "ğŸ“Š ì˜ìƒ ì •ë³´: {'fps': 30.0, 'width': 966, 'height': 500, 'frame_count': 36, 'duration': 1.2}\n",
            "ğŸš€ í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘!\n",
            "============================================================\n",
            "\n",
            "ğŸ”„ FFmpeg minterpolate í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: 60)\n",
            "âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: 8.00ì´ˆ, íŒŒì¼í¬ê¸°: 0.16MB\n",
            "\n",
            "ğŸ”„ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: 60)\n",
            "âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: 1.24ì´ˆ, íŒŒì¼í¬ê¸°: 0.58MB\n",
            "\n",
            "ğŸ”„ RIFE í…ŒìŠ¤íŠ¸ (multiplier: 2)\n",
            "âš ï¸  RIFE ì €ì¥ì†Œ í´ë¡  ì¤‘...\n",
            "âŒ ì‹¤íŒ¨: python3: can't open file '/content/ECCV2022-RIFE/ECCV2022-RIFE/inference_video.py': [Errno 2] No such file or directory\n",
            "\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š í’ˆì§ˆ ë¶„ì„ ì‹œì‘...\n",
            "\n",
            "ğŸ“Š FFmpeg_minterpolate í’ˆì§ˆ ë¶„ì„...\n",
            "   PSNR: 42.58 Â± 0.60\n",
            "   SSIM: 0.980 Â± 0.002\n",
            "\n",
            "ğŸ“Š Frame_Blending í’ˆì§ˆ ë¶„ì„...\n",
            "   PSNR: 28.28 Â± 5.74\n",
            "   SSIM: 0.902 Â± 0.046\n",
            "ğŸ’¾ ê²°ê³¼ ì €ì¥: benchmark_results/benchmark_results.json\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ìµœì¢… ë¹„êµ ë¦¬í¬íŠ¸\n",
            "============================================================\n",
            "ë°©ë²•                   ì²˜ë¦¬ì‹œê°„(ì´ˆ)      íŒŒì¼í¬ê¸°(MB)     PSNR     SSIM    \n",
            "----------------------------------------------------------------------\n",
            "FFmpeg_minterpolate  8.00         0.16         42.58    0.980   \n",
            "Frame_Blending       1.24         0.58         28.28    0.902   \n",
            "\n",
            "ğŸ† ì¶”ì²œ ê²°ê³¼:\n",
            "   âš¡ ê°€ì¥ ë¹ ë¦„: Frame_Blending (1.24ì´ˆ)\n",
            "   ğŸ¯ ìµœê³  í’ˆì§ˆ: FFmpeg_minterpolate (SSIM: 0.980)\n",
            "   ğŸ’¾ ìµœì†Œ ìš©ëŸ‰: FFmpeg_minterpolate (0.16MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_missing_frames():\n",
        "    \"\"\"ë¹ ì§„ í”„ë ˆì„ë“¤ì„ ë³´ê°„ìœ¼ë¡œ ì±„ìš°ê¸°\"\"\"\n",
        "    import glob\n",
        "\n",
        "    images = sorted(glob.glob('output/frame_*.png'))\n",
        "\n",
        "    cap = cv2.VideoCapture('target.mp4')\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    cap.release()\n",
        "\n",
        "    img = cv2.imread(images[0])\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    out = cv2.VideoWriter('interpolated_normal_speed.mp4',\n",
        "                         cv2.VideoWriter_fourcc(*'mp4v'), original_fps, (w, h))\n",
        "\n",
        "    for i in range(len(images) - 1):\n",
        "        current_frame = cv2.imread(images[i])\n",
        "        next_frame = cv2.imread(images[i + 1])\n",
        "\n",
        "        # í˜„ì¬ í”„ë ˆì„ ì“°ê¸°\n",
        "        out.write(current_frame)\n",
        "\n",
        "        # ì¤‘ê°„ì— 9ê°œ í”„ë ˆì„ ë³´ê°„\n",
        "        for j in range(1, 10):\n",
        "            alpha = j / 10\n",
        "            blended = cv2.addWeighted(current_frame, 1-alpha, next_frame, alpha, 0)\n",
        "            out.write(blended)\n",
        "\n",
        "    # ë§ˆì§€ë§‰ í”„ë ˆì„\n",
        "    if images:\n",
        "        last_frame = cv2.imread(images[-1])\n",
        "        for _ in range(10):\n",
        "            out.write(last_frame)\n",
        "\n",
        "    out.release()\n",
        "    print(\"âœ… ë³´ê°„ëœ ì •ìƒ ì†ë„ ì˜ìƒ ì™„ì„±!\")\n",
        "\n",
        "interpolate_missing_frames()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdnesMS02WWq",
        "outputId": "b1d228f1-b1a6-4cab-d8f6-223e8d903313"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë³´ê°„ëœ ì •ìƒ ì†ë„ ì˜ìƒ ì™„ì„±!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import GPUtil\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FrameInterpolationBenchmark:\n",
        "    def __init__(self, input_video_path, output_dir=\"benchmark_results\"):\n",
        "        \"\"\"\n",
        "        í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í‰ê°€ ì‹œìŠ¤í…œ\n",
        "\n",
        "        Args:\n",
        "            input_video_path: í…ŒìŠ¤íŠ¸í•  ì…ë ¥ ì˜ìƒ ê²½ë¡œ\n",
        "            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬\n",
        "        \"\"\"\n",
        "        self.input_video = input_video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.results = {}\n",
        "\n",
        "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
        "        self.get_video_info()\n",
        "\n",
        "        print(f\"ğŸ¬ ì…ë ¥ ì˜ìƒ: {input_video_path}\")\n",
        "        print(f\"ğŸ“Š ì˜ìƒ ì •ë³´: {self.video_info}\")\n",
        "\n",
        "    def get_video_info(self):\n",
        "        \"\"\"ì…ë ¥ ì˜ìƒ ì •ë³´ ë¶„ì„\"\"\"\n",
        "        cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "        self.video_info = {\n",
        "            'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "            'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "            'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "        }\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    def monitor_resources(self):\n",
        "        \"\"\"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§\"\"\"\n",
        "        cpu_percent = psutil.cpu_percent(interval=1)\n",
        "        memory = psutil.virtual_memory()\n",
        "\n",
        "        gpu_info = []\n",
        "        try:\n",
        "            gpus = GPUtil.getGPUs()\n",
        "            for gpu in gpus:\n",
        "                gpu_info.append({\n",
        "                    'name': gpu.name,\n",
        "                    'utilization': gpu.load * 100,\n",
        "                    'memory_used': gpu.memoryUsed,\n",
        "                    'memory_total': gpu.memoryTotal\n",
        "                })\n",
        "        except:\n",
        "            gpu_info = [{'name': 'N/A', 'utilization': 0, 'memory_used': 0, 'memory_total': 0}]\n",
        "\n",
        "        return {\n",
        "            'cpu_percent': cpu_percent,\n",
        "            'memory_percent': memory.percent,\n",
        "            'memory_used_gb': memory.used / (1024**3),\n",
        "            'gpu_info': gpu_info\n",
        "        }\n",
        "\n",
        "    def test_ffmpeg_minterpolate(self, target_fps=60):\n",
        "        \"\"\"FFmpeg minterpolate í…ŒìŠ¤íŠ¸\"\"\"\n",
        "        print(f\"\\nğŸ”„ FFmpeg minterpolate í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"ffmpeg_minterpolate_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', self.input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci',\n",
        "            '-y', output_path\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
        "\n",
        "                self.results['FFmpeg_minterpolate'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'target_fps': target_fps\n",
        "                }\n",
        "                print(f\"âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"âŒ ì‹¤íŒ¨: {result.stderr}\")\n",
        "                self.results['FFmpeg_minterpolate'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"âŒ ì‹œê°„ ì´ˆê³¼ (300ì´ˆ)\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_rife(self, multiplier=2):\n",
        "        \"\"\"RIFE í…ŒìŠ¤íŠ¸ (GitHubì—ì„œ í´ë¡  í•„ìš”)\"\"\"\n",
        "        print(f\"\\nğŸ”„ RIFE í…ŒìŠ¤íŠ¸ (multiplier: {multiplier})\")\n",
        "\n",
        "        rife_dir = \"ECCV2022-RIFE\"\n",
        "\n",
        "        # RIFE ì„¤ì¹˜ ë° ì„¤ì •\n",
        "        if not os.path.exists(rife_dir):\n",
        "            print(\"âš ï¸  RIFE ì €ì¥ì†Œ í´ë¡  ì¤‘...\")\n",
        "            try:\n",
        "                subprocess.run(['git', 'clone', 'https://github.com/megvii-research/ECCV2022-RIFE.git'],\n",
        "                             check=True, timeout=120)\n",
        "                print(\"âœ… RIFE í´ë¡  ì™„ë£Œ\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"âŒ RIFE í´ë¡  ì‹¤íŒ¨: {e}\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': f'Clone failed: {e}'}\n",
        "                return\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"âŒ RIFE í´ë¡  ì‹œê°„ì´ˆê³¼\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'Clone timeout'}\n",
        "                return\n",
        "\n",
        "        # í•„ìš”í•œ íŒŒì¼ë“¤ í™•ì¸\n",
        "        inference_script = os.path.join(rife_dir, 'inference_video.py')\n",
        "        if not os.path.exists(inference_script):\n",
        "            print(\"âŒ inference_video.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "            # ëŒ€ì²´ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë“¤ í™•ì¸\n",
        "            alternative_scripts = [\n",
        "                os.path.join(rife_dir, 'inference_img.py'),\n",
        "                os.path.join(rife_dir, 'demo_MiddleBury.py'),\n",
        "                os.path.join(rife_dir, 'test.py')\n",
        "            ]\n",
        "\n",
        "            found_script = None\n",
        "            for script in alternative_scripts:\n",
        "                if os.path.exists(script):\n",
        "                    found_script = script\n",
        "                    print(f\"âœ… ëŒ€ì²´ ìŠ¤í¬ë¦½íŠ¸ ë°œê²¬: {script}\")\n",
        "                    break\n",
        "\n",
        "            if not found_script:\n",
        "                print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ RIFE ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'No inference script found'}\n",
        "                return\n",
        "\n",
        "            inference_script = found_script\n",
        "\n",
        "        # ì˜ì¡´ì„± ì„¤ì¹˜\n",
        "        try:\n",
        "            print(\"ğŸ“¦ RIFE ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...\")\n",
        "            original_dir = os.getcwd()\n",
        "            os.chdir(rife_dir)\n",
        "\n",
        "            # requirements.txt ì„¤ì¹˜\n",
        "            if os.path.exists('requirements.txt'):\n",
        "                subprocess.run(['pip', 'install', '-r', 'requirements.txt'],\n",
        "                             capture_output=True, timeout=180)\n",
        "\n",
        "            # í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "            subprocess.run(['pip', 'install', 'torch', 'torchvision', 'opencv-python', 'numpy'],\n",
        "                         capture_output=True, timeout=180)\n",
        "\n",
        "            os.chdir(original_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}\")\n",
        "\n",
        "        # RIFE ì‹¤í–‰\n",
        "        output_path = os.path.join(self.output_dir, f\"rife_x{multiplier}.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
        "        abs_input = os.path.abspath(self.input_video)\n",
        "        abs_output = os.path.abspath(output_path)\n",
        "\n",
        "        # ì—¬ëŸ¬ ê°€ì§€ ëª…ë ¹ì–´ ì‹œë„\n",
        "        commands_to_try = [\n",
        "            # í‘œì¤€ inference_video.py\n",
        "            ['python', 'inference_video.py', f'--exp={multiplier}', f'--video={abs_input}', f'--output={abs_output}'],\n",
        "            # ëŒ€ì²´ ëª…ë ¹ì–´ë“¤\n",
        "            ['python', 'inference_video.py', '--times', str(multiplier), '--video', abs_input, '--output', abs_output],\n",
        "            ['python', 'test.py', '--video', abs_input, '--output', abs_output],\n",
        "        ]\n",
        "\n",
        "        success = False\n",
        "        original_dir = os.getcwd()\n",
        "\n",
        "        try:\n",
        "            os.chdir(rife_dir)\n",
        "\n",
        "            for i, cmd in enumerate(commands_to_try):\n",
        "                print(f\"ğŸ”„ RIFE ëª…ë ¹ì–´ ì‹œë„ {i+1}: {' '.join(cmd)}\")\n",
        "\n",
        "                try:\n",
        "                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n",
        "\n",
        "                    if result.returncode == 0:\n",
        "                        print(f\"âœ… RIFE ëª…ë ¹ì–´ {i+1} ì„±ê³µ!\")\n",
        "                        success = True\n",
        "                        break\n",
        "                    else:\n",
        "                        print(f\"âŒ ëª…ë ¹ì–´ {i+1} ì‹¤íŒ¨: {result.stderr[:200]}\")\n",
        "\n",
        "                except subprocess.TimeoutExpired:\n",
        "                    print(f\"âŒ ëª…ë ¹ì–´ {i+1} ì‹œê°„ ì´ˆê³¼\")\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ ëª…ë ¹ì–´ {i+1} ì˜¤ë¥˜: {e}\")\n",
        "\n",
        "            os.chdir(original_dir)\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if success and os.path.exists(abs_output):\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(abs_output) / (1024**2)\n",
        "\n",
        "                self.results['RIFE'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': abs_output,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'multiplier': multiplier\n",
        "                }\n",
        "                print(f\"âœ… RIFE ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(\"âŒ RIFE ì‹¤í–‰ ì‹¤íŒ¨ - ëª¨ë“  ëª…ë ¹ì–´ ì‹œë„ ì™„ë£Œ\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'All command attempts failed'}\n",
        "\n",
        "        except Exception as e:\n",
        "            os.chdir(original_dir)\n",
        "            print(f\"âŒ RIFE ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['RIFE'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_frame_blending(self, target_fps=60):\n",
        "        \"\"\"ê°„ë‹¨í•œ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ê¸°ì¤€ì„ )\"\"\"\n",
        "        print(f\"\\nğŸ”„ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"frame_blending_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, target_fps,\n",
        "                                (self.video_info['width'], self.video_info['height']))\n",
        "\n",
        "            frames = []\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frames.append(frame)\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "            # í”„ë ˆì„ ê°„ ë¸”ë Œë”©ìœ¼ë¡œ ë³´ê°„\n",
        "            interpolation_factor = target_fps / self.video_info['fps']\n",
        "\n",
        "            for i in range(len(frames) - 1):\n",
        "                out.write(frames[i])\n",
        "\n",
        "                # ì¤‘ê°„ í”„ë ˆì„ë“¤ ìƒì„±\n",
        "                num_inter_frames = int(interpolation_factor) - 1\n",
        "                for j in range(1, num_inter_frames + 1):\n",
        "                    alpha = j / (num_inter_frames + 1)\n",
        "                    blended = cv2.addWeighted(frames[i], 1-alpha, frames[i+1], alpha, 0)\n",
        "                    out.write(blended)\n",
        "\n",
        "            if frames:\n",
        "                out.write(frames[-1])\n",
        "\n",
        "            out.release()\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            end_resources = self.monitor_resources()\n",
        "            file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "            self.results['Frame_Blending'] = {\n",
        "                'status': 'success',\n",
        "                'processing_time': processing_time,\n",
        "                'output_path': output_path,\n",
        "                'file_size_mb': file_size,\n",
        "                'start_resources': start_resources,\n",
        "                'end_resources': end_resources,\n",
        "                'target_fps': target_fps\n",
        "            }\n",
        "            print(f\"âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, íŒŒì¼í¬ê¸°: {file_size:.2f}MB\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            self.results['Frame_Blending'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def calculate_quality_metrics(self, method_name, output_path):\n",
        "        \"\"\"í’ˆì§ˆ ì§€í‘œ ê³„ì‚° (PSNR, SSIM)\"\"\"\n",
        "        print(f\"\\nğŸ“Š {method_name} í’ˆì§ˆ ë¶„ì„...\")\n",
        "\n",
        "        try:\n",
        "            # ì›ë³¸ê³¼ ê²°ê³¼ ì˜ìƒì—ì„œ ìƒ˜í”Œ í”„ë ˆì„ ì¶”ì¶œ\n",
        "            original_frames = self.extract_sample_frames(self.input_video, num_samples=10)\n",
        "            result_frames = self.extract_sample_frames(output_path, num_samples=10)\n",
        "\n",
        "            if len(original_frames) == 0 or len(result_frames) == 0:\n",
        "                return None\n",
        "\n",
        "            psnr_scores = []\n",
        "            ssim_scores = []\n",
        "\n",
        "            # í¬ê¸° ë§ì¶”ê¸°\n",
        "            min_samples = min(len(original_frames), len(result_frames))\n",
        "\n",
        "            for i in range(min_samples):\n",
        "                orig = original_frames[i]\n",
        "                result = result_frames[i]\n",
        "\n",
        "                # í¬ê¸° ì¡°ì •\n",
        "                if orig.shape != result.shape:\n",
        "                    result = cv2.resize(result, (orig.shape[1], orig.shape[0]))\n",
        "\n",
        "                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
        "                orig_gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
        "                result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # PSNR ê³„ì‚°\n",
        "                psnr_val = psnr(orig_gray, result_gray, data_range=255)\n",
        "                psnr_scores.append(psnr_val)\n",
        "\n",
        "                # SSIM ê³„ì‚°\n",
        "                ssim_val = ssim(orig_gray, result_gray, data_range=255)\n",
        "                ssim_scores.append(ssim_val)\n",
        "\n",
        "            quality_metrics = {\n",
        "                'avg_psnr': np.mean(psnr_scores),\n",
        "                'avg_ssim': np.mean(ssim_scores),\n",
        "                'psnr_std': np.std(psnr_scores),\n",
        "                'ssim_std': np.std(ssim_scores)\n",
        "            }\n",
        "\n",
        "            self.results[method_name]['quality_metrics'] = quality_metrics\n",
        "            print(f\"   PSNR: {quality_metrics['avg_psnr']:.2f} Â± {quality_metrics['psnr_std']:.2f}\")\n",
        "            print(f\"   SSIM: {quality_metrics['avg_ssim']:.3f} Â± {quality_metrics['ssim_std']:.3f}\")\n",
        "\n",
        "            return quality_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ í’ˆì§ˆ ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_sample_frames(self, video_path, num_samples=10):\n",
        "        \"\"\"ì˜ìƒì—ì„œ ìƒ˜í”Œ í”„ë ˆì„ ì¶”ì¶œ\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if frame_count == 0:\n",
        "            cap.release()\n",
        "            return []\n",
        "\n",
        "        frames = []\n",
        "        step = max(1, frame_count // num_samples)\n",
        "\n",
        "        for i in range(0, frame_count, step):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "                if len(frames) >= num_samples:\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def run_all_tests(self):\n",
        "        \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
        "        print(\"ğŸš€ í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. FFmpeg minterpolate\n",
        "        self.test_ffmpeg_minterpolate(target_fps=60)\n",
        "\n",
        "        # 2. Frame Blending (ê¸°ì¤€ì„ )\n",
        "        self.test_frame_blending(target_fps=60)\n",
        "\n",
        "        # 3. RIFE (ì¡°ê±´ë¶€)\n",
        "        if self.should_test_rife():\n",
        "            self.test_rife(multiplier=2)\n",
        "        else:\n",
        "            print(\"\\nâš ï¸  RIFE í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€ (ì˜ì¡´ì„± ì—†ìŒ)\")\n",
        "\n",
        "        # í’ˆì§ˆ ë¶„ì„\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ“Š í’ˆì§ˆ ë¶„ì„ ì‹œì‘...\")\n",
        "\n",
        "        for method, result in self.results.items():\n",
        "            if result.get('status') == 'success':\n",
        "                self.calculate_quality_metrics(method, result['output_path'])\n",
        "\n",
        "        # ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”\n",
        "        self.save_results()\n",
        "        self.create_comparison_report()\n",
        "\n",
        "    def should_test_rife(self):\n",
        "        \"\"\"RIFE í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\"\"\"\n",
        "        try:\n",
        "            # PyTorch ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸\n",
        "            import torch\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
        "        results_file = os.path.join(self.output_dir, \"benchmark_results.json\")\n",
        "\n",
        "        # datetime ê°ì²´ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
        "        serializable_results = {}\n",
        "        for method, result in self.results.items():\n",
        "            serializable_results[method] = {}\n",
        "            for key, value in result.items():\n",
        "                if isinstance(value, (dict, list, str, int, float, bool)) or value is None:\n",
        "                    serializable_results[method][key] = value\n",
        "                else:\n",
        "                    serializable_results[method][key] = str(value)\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'input_video_info': self.video_info,\n",
        "                'results': serializable_results\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}\")\n",
        "\n",
        "    def create_comparison_report(self):\n",
        "        \"\"\"ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"ğŸ“Š ìµœì¢… ë¹„êµ ë¦¬í¬íŠ¸\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        successful_methods = {k: v for k, v in self.results.items() if v.get('status') == 'success'}\n",
        "\n",
        "        if not successful_methods:\n",
        "            print(\"âŒ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "            return\n",
        "\n",
        "        # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”\n",
        "        print(f\"{'ë°©ë²•':<20} {'ì²˜ë¦¬ì‹œê°„(ì´ˆ)':<12} {'íŒŒì¼í¬ê¸°(MB)':<12} {'PSNR':<8} {'SSIM':<8}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for method, result in successful_methods.items():\n",
        "            processing_time = result.get('processing_time', 0)\n",
        "            file_size = result.get('file_size_mb', 0)\n",
        "\n",
        "            quality = result.get('quality_metrics', {})\n",
        "            psnr_val = quality.get('avg_psnr', 0)\n",
        "            ssim_val = quality.get('avg_ssim', 0)\n",
        "\n",
        "            print(f\"{method:<20} {processing_time:<12.2f} {file_size:<12.2f} {psnr_val:<8.2f} {ssim_val:<8.3f}\")\n",
        "\n",
        "        # ì¶”ì²œ ê²°ê³¼\n",
        "        print(\"\\nğŸ† ì¶”ì²œ ê²°ê³¼:\")\n",
        "\n",
        "        # ì†ë„ ê¸°ì¤€ ìµœê³ \n",
        "        fastest = min(successful_methods.items(), key=lambda x: x[1].get('processing_time', float('inf')))\n",
        "        print(f\"   âš¡ ê°€ì¥ ë¹ ë¦„: {fastest[0]} ({fastest[1].get('processing_time', 0):.2f}ì´ˆ)\")\n",
        "\n",
        "        # í’ˆì§ˆ ê¸°ì¤€ ìµœê³  (SSIM)\n",
        "        quality_methods = {k: v for k, v in successful_methods.items() if v.get('quality_metrics')}\n",
        "        if quality_methods:\n",
        "            best_quality = max(quality_methods.items(),\n",
        "                             key=lambda x: x[1].get('quality_metrics', {}).get('avg_ssim', 0))\n",
        "            ssim_score = best_quality[1].get('quality_metrics', {}).get('avg_ssim', 0)\n",
        "            print(f\"   ğŸ¯ ìµœê³  í’ˆì§ˆ: {best_quality[0]} (SSIM: {ssim_score:.3f})\")\n",
        "\n",
        "        # íŒŒì¼ í¬ê¸° ìµœì í™”\n",
        "        smallest = min(successful_methods.items(), key=lambda x: x[1].get('file_size_mb', float('inf')))\n",
        "        print(f\"   ğŸ’¾ ìµœì†Œ ìš©ëŸ‰: {smallest[0]} ({smallest[1].get('file_size_mb', 0):.2f}MB)\")\n",
        "\n",
        "# ì‚¬ìš© ì˜ˆì‹œ\n",
        "def main():\n",
        "    # í…ŒìŠ¤íŠ¸í•  ì˜ìƒ ê²½ë¡œ\n",
        "    input_video = \"final_result.mp4\"  # ì—¬ê¸°ì— í…ŒìŠ¤íŠ¸í•  ì˜ìƒ ê²½ë¡œ ì…ë ¥\n",
        "\n",
        "    if not os.path.exists(input_video):\n",
        "        print(f\"âŒ ì…ë ¥ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_video}\")\n",
        "        print(\"í…ŒìŠ¤íŠ¸ìš© ì˜ìƒì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”!\")\n",
        "        return\n",
        "\n",
        "    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰\n",
        "    benchmark = FrameInterpolationBenchmark(input_video)\n",
        "    benchmark.run_all_tests()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-RamNp52tIu",
        "outputId": "96119e18-c77f-42cb-f0c3-642d7da25146"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¬ ì…ë ¥ ì˜ìƒ: final_result.mp4\n",
            "ğŸ“Š ì˜ìƒ ì •ë³´: {'fps': 30.0, 'width': 966, 'height': 500, 'frame_count': 36, 'duration': 1.2}\n",
            "ğŸš€ í”„ë ˆì„ ë³´ê°„ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘!\n",
            "============================================================\n",
            "\n",
            "ğŸ”„ FFmpeg minterpolate í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: 60)\n",
            "âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: 6.47ì´ˆ, íŒŒì¼í¬ê¸°: 0.16MB\n",
            "\n",
            "ğŸ”„ í”„ë ˆì„ ë¸”ë Œë”© í…ŒìŠ¤íŠ¸ (ëª©í‘œ FPS: 60)\n",
            "âœ… ì™„ë£Œ! ì²˜ë¦¬ì‹œê°„: 1.21ì´ˆ, íŒŒì¼í¬ê¸°: 0.58MB\n",
            "\n",
            "ğŸ”„ RIFE í…ŒìŠ¤íŠ¸ (multiplier: 2)\n",
            "ğŸ“¦ RIFE ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...\n",
            "ğŸ”„ RIFE ëª…ë ¹ì–´ ì‹œë„ 1: python inference_video.py --exp=2 --video=/content/final_result.mp4 --output=/content/benchmark_results/rife_x2.mp4\n",
            "âŒ ëª…ë ¹ì–´ 1 ì‹¤íŒ¨: Traceback (most recent call last):\n",
            "  File \"/content/ECCV2022-RIFE/inference_video.py\", line 91, in <module>\n",
            "    from model.RIFE_HDv2 import Model\n",
            "ModuleNotFoundError: No module named 'model.RIFE_HDv2'\n",
            "ğŸ”„ RIFE ëª…ë ¹ì–´ ì‹œë„ 2: python inference_video.py --times 2 --video /content/final_result.mp4 --output /content/benchmark_results/rife_x2.mp4\n",
            "âŒ ëª…ë ¹ì–´ 2 ì‹¤íŒ¨: usage: inference_video.py [-h] [--video VIDEO] [--output OUTPUT] [--img IMG]\n",
            "                          [--montage] [--model MODELDIR] [--fp16] [--UHD]\n",
            "                          [--scale SCALE] [--skip\n",
            "ğŸ”„ RIFE ëª…ë ¹ì–´ ì‹œë„ 3: python test.py --video /content/final_result.mp4 --output /content/benchmark_results/rife_x2.mp4\n",
            "âŒ ëª…ë ¹ì–´ 3 ì‹¤íŒ¨: python3: can't open file '/content/ECCV2022-RIFE/test.py': [Errno 2] No such file or directory\n",
            "\n",
            "âŒ RIFE ì‹¤í–‰ ì‹¤íŒ¨ - ëª¨ë“  ëª…ë ¹ì–´ ì‹œë„ ì™„ë£Œ\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š í’ˆì§ˆ ë¶„ì„ ì‹œì‘...\n",
            "\n",
            "ğŸ“Š FFmpeg_minterpolate í’ˆì§ˆ ë¶„ì„...\n",
            "   PSNR: 42.58 Â± 0.60\n",
            "   SSIM: 0.980 Â± 0.002\n",
            "\n",
            "ğŸ“Š Frame_Blending í’ˆì§ˆ ë¶„ì„...\n",
            "   PSNR: 28.28 Â± 5.74\n",
            "   SSIM: 0.902 Â± 0.046\n",
            "ğŸ’¾ ê²°ê³¼ ì €ì¥: benchmark_results/benchmark_results.json\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ìµœì¢… ë¹„êµ ë¦¬í¬íŠ¸\n",
            "============================================================\n",
            "ë°©ë²•                   ì²˜ë¦¬ì‹œê°„(ì´ˆ)      íŒŒì¼í¬ê¸°(MB)     PSNR     SSIM    \n",
            "----------------------------------------------------------------------\n",
            "FFmpeg_minterpolate  6.47         0.16         42.58    0.980   \n",
            "Frame_Blending       1.21         0.58         28.28    0.902   \n",
            "\n",
            "ğŸ† ì¶”ì²œ ê²°ê³¼:\n",
            "   âš¡ ê°€ì¥ ë¹ ë¦„: Frame_Blending (1.21ì´ˆ)\n",
            "   ğŸ¯ ìµœê³  í’ˆì§ˆ: FFmpeg_minterpolate (SSIM: 0.980)\n",
            "   ğŸ’¾ ìµœì†Œ ìš©ëŸ‰: FFmpeg_minterpolate (0.16MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def change_video_speed_colab(input_video, output_video, speed=1.0):\n",
        "    \"\"\"\n",
        "    ì˜¤ë””ì˜¤ ì—†ëŠ” ì˜ìƒ ì†ë„ ì¡°ì ˆ (ëŠë¦¬ê²Œ/ë¹ ë¥´ê²Œ) - Colab ìš©\n",
        "    Args:\n",
        "        input_video (str): ì…ë ¥ íŒŒì¼\n",
        "        output_video (str): ì¶œë ¥ íŒŒì¼\n",
        "        speed (float): ì†ë„ ë°°ìˆ˜ (ì˜ˆ: 0.25 = ëŠë¦¬ê²Œ, 4.0 = ë¹ ë¥´ê²Œ)\n",
        "    \"\"\"\n",
        "    print(f\"ğŸï¸ ì˜ìƒ ì†ë„ {speed}ë°° {'ë¹ ë¥´ê²Œ' if speed > 1 else 'ëŠë¦¬ê²Œ'}: {input_video}\")\n",
        "\n",
        "    # setpts ê³µì‹: ëŠë¦¬ê²ŒëŠ” í° ê°’, ë¹ ë¥´ê²ŒëŠ” ì‘ì€ ê°’\n",
        "    setpts_value = speed\n",
        "    cmd = [\n",
        "        'ffmpeg', '-i', input_video,\n",
        "        '-filter:v', f'setpts={setpts_value:.3f}*PTS',\n",
        "        '-y', output_video\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        size = os.path.getsize(output_video) / (1024**2)\n",
        "        print(f\"âœ… ì™„ë£Œ: {output_video} ({size:.1f}MB)\")\n",
        "    else:\n",
        "        print(f\"âŒ ì‹¤íŒ¨: {result.stderr}\")\n",
        "\n",
        "##ffmpegìŠ¹\n"
      ],
      "metadata": {
        "id": "8nZDBeJR3axb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆ: final_result.mp4 ë¥¼ 0.25ë°° ~ 4ë°° ì†ë„ë¡œ ê°ê° ìƒì„±\n",
        "batch_change_speeds(\"/content/benchmark_results/frame_blending_60fps.mp4\", speeds=[0.25, 0.5, 1.0, 2.0, 4.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-5dMCZH5Qwi",
        "outputId": "6bd424b0-4ce9-47d5-8243-e8da058d737c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš™ï¸ ì›ë³¸: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "ğŸï¸ ì˜ìƒ ì†ë„ 0.25ë°° ëŠë¦¬ê²Œ: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "âœ… ì™„ë£Œ: /content/benchmark_results/frame_blending_60fps_0.25x.mp4 (0.1MB)\n",
            "ğŸï¸ ì˜ìƒ ì†ë„ 0.5ë°° ëŠë¦¬ê²Œ: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "âœ… ì™„ë£Œ: /content/benchmark_results/frame_blending_60fps_0.5x.mp4 (0.1MB)\n",
            "ğŸï¸ ì˜ìƒ ì†ë„ 1.0ë°° ëŠë¦¬ê²Œ: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "âœ… ì™„ë£Œ: /content/benchmark_results/frame_blending_60fps_1.0x.mp4 (0.2MB)\n",
            "ğŸï¸ ì˜ìƒ ì†ë„ 2.0ë°° ë¹ ë¥´ê²Œ: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "âœ… ì™„ë£Œ: /content/benchmark_results/frame_blending_60fps_2.0x.mp4 (0.3MB)\n",
            "ğŸï¸ ì˜ìƒ ì†ë„ 4.0ë°° ë¹ ë¥´ê²Œ: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "âœ… ì™„ë£Œ: /content/benchmark_results/frame_blending_60fps_4.0x.mp4 (0.4MB)\n"
          ]
        }
      ]
    }
  ]
}