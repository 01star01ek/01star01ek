{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy15bvILQzNu9U0IVK5LGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%EC%B5%9C%EC%A2%85%EC%9A%B0%EC%8A%B9%EC%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnWtZK-jtsJ6",
        "outputId": "76b7c2fd-3779-49ea-988a-dc2198fd949d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.16.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.11.5)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (3.12.5)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.4.9)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (4.14.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.4.26)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp311-cp311-linux_x86_64.whl size=1060438 sha256=f616035843089a8e68d930ae39e6db694ed463929ee69e7784c1558e6e910ca0\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/d8/22/f52d858d16cd06e7b2e6aad34a1777dcfaf000be833bbf8146\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.18.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_inswapper():\n",
        "    url = \"https://civitai.com/api/download/models/85159\"\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        with open('inswapper_128.onnx', 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(\"모델 다운로드 완료!\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"다운로드 실패: {response.status_code}\")\n",
        "        return False\n",
        "\n",
        "download_inswapper()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBeREbyCuiFr",
        "outputId": "71285790-8cb4-4c8c-cfe6-ac47b5403f79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 다운로드 완료!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "import os\n",
        "\n",
        "# 설정\n",
        "app = FaceAnalysis()\n",
        "app.prepare(ctx_id=0, det_size=(320, 320))\n",
        "swapper = insightface.model_zoo.get_model('inswapper_128.onnx')\n",
        "\n",
        "# 소스 이미지\n",
        "source_img = cv2.imread('source.png')\n",
        "source_faces = app.get(source_img)\n",
        "source_face = source_faces[0]\n",
        "\n",
        "# 비디오 처리\n",
        "cap = cv2.VideoCapture('target.mp4')\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # 10프레임마다 처리\n",
        "    if frame_count % 10 == 0:\n",
        "        target_faces = app.get(frame)\n",
        "\n",
        "        if len(target_faces) > 0:\n",
        "            # 얼굴 합성\n",
        "            result = swapper.get(frame, target_faces[0], source_face, paste_back=True)\n",
        "\n",
        "            # 이미지 저장\n",
        "            cv2.imwrite(f'output/frame_{saved_count:04d}.png', result)\n",
        "            saved_count += 1\n",
        "            print(f\"저장: frame_{saved_count:04d}.png\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"완료! {saved_count}개 이미지 저장\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln9rNQv7txTk",
        "outputId": "ef4ef0dd-3af6-467a-f0d1-c3baf54bbc65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (320, 320)\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "inswapper-shape: [1, 3, 128, 128]\n",
            "저장: frame_0001.png\n",
            "저장: frame_0002.png\n",
            "저장: frame_0003.png\n",
            "저장: frame_0004.png\n",
            "저장: frame_0005.png\n",
            "저장: frame_0006.png\n",
            "저장: frame_0007.png\n",
            "저장: frame_0008.png\n",
            "저장: frame_0009.png\n",
            "저장: frame_0010.png\n",
            "저장: frame_0011.png\n",
            "저장: frame_0012.png\n",
            "저장: frame_0013.png\n",
            "저장: frame_0014.png\n",
            "저장: frame_0015.png\n",
            "저장: frame_0016.png\n",
            "저장: frame_0017.png\n",
            "저장: frame_0018.png\n",
            "저장: frame_0019.png\n",
            "저장: frame_0020.png\n",
            "저장: frame_0021.png\n",
            "저장: frame_0022.png\n",
            "저장: frame_0023.png\n",
            "저장: frame_0024.png\n",
            "저장: frame_0025.png\n",
            "저장: frame_0026.png\n",
            "저장: frame_0027.png\n",
            "저장: frame_0028.png\n",
            "저장: frame_0029.png\n",
            "저장: frame_0030.png\n",
            "저장: frame_0031.png\n",
            "저장: frame_0032.png\n",
            "저장: frame_0033.png\n",
            "저장: frame_0034.png\n",
            "저장: frame_0035.png\n",
            "저장: frame_0036.png\n",
            "완료! 36개 이미지 저장\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "print(\"영상 생성 중...\")\n",
        "\n",
        "# 이미지 파일들 가져오기\n",
        "image_files = sorted(glob('output/frame_*.png'))\n",
        "if len(image_files) > 0:\n",
        "    # 첫 번째 이미지로 크기 확인\n",
        "    first_img = cv2.imread(image_files[0])\n",
        "    height, width, _ = first_img.shape\n",
        "\n",
        "    # 비디오 라이터 설정\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter('final_result.mp4', fourcc, 30, (width, height))\n",
        "\n",
        "    # 모든 이미지를 영상에 추가\n",
        "    for img_path in image_files:\n",
        "        img = cv2.imread(img_path)\n",
        "        out.write(img)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"✅ 영상 완성! final_result.mp4 ({len(image_files)}개 프레임)\")\n",
        "else:\n",
        "    print(\"❌ 저장된 이미지가 없습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GFRuhf_ztk6",
        "outputId": "a9f099d7-46e7-4389-cf08-f1f26dffe05d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영상 생성 중...\n",
            "✅ 영상 완성! final_result.mp4 (36개 프레임)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPUtil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aslBCf8038t",
        "outputId": "090c899a-2040-4bf6-b3e8-ebc5d6ef9315"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=2a6f2be9ec541a3f655187985f9e59a500127d65d8fdc4b36dab8da35750079c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import GPUtil\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FrameInterpolationBenchmark:\n",
        "    def __init__(self, input_video_path, output_dir=\"benchmark_results\"):\n",
        "        \"\"\"\n",
        "        프레임 보간 성능 비교 평가 시스템\n",
        "\n",
        "        Args:\n",
        "            input_video_path: 테스트할 입력 영상 경로\n",
        "            output_dir: 결과 저장 디렉토리\n",
        "        \"\"\"\n",
        "        self.input_video = input_video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.results = {}\n",
        "\n",
        "        # 출력 디렉토리 생성\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # 영상 정보 가져오기\n",
        "        self.get_video_info()\n",
        "\n",
        "        print(f\"🎬 입력 영상: {input_video_path}\")\n",
        "        print(f\"📊 영상 정보: {self.video_info}\")\n",
        "\n",
        "    def get_video_info(self):\n",
        "        \"\"\"입력 영상 정보 분석\"\"\"\n",
        "        cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "        self.video_info = {\n",
        "            'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "            'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "            'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "        }\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    def monitor_resources(self):\n",
        "        \"\"\"시스템 리소스 모니터링\"\"\"\n",
        "        cpu_percent = psutil.cpu_percent(interval=1)\n",
        "        memory = psutil.virtual_memory()\n",
        "\n",
        "        gpu_info = []\n",
        "        try:\n",
        "            gpus = GPUtil.getGPUs()\n",
        "            for gpu in gpus:\n",
        "                gpu_info.append({\n",
        "                    'name': gpu.name,\n",
        "                    'utilization': gpu.load * 100,\n",
        "                    'memory_used': gpu.memoryUsed,\n",
        "                    'memory_total': gpu.memoryTotal\n",
        "                })\n",
        "        except:\n",
        "            gpu_info = [{'name': 'N/A', 'utilization': 0, 'memory_used': 0, 'memory_total': 0}]\n",
        "\n",
        "        return {\n",
        "            'cpu_percent': cpu_percent,\n",
        "            'memory_percent': memory.percent,\n",
        "            'memory_used_gb': memory.used / (1024**3),\n",
        "            'gpu_info': gpu_info\n",
        "        }\n",
        "\n",
        "    def test_ffmpeg_minterpolate(self, target_fps=60):\n",
        "        \"\"\"FFmpeg minterpolate 테스트\"\"\"\n",
        "        print(f\"\\n🔄 FFmpeg minterpolate 테스트 (목표 FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"ffmpeg_minterpolate_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', self.input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci',\n",
        "            '-y', output_path\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
        "\n",
        "                self.results['FFmpeg_minterpolate'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'target_fps': target_fps\n",
        "                }\n",
        "                print(f\"✅ 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"❌ 실패: {result.stderr}\")\n",
        "                self.results['FFmpeg_minterpolate'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"❌ 시간 초과 (300초)\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_rife(self, multiplier=2):\n",
        "        \"\"\"RIFE 테스트 (GitHub에서 클론 필요)\"\"\"\n",
        "        print(f\"\\n🔄 RIFE 테스트 (multiplier: {multiplier})\")\n",
        "\n",
        "        rife_dir = \"ECCV2022-RIFE\"\n",
        "        if not os.path.exists(rife_dir):\n",
        "            print(\"⚠️  RIFE 저장소 클론 중...\")\n",
        "            subprocess.run(['git', 'clone', 'https://github.com/megvii-research/ECCV2022-RIFE.git'])\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"rife_x{multiplier}.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'python', f'{rife_dir}/inference_video.py',\n",
        "            f'--exp={multiplier}',\n",
        "            f'--video={self.input_video}',\n",
        "            f'--output={output_path}'\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            os.chdir(rife_dir)\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n",
        "            os.chdir('..')\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(output_path):\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "                self.results['RIFE'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'multiplier': multiplier\n",
        "                }\n",
        "                print(f\"✅ 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"❌ 실패: {result.stderr}\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"❌ 시간 초과 (600초)\")\n",
        "            self.results['RIFE'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            self.results['RIFE'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_frame_blending(self, target_fps=60):\n",
        "        \"\"\"간단한 프레임 블렌딩 테스트 (기준선)\"\"\"\n",
        "        print(f\"\\n🔄 프레임 블렌딩 테스트 (목표 FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"frame_blending_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, target_fps,\n",
        "                                (self.video_info['width'], self.video_info['height']))\n",
        "\n",
        "            frames = []\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frames.append(frame)\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "            # 프레임 간 블렌딩으로 보간\n",
        "            interpolation_factor = target_fps / self.video_info['fps']\n",
        "\n",
        "            for i in range(len(frames) - 1):\n",
        "                out.write(frames[i])\n",
        "\n",
        "                # 중간 프레임들 생성\n",
        "                num_inter_frames = int(interpolation_factor) - 1\n",
        "                for j in range(1, num_inter_frames + 1):\n",
        "                    alpha = j / (num_inter_frames + 1)\n",
        "                    blended = cv2.addWeighted(frames[i], 1-alpha, frames[i+1], alpha, 0)\n",
        "                    out.write(blended)\n",
        "\n",
        "            if frames:\n",
        "                out.write(frames[-1])\n",
        "\n",
        "            out.release()\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            end_resources = self.monitor_resources()\n",
        "            file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "            self.results['Frame_Blending'] = {\n",
        "                'status': 'success',\n",
        "                'processing_time': processing_time,\n",
        "                'output_path': output_path,\n",
        "                'file_size_mb': file_size,\n",
        "                'start_resources': start_resources,\n",
        "                'end_resources': end_resources,\n",
        "                'target_fps': target_fps\n",
        "            }\n",
        "            print(f\"✅ 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            self.results['Frame_Blending'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def calculate_quality_metrics(self, method_name, output_path):\n",
        "        \"\"\"품질 지표 계산 (PSNR, SSIM)\"\"\"\n",
        "        print(f\"\\n📊 {method_name} 품질 분석...\")\n",
        "\n",
        "        try:\n",
        "            # 원본과 결과 영상에서 샘플 프레임 추출\n",
        "            original_frames = self.extract_sample_frames(self.input_video, num_samples=10)\n",
        "            result_frames = self.extract_sample_frames(output_path, num_samples=10)\n",
        "\n",
        "            if len(original_frames) == 0 or len(result_frames) == 0:\n",
        "                return None\n",
        "\n",
        "            psnr_scores = []\n",
        "            ssim_scores = []\n",
        "\n",
        "            # 크기 맞추기\n",
        "            min_samples = min(len(original_frames), len(result_frames))\n",
        "\n",
        "            for i in range(min_samples):\n",
        "                orig = original_frames[i]\n",
        "                result = result_frames[i]\n",
        "\n",
        "                # 크기 조정\n",
        "                if orig.shape != result.shape:\n",
        "                    result = cv2.resize(result, (orig.shape[1], orig.shape[0]))\n",
        "\n",
        "                # 그레이스케일 변환\n",
        "                orig_gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
        "                result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # PSNR 계산\n",
        "                psnr_val = psnr(orig_gray, result_gray, data_range=255)\n",
        "                psnr_scores.append(psnr_val)\n",
        "\n",
        "                # SSIM 계산\n",
        "                ssim_val = ssim(orig_gray, result_gray, data_range=255)\n",
        "                ssim_scores.append(ssim_val)\n",
        "\n",
        "            quality_metrics = {\n",
        "                'avg_psnr': np.mean(psnr_scores),\n",
        "                'avg_ssim': np.mean(ssim_scores),\n",
        "                'psnr_std': np.std(psnr_scores),\n",
        "                'ssim_std': np.std(ssim_scores)\n",
        "            }\n",
        "\n",
        "            self.results[method_name]['quality_metrics'] = quality_metrics\n",
        "            print(f\"   PSNR: {quality_metrics['avg_psnr']:.2f} ± {quality_metrics['psnr_std']:.2f}\")\n",
        "            print(f\"   SSIM: {quality_metrics['avg_ssim']:.3f} ± {quality_metrics['ssim_std']:.3f}\")\n",
        "\n",
        "            return quality_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 품질 분석 실패: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_sample_frames(self, video_path, num_samples=10):\n",
        "        \"\"\"영상에서 샘플 프레임 추출\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if frame_count == 0:\n",
        "            cap.release()\n",
        "            return []\n",
        "\n",
        "        frames = []\n",
        "        step = max(1, frame_count // num_samples)\n",
        "\n",
        "        for i in range(0, frame_count, step):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "                if len(frames) >= num_samples:\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def run_all_tests(self):\n",
        "        \"\"\"모든 테스트 실행\"\"\"\n",
        "        print(\"🚀 프레임 보간 성능 비교 테스트 시작!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. FFmpeg minterpolate\n",
        "        self.test_ffmpeg_minterpolate(target_fps=60)\n",
        "\n",
        "        # 2. Frame Blending (기준선)\n",
        "        self.test_frame_blending(target_fps=60)\n",
        "\n",
        "        # 3. RIFE (조건부)\n",
        "        if self.should_test_rife():\n",
        "            self.test_rife(multiplier=2)\n",
        "        else:\n",
        "            print(\"\\n⚠️  RIFE 테스트 건너뜀 (의존성 없음)\")\n",
        "\n",
        "        # 품질 분석\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"📊 품질 분석 시작...\")\n",
        "\n",
        "        for method, result in self.results.items():\n",
        "            if result.get('status') == 'success':\n",
        "                self.calculate_quality_metrics(method, result['output_path'])\n",
        "\n",
        "        # 결과 저장 및 시각화\n",
        "        self.save_results()\n",
        "        self.create_comparison_report()\n",
        "\n",
        "    def should_test_rife(self):\n",
        "        \"\"\"RIFE 테스트 가능 여부 확인\"\"\"\n",
        "        try:\n",
        "            # PyTorch 설치 여부 확인\n",
        "            import torch\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"결과를 JSON 파일로 저장\"\"\"\n",
        "        results_file = os.path.join(self.output_dir, \"benchmark_results.json\")\n",
        "\n",
        "        # datetime 객체들을 문자열로 변환\n",
        "        serializable_results = {}\n",
        "        for method, result in self.results.items():\n",
        "            serializable_results[method] = {}\n",
        "            for key, value in result.items():\n",
        "                if isinstance(value, (dict, list, str, int, float, bool)) or value is None:\n",
        "                    serializable_results[method][key] = value\n",
        "                else:\n",
        "                    serializable_results[method][key] = str(value)\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'input_video_info': self.video_info,\n",
        "                'results': serializable_results\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"💾 결과 저장: {results_file}\")\n",
        "\n",
        "    def create_comparison_report(self):\n",
        "        \"\"\"비교 리포트 생성\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"📊 최종 비교 리포트\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        successful_methods = {k: v for k, v in self.results.items() if v.get('status') == 'success'}\n",
        "\n",
        "        if not successful_methods:\n",
        "            print(\"❌ 성공한 테스트가 없습니다!\")\n",
        "            return\n",
        "\n",
        "        # 성능 비교 테이블\n",
        "        print(f\"{'방법':<20} {'처리시간(초)':<12} {'파일크기(MB)':<12} {'PSNR':<8} {'SSIM':<8}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for method, result in successful_methods.items():\n",
        "            processing_time = result.get('processing_time', 0)\n",
        "            file_size = result.get('file_size_mb', 0)\n",
        "\n",
        "            quality = result.get('quality_metrics', {})\n",
        "            psnr_val = quality.get('avg_psnr', 0)\n",
        "            ssim_val = quality.get('avg_ssim', 0)\n",
        "\n",
        "            print(f\"{method:<20} {processing_time:<12.2f} {file_size:<12.2f} {psnr_val:<8.2f} {ssim_val:<8.3f}\")\n",
        "\n",
        "        # 추천 결과\n",
        "        print(\"\\n🏆 추천 결과:\")\n",
        "\n",
        "        # 속도 기준 최고\n",
        "        fastest = min(successful_methods.items(), key=lambda x: x[1].get('processing_time', float('inf')))\n",
        "        print(f\"   ⚡ 가장 빠름: {fastest[0]} ({fastest[1].get('processing_time', 0):.2f}초)\")\n",
        "\n",
        "        # 품질 기준 최고 (SSIM)\n",
        "        quality_methods = {k: v for k, v in successful_methods.items() if v.get('quality_metrics')}\n",
        "        if quality_methods:\n",
        "            best_quality = max(quality_methods.items(),\n",
        "                             key=lambda x: x[1].get('quality_metrics', {}).get('avg_ssim', 0))\n",
        "            ssim_score = best_quality[1].get('quality_metrics', {}).get('avg_ssim', 0)\n",
        "            print(f\"   🎯 최고 품질: {best_quality[0]} (SSIM: {ssim_score:.3f})\")\n",
        "\n",
        "        # 파일 크기 최적화\n",
        "        smallest = min(successful_methods.items(), key=lambda x: x[1].get('file_size_mb', float('inf')))\n",
        "        print(f\"   💾 최소 용량: {smallest[0]} ({smallest[1].get('file_size_mb', 0):.2f}MB)\")\n",
        "\n",
        "# 사용 예시\n",
        "def main():\n",
        "    # 테스트할 영상 경로\n",
        "    input_video = \"final_result.mp4\"  # 여기에 테스트할 영상 경로 입력\n",
        "\n",
        "    if not os.path.exists(input_video):\n",
        "        print(f\"❌ 입력 영상을 찾을 수 없습니다: {input_video}\")\n",
        "        print(\"테스트용 영상을 준비해주세요!\")\n",
        "        return\n",
        "\n",
        "    # 벤치마크 실행\n",
        "    benchmark = FrameInterpolationBenchmark(input_video)\n",
        "    benchmark.run_all_tests()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B54CmXX90zjB",
        "outputId": "320343fc-b444-4a10-c7a0-b90068fa788b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 입력 영상: final_result.mp4\n",
            "📊 영상 정보: {'fps': 30.0, 'width': 966, 'height': 500, 'frame_count': 36, 'duration': 1.2}\n",
            "🚀 프레임 보간 성능 비교 테스트 시작!\n",
            "============================================================\n",
            "\n",
            "🔄 FFmpeg minterpolate 테스트 (목표 FPS: 60)\n",
            "✅ 완료! 처리시간: 8.00초, 파일크기: 0.16MB\n",
            "\n",
            "🔄 프레임 블렌딩 테스트 (목표 FPS: 60)\n",
            "✅ 완료! 처리시간: 1.24초, 파일크기: 0.58MB\n",
            "\n",
            "🔄 RIFE 테스트 (multiplier: 2)\n",
            "⚠️  RIFE 저장소 클론 중...\n",
            "❌ 실패: python3: can't open file '/content/ECCV2022-RIFE/ECCV2022-RIFE/inference_video.py': [Errno 2] No such file or directory\n",
            "\n",
            "\n",
            "============================================================\n",
            "📊 품질 분석 시작...\n",
            "\n",
            "📊 FFmpeg_minterpolate 품질 분석...\n",
            "   PSNR: 42.58 ± 0.60\n",
            "   SSIM: 0.980 ± 0.002\n",
            "\n",
            "📊 Frame_Blending 품질 분석...\n",
            "   PSNR: 28.28 ± 5.74\n",
            "   SSIM: 0.902 ± 0.046\n",
            "💾 결과 저장: benchmark_results/benchmark_results.json\n",
            "\n",
            "============================================================\n",
            "📊 최종 비교 리포트\n",
            "============================================================\n",
            "방법                   처리시간(초)      파일크기(MB)     PSNR     SSIM    \n",
            "----------------------------------------------------------------------\n",
            "FFmpeg_minterpolate  8.00         0.16         42.58    0.980   \n",
            "Frame_Blending       1.24         0.58         28.28    0.902   \n",
            "\n",
            "🏆 추천 결과:\n",
            "   ⚡ 가장 빠름: Frame_Blending (1.24초)\n",
            "   🎯 최고 품질: FFmpeg_minterpolate (SSIM: 0.980)\n",
            "   💾 최소 용량: FFmpeg_minterpolate (0.16MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_missing_frames():\n",
        "    \"\"\"빠진 프레임들을 보간으로 채우기\"\"\"\n",
        "    import glob\n",
        "\n",
        "    images = sorted(glob.glob('output/frame_*.png'))\n",
        "\n",
        "    cap = cv2.VideoCapture('target.mp4')\n",
        "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    cap.release()\n",
        "\n",
        "    img = cv2.imread(images[0])\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    out = cv2.VideoWriter('interpolated_normal_speed.mp4',\n",
        "                         cv2.VideoWriter_fourcc(*'mp4v'), original_fps, (w, h))\n",
        "\n",
        "    for i in range(len(images) - 1):\n",
        "        current_frame = cv2.imread(images[i])\n",
        "        next_frame = cv2.imread(images[i + 1])\n",
        "\n",
        "        # 현재 프레임 쓰기\n",
        "        out.write(current_frame)\n",
        "\n",
        "        # 중간에 9개 프레임 보간\n",
        "        for j in range(1, 10):\n",
        "            alpha = j / 10\n",
        "            blended = cv2.addWeighted(current_frame, 1-alpha, next_frame, alpha, 0)\n",
        "            out.write(blended)\n",
        "\n",
        "    # 마지막 프레임\n",
        "    if images:\n",
        "        last_frame = cv2.imread(images[-1])\n",
        "        for _ in range(10):\n",
        "            out.write(last_frame)\n",
        "\n",
        "    out.release()\n",
        "    print(\"✅ 보간된 정상 속도 영상 완성!\")\n",
        "\n",
        "interpolate_missing_frames()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdnesMS02WWq",
        "outputId": "b1d228f1-b1a6-4cab-d8f6-223e8d903313"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 보간된 정상 속도 영상 완성!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import psutil\n",
        "import GPUtil\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FrameInterpolationBenchmark:\n",
        "    def __init__(self, input_video_path, output_dir=\"benchmark_results\"):\n",
        "        \"\"\"\n",
        "        프레임 보간 성능 비교 평가 시스템\n",
        "\n",
        "        Args:\n",
        "            input_video_path: 테스트할 입력 영상 경로\n",
        "            output_dir: 결과 저장 디렉토리\n",
        "        \"\"\"\n",
        "        self.input_video = input_video_path\n",
        "        self.output_dir = output_dir\n",
        "        self.results = {}\n",
        "\n",
        "        # 출력 디렉토리 생성\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # 영상 정보 가져오기\n",
        "        self.get_video_info()\n",
        "\n",
        "        print(f\"🎬 입력 영상: {input_video_path}\")\n",
        "        print(f\"📊 영상 정보: {self.video_info}\")\n",
        "\n",
        "    def get_video_info(self):\n",
        "        \"\"\"입력 영상 정보 분석\"\"\"\n",
        "        cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "        self.video_info = {\n",
        "            'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "            'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "            'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "            'duration': cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
        "        }\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    def monitor_resources(self):\n",
        "        \"\"\"시스템 리소스 모니터링\"\"\"\n",
        "        cpu_percent = psutil.cpu_percent(interval=1)\n",
        "        memory = psutil.virtual_memory()\n",
        "\n",
        "        gpu_info = []\n",
        "        try:\n",
        "            gpus = GPUtil.getGPUs()\n",
        "            for gpu in gpus:\n",
        "                gpu_info.append({\n",
        "                    'name': gpu.name,\n",
        "                    'utilization': gpu.load * 100,\n",
        "                    'memory_used': gpu.memoryUsed,\n",
        "                    'memory_total': gpu.memoryTotal\n",
        "                })\n",
        "        except:\n",
        "            gpu_info = [{'name': 'N/A', 'utilization': 0, 'memory_used': 0, 'memory_total': 0}]\n",
        "\n",
        "        return {\n",
        "            'cpu_percent': cpu_percent,\n",
        "            'memory_percent': memory.percent,\n",
        "            'memory_used_gb': memory.used / (1024**3),\n",
        "            'gpu_info': gpu_info\n",
        "        }\n",
        "\n",
        "    def test_ffmpeg_minterpolate(self, target_fps=60):\n",
        "        \"\"\"FFmpeg minterpolate 테스트\"\"\"\n",
        "        print(f\"\\n🔄 FFmpeg minterpolate 테스트 (목표 FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"ffmpeg_minterpolate_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', self.input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci',\n",
        "            '-y', output_path\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(output_path) / (1024**2)  # MB\n",
        "\n",
        "                self.results['FFmpeg_minterpolate'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': output_path,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'target_fps': target_fps\n",
        "                }\n",
        "                print(f\"✅ 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(f\"❌ 실패: {result.stderr}\")\n",
        "                self.results['FFmpeg_minterpolate'] = {'status': 'failed', 'error': result.stderr}\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"❌ 시간 초과 (300초)\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'timeout'}\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            self.results['FFmpeg_minterpolate'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_rife(self, multiplier=2):\n",
        "        \"\"\"RIFE 테스트 (GitHub에서 클론 필요)\"\"\"\n",
        "        print(f\"\\n🔄 RIFE 테스트 (multiplier: {multiplier})\")\n",
        "\n",
        "        rife_dir = \"ECCV2022-RIFE\"\n",
        "\n",
        "        # RIFE 설치 및 설정\n",
        "        if not os.path.exists(rife_dir):\n",
        "            print(\"⚠️  RIFE 저장소 클론 중...\")\n",
        "            try:\n",
        "                subprocess.run(['git', 'clone', 'https://github.com/megvii-research/ECCV2022-RIFE.git'],\n",
        "                             check=True, timeout=120)\n",
        "                print(\"✅ RIFE 클론 완료\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"❌ RIFE 클론 실패: {e}\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': f'Clone failed: {e}'}\n",
        "                return\n",
        "            except subprocess.TimeoutExpired:\n",
        "                print(\"❌ RIFE 클론 시간초과\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'Clone timeout'}\n",
        "                return\n",
        "\n",
        "        # 필요한 파일들 확인\n",
        "        inference_script = os.path.join(rife_dir, 'inference_video.py')\n",
        "        if not os.path.exists(inference_script):\n",
        "            print(\"❌ inference_video.py 파일을 찾을 수 없습니다\")\n",
        "            # 대체 스크립트 경로들 확인\n",
        "            alternative_scripts = [\n",
        "                os.path.join(rife_dir, 'inference_img.py'),\n",
        "                os.path.join(rife_dir, 'demo_MiddleBury.py'),\n",
        "                os.path.join(rife_dir, 'test.py')\n",
        "            ]\n",
        "\n",
        "            found_script = None\n",
        "            for script in alternative_scripts:\n",
        "                if os.path.exists(script):\n",
        "                    found_script = script\n",
        "                    print(f\"✅ 대체 스크립트 발견: {script}\")\n",
        "                    break\n",
        "\n",
        "            if not found_script:\n",
        "                print(\"❌ 사용 가능한 RIFE 스크립트를 찾을 수 없습니다\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'No inference script found'}\n",
        "                return\n",
        "\n",
        "            inference_script = found_script\n",
        "\n",
        "        # 의존성 설치\n",
        "        try:\n",
        "            print(\"📦 RIFE 의존성 설치 중...\")\n",
        "            original_dir = os.getcwd()\n",
        "            os.chdir(rife_dir)\n",
        "\n",
        "            # requirements.txt 설치\n",
        "            if os.path.exists('requirements.txt'):\n",
        "                subprocess.run(['pip', 'install', '-r', 'requirements.txt'],\n",
        "                             capture_output=True, timeout=180)\n",
        "\n",
        "            # 필수 패키지 설치\n",
        "            subprocess.run(['pip', 'install', 'torch', 'torchvision', 'opencv-python', 'numpy'],\n",
        "                         capture_output=True, timeout=180)\n",
        "\n",
        "            os.chdir(original_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  의존성 설치 중 오류 (계속 진행): {e}\")\n",
        "\n",
        "        # RIFE 실행\n",
        "        output_path = os.path.join(self.output_dir, f\"rife_x{multiplier}.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        # 절대 경로 사용\n",
        "        abs_input = os.path.abspath(self.input_video)\n",
        "        abs_output = os.path.abspath(output_path)\n",
        "\n",
        "        # 여러 가지 명령어 시도\n",
        "        commands_to_try = [\n",
        "            # 표준 inference_video.py\n",
        "            ['python', 'inference_video.py', f'--exp={multiplier}', f'--video={abs_input}', f'--output={abs_output}'],\n",
        "            # 대체 명령어들\n",
        "            ['python', 'inference_video.py', '--times', str(multiplier), '--video', abs_input, '--output', abs_output],\n",
        "            ['python', 'test.py', '--video', abs_input, '--output', abs_output],\n",
        "        ]\n",
        "\n",
        "        success = False\n",
        "        original_dir = os.getcwd()\n",
        "\n",
        "        try:\n",
        "            os.chdir(rife_dir)\n",
        "\n",
        "            for i, cmd in enumerate(commands_to_try):\n",
        "                print(f\"🔄 RIFE 명령어 시도 {i+1}: {' '.join(cmd)}\")\n",
        "\n",
        "                try:\n",
        "                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n",
        "\n",
        "                    if result.returncode == 0:\n",
        "                        print(f\"✅ RIFE 명령어 {i+1} 성공!\")\n",
        "                        success = True\n",
        "                        break\n",
        "                    else:\n",
        "                        print(f\"❌ 명령어 {i+1} 실패: {result.stderr[:200]}\")\n",
        "\n",
        "                except subprocess.TimeoutExpired:\n",
        "                    print(f\"❌ 명령어 {i+1} 시간 초과\")\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ 명령어 {i+1} 오류: {e}\")\n",
        "\n",
        "            os.chdir(original_dir)\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            if success and os.path.exists(abs_output):\n",
        "                end_resources = self.monitor_resources()\n",
        "                file_size = os.path.getsize(abs_output) / (1024**2)\n",
        "\n",
        "                self.results['RIFE'] = {\n",
        "                    'status': 'success',\n",
        "                    'processing_time': processing_time,\n",
        "                    'output_path': abs_output,\n",
        "                    'file_size_mb': file_size,\n",
        "                    'start_resources': start_resources,\n",
        "                    'end_resources': end_resources,\n",
        "                    'multiplier': multiplier\n",
        "                }\n",
        "                print(f\"✅ RIFE 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "            else:\n",
        "                print(\"❌ RIFE 실행 실패 - 모든 명령어 시도 완료\")\n",
        "                self.results['RIFE'] = {'status': 'failed', 'error': 'All command attempts failed'}\n",
        "\n",
        "        except Exception as e:\n",
        "            os.chdir(original_dir)\n",
        "            print(f\"❌ RIFE 실행 중 오류: {e}\")\n",
        "            self.results['RIFE'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def test_frame_blending(self, target_fps=60):\n",
        "        \"\"\"간단한 프레임 블렌딩 테스트 (기준선)\"\"\"\n",
        "        print(f\"\\n🔄 프레임 블렌딩 테스트 (목표 FPS: {target_fps})\")\n",
        "\n",
        "        output_path = os.path.join(self.output_dir, f\"frame_blending_{target_fps}fps.mp4\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_resources = self.monitor_resources()\n",
        "\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(self.input_video)\n",
        "\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(output_path, fourcc, target_fps,\n",
        "                                (self.video_info['width'], self.video_info['height']))\n",
        "\n",
        "            frames = []\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frames.append(frame)\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "            # 프레임 간 블렌딩으로 보간\n",
        "            interpolation_factor = target_fps / self.video_info['fps']\n",
        "\n",
        "            for i in range(len(frames) - 1):\n",
        "                out.write(frames[i])\n",
        "\n",
        "                # 중간 프레임들 생성\n",
        "                num_inter_frames = int(interpolation_factor) - 1\n",
        "                for j in range(1, num_inter_frames + 1):\n",
        "                    alpha = j / (num_inter_frames + 1)\n",
        "                    blended = cv2.addWeighted(frames[i], 1-alpha, frames[i+1], alpha, 0)\n",
        "                    out.write(blended)\n",
        "\n",
        "            if frames:\n",
        "                out.write(frames[-1])\n",
        "\n",
        "            out.release()\n",
        "\n",
        "            processing_time = time.time() - start_time\n",
        "            end_resources = self.monitor_resources()\n",
        "            file_size = os.path.getsize(output_path) / (1024**2)\n",
        "\n",
        "            self.results['Frame_Blending'] = {\n",
        "                'status': 'success',\n",
        "                'processing_time': processing_time,\n",
        "                'output_path': output_path,\n",
        "                'file_size_mb': file_size,\n",
        "                'start_resources': start_resources,\n",
        "                'end_resources': end_resources,\n",
        "                'target_fps': target_fps\n",
        "            }\n",
        "            print(f\"✅ 완료! 처리시간: {processing_time:.2f}초, 파일크기: {file_size:.2f}MB\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            self.results['Frame_Blending'] = {'status': 'error', 'error': str(e)}\n",
        "\n",
        "    def calculate_quality_metrics(self, method_name, output_path):\n",
        "        \"\"\"품질 지표 계산 (PSNR, SSIM)\"\"\"\n",
        "        print(f\"\\n📊 {method_name} 품질 분석...\")\n",
        "\n",
        "        try:\n",
        "            # 원본과 결과 영상에서 샘플 프레임 추출\n",
        "            original_frames = self.extract_sample_frames(self.input_video, num_samples=10)\n",
        "            result_frames = self.extract_sample_frames(output_path, num_samples=10)\n",
        "\n",
        "            if len(original_frames) == 0 or len(result_frames) == 0:\n",
        "                return None\n",
        "\n",
        "            psnr_scores = []\n",
        "            ssim_scores = []\n",
        "\n",
        "            # 크기 맞추기\n",
        "            min_samples = min(len(original_frames), len(result_frames))\n",
        "\n",
        "            for i in range(min_samples):\n",
        "                orig = original_frames[i]\n",
        "                result = result_frames[i]\n",
        "\n",
        "                # 크기 조정\n",
        "                if orig.shape != result.shape:\n",
        "                    result = cv2.resize(result, (orig.shape[1], orig.shape[0]))\n",
        "\n",
        "                # 그레이스케일 변환\n",
        "                orig_gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)\n",
        "                result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # PSNR 계산\n",
        "                psnr_val = psnr(orig_gray, result_gray, data_range=255)\n",
        "                psnr_scores.append(psnr_val)\n",
        "\n",
        "                # SSIM 계산\n",
        "                ssim_val = ssim(orig_gray, result_gray, data_range=255)\n",
        "                ssim_scores.append(ssim_val)\n",
        "\n",
        "            quality_metrics = {\n",
        "                'avg_psnr': np.mean(psnr_scores),\n",
        "                'avg_ssim': np.mean(ssim_scores),\n",
        "                'psnr_std': np.std(psnr_scores),\n",
        "                'ssim_std': np.std(ssim_scores)\n",
        "            }\n",
        "\n",
        "            self.results[method_name]['quality_metrics'] = quality_metrics\n",
        "            print(f\"   PSNR: {quality_metrics['avg_psnr']:.2f} ± {quality_metrics['psnr_std']:.2f}\")\n",
        "            print(f\"   SSIM: {quality_metrics['avg_ssim']:.3f} ± {quality_metrics['ssim_std']:.3f}\")\n",
        "\n",
        "            return quality_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 품질 분석 실패: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_sample_frames(self, video_path, num_samples=10):\n",
        "        \"\"\"영상에서 샘플 프레임 추출\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if frame_count == 0:\n",
        "            cap.release()\n",
        "            return []\n",
        "\n",
        "        frames = []\n",
        "        step = max(1, frame_count // num_samples)\n",
        "\n",
        "        for i in range(0, frame_count, step):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frames.append(frame)\n",
        "                if len(frames) >= num_samples:\n",
        "                    break\n",
        "\n",
        "        cap.release()\n",
        "        return frames\n",
        "\n",
        "    def run_all_tests(self):\n",
        "        \"\"\"모든 테스트 실행\"\"\"\n",
        "        print(\"🚀 프레임 보간 성능 비교 테스트 시작!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # 1. FFmpeg minterpolate\n",
        "        self.test_ffmpeg_minterpolate(target_fps=60)\n",
        "\n",
        "        # 2. Frame Blending (기준선)\n",
        "        self.test_frame_blending(target_fps=60)\n",
        "\n",
        "        # 3. RIFE (조건부)\n",
        "        if self.should_test_rife():\n",
        "            self.test_rife(multiplier=2)\n",
        "        else:\n",
        "            print(\"\\n⚠️  RIFE 테스트 건너뜀 (의존성 없음)\")\n",
        "\n",
        "        # 품질 분석\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"📊 품질 분석 시작...\")\n",
        "\n",
        "        for method, result in self.results.items():\n",
        "            if result.get('status') == 'success':\n",
        "                self.calculate_quality_metrics(method, result['output_path'])\n",
        "\n",
        "        # 결과 저장 및 시각화\n",
        "        self.save_results()\n",
        "        self.create_comparison_report()\n",
        "\n",
        "    def should_test_rife(self):\n",
        "        \"\"\"RIFE 테스트 가능 여부 확인\"\"\"\n",
        "        try:\n",
        "            # PyTorch 설치 여부 확인\n",
        "            import torch\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"결과를 JSON 파일로 저장\"\"\"\n",
        "        results_file = os.path.join(self.output_dir, \"benchmark_results.json\")\n",
        "\n",
        "        # datetime 객체들을 문자열로 변환\n",
        "        serializable_results = {}\n",
        "        for method, result in self.results.items():\n",
        "            serializable_results[method] = {}\n",
        "            for key, value in result.items():\n",
        "                if isinstance(value, (dict, list, str, int, float, bool)) or value is None:\n",
        "                    serializable_results[method][key] = value\n",
        "                else:\n",
        "                    serializable_results[method][key] = str(value)\n",
        "\n",
        "        with open(results_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'input_video_info': self.video_info,\n",
        "                'results': serializable_results\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"💾 결과 저장: {results_file}\")\n",
        "\n",
        "    def create_comparison_report(self):\n",
        "        \"\"\"비교 리포트 생성\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"📊 최종 비교 리포트\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        successful_methods = {k: v for k, v in self.results.items() if v.get('status') == 'success'}\n",
        "\n",
        "        if not successful_methods:\n",
        "            print(\"❌ 성공한 테스트가 없습니다!\")\n",
        "            return\n",
        "\n",
        "        # 성능 비교 테이블\n",
        "        print(f\"{'방법':<20} {'처리시간(초)':<12} {'파일크기(MB)':<12} {'PSNR':<8} {'SSIM':<8}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for method, result in successful_methods.items():\n",
        "            processing_time = result.get('processing_time', 0)\n",
        "            file_size = result.get('file_size_mb', 0)\n",
        "\n",
        "            quality = result.get('quality_metrics', {})\n",
        "            psnr_val = quality.get('avg_psnr', 0)\n",
        "            ssim_val = quality.get('avg_ssim', 0)\n",
        "\n",
        "            print(f\"{method:<20} {processing_time:<12.2f} {file_size:<12.2f} {psnr_val:<8.2f} {ssim_val:<8.3f}\")\n",
        "\n",
        "        # 추천 결과\n",
        "        print(\"\\n🏆 추천 결과:\")\n",
        "\n",
        "        # 속도 기준 최고\n",
        "        fastest = min(successful_methods.items(), key=lambda x: x[1].get('processing_time', float('inf')))\n",
        "        print(f\"   ⚡ 가장 빠름: {fastest[0]} ({fastest[1].get('processing_time', 0):.2f}초)\")\n",
        "\n",
        "        # 품질 기준 최고 (SSIM)\n",
        "        quality_methods = {k: v for k, v in successful_methods.items() if v.get('quality_metrics')}\n",
        "        if quality_methods:\n",
        "            best_quality = max(quality_methods.items(),\n",
        "                             key=lambda x: x[1].get('quality_metrics', {}).get('avg_ssim', 0))\n",
        "            ssim_score = best_quality[1].get('quality_metrics', {}).get('avg_ssim', 0)\n",
        "            print(f\"   🎯 최고 품질: {best_quality[0]} (SSIM: {ssim_score:.3f})\")\n",
        "\n",
        "        # 파일 크기 최적화\n",
        "        smallest = min(successful_methods.items(), key=lambda x: x[1].get('file_size_mb', float('inf')))\n",
        "        print(f\"   💾 최소 용량: {smallest[0]} ({smallest[1].get('file_size_mb', 0):.2f}MB)\")\n",
        "\n",
        "# 사용 예시\n",
        "def main():\n",
        "    # 테스트할 영상 경로\n",
        "    input_video = \"final_result.mp4\"  # 여기에 테스트할 영상 경로 입력\n",
        "\n",
        "    if not os.path.exists(input_video):\n",
        "        print(f\"❌ 입력 영상을 찾을 수 없습니다: {input_video}\")\n",
        "        print(\"테스트용 영상을 준비해주세요!\")\n",
        "        return\n",
        "\n",
        "    # 벤치마크 실행\n",
        "    benchmark = FrameInterpolationBenchmark(input_video)\n",
        "    benchmark.run_all_tests()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-RamNp52tIu",
        "outputId": "96119e18-c77f-42cb-f0c3-642d7da25146"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 입력 영상: final_result.mp4\n",
            "📊 영상 정보: {'fps': 30.0, 'width': 966, 'height': 500, 'frame_count': 36, 'duration': 1.2}\n",
            "🚀 프레임 보간 성능 비교 테스트 시작!\n",
            "============================================================\n",
            "\n",
            "🔄 FFmpeg minterpolate 테스트 (목표 FPS: 60)\n",
            "✅ 완료! 처리시간: 6.47초, 파일크기: 0.16MB\n",
            "\n",
            "🔄 프레임 블렌딩 테스트 (목표 FPS: 60)\n",
            "✅ 완료! 처리시간: 1.21초, 파일크기: 0.58MB\n",
            "\n",
            "🔄 RIFE 테스트 (multiplier: 2)\n",
            "📦 RIFE 의존성 설치 중...\n",
            "🔄 RIFE 명령어 시도 1: python inference_video.py --exp=2 --video=/content/final_result.mp4 --output=/content/benchmark_results/rife_x2.mp4\n",
            "❌ 명령어 1 실패: Traceback (most recent call last):\n",
            "  File \"/content/ECCV2022-RIFE/inference_video.py\", line 91, in <module>\n",
            "    from model.RIFE_HDv2 import Model\n",
            "ModuleNotFoundError: No module named 'model.RIFE_HDv2'\n",
            "🔄 RIFE 명령어 시도 2: python inference_video.py --times 2 --video /content/final_result.mp4 --output /content/benchmark_results/rife_x2.mp4\n",
            "❌ 명령어 2 실패: usage: inference_video.py [-h] [--video VIDEO] [--output OUTPUT] [--img IMG]\n",
            "                          [--montage] [--model MODELDIR] [--fp16] [--UHD]\n",
            "                          [--scale SCALE] [--skip\n",
            "🔄 RIFE 명령어 시도 3: python test.py --video /content/final_result.mp4 --output /content/benchmark_results/rife_x2.mp4\n",
            "❌ 명령어 3 실패: python3: can't open file '/content/ECCV2022-RIFE/test.py': [Errno 2] No such file or directory\n",
            "\n",
            "❌ RIFE 실행 실패 - 모든 명령어 시도 완료\n",
            "\n",
            "============================================================\n",
            "📊 품질 분석 시작...\n",
            "\n",
            "📊 FFmpeg_minterpolate 품질 분석...\n",
            "   PSNR: 42.58 ± 0.60\n",
            "   SSIM: 0.980 ± 0.002\n",
            "\n",
            "📊 Frame_Blending 품질 분석...\n",
            "   PSNR: 28.28 ± 5.74\n",
            "   SSIM: 0.902 ± 0.046\n",
            "💾 결과 저장: benchmark_results/benchmark_results.json\n",
            "\n",
            "============================================================\n",
            "📊 최종 비교 리포트\n",
            "============================================================\n",
            "방법                   처리시간(초)      파일크기(MB)     PSNR     SSIM    \n",
            "----------------------------------------------------------------------\n",
            "FFmpeg_minterpolate  6.47         0.16         42.58    0.980   \n",
            "Frame_Blending       1.21         0.58         28.28    0.902   \n",
            "\n",
            "🏆 추천 결과:\n",
            "   ⚡ 가장 빠름: Frame_Blending (1.21초)\n",
            "   🎯 최고 품질: FFmpeg_minterpolate (SSIM: 0.980)\n",
            "   💾 최소 용량: FFmpeg_minterpolate (0.16MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def change_video_speed_colab(input_video, output_video, speed=1.0):\n",
        "    \"\"\"\n",
        "    오디오 없는 영상 속도 조절 (느리게/빠르게) - Colab 용\n",
        "    Args:\n",
        "        input_video (str): 입력 파일\n",
        "        output_video (str): 출력 파일\n",
        "        speed (float): 속도 배수 (예: 0.25 = 느리게, 4.0 = 빠르게)\n",
        "    \"\"\"\n",
        "    print(f\"🎞️ 영상 속도 {speed}배 {'빠르게' if speed > 1 else '느리게'}: {input_video}\")\n",
        "\n",
        "    # setpts 공식: 느리게는 큰 값, 빠르게는 작은 값\n",
        "    setpts_value = speed\n",
        "    cmd = [\n",
        "        'ffmpeg', '-i', input_video,\n",
        "        '-filter:v', f'setpts={setpts_value:.3f}*PTS',\n",
        "        '-y', output_video\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        size = os.path.getsize(output_video) / (1024**2)\n",
        "        print(f\"✅ 완료: {output_video} ({size:.1f}MB)\")\n",
        "    else:\n",
        "        print(f\"❌ 실패: {result.stderr}\")\n",
        "\n",
        "##ffmpeg승\n"
      ],
      "metadata": {
        "id": "8nZDBeJR3axb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예: final_result.mp4 를 0.25배 ~ 4배 속도로 각각 생성\n",
        "batch_change_speeds(\"/content/benchmark_results/frame_blending_60fps.mp4\", speeds=[0.25, 0.5, 1.0, 2.0, 4.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-5dMCZH5Qwi",
        "outputId": "6bd424b0-4ce9-47d5-8243-e8da058d737c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ 원본: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "🎞️ 영상 속도 0.25배 느리게: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "✅ 완료: /content/benchmark_results/frame_blending_60fps_0.25x.mp4 (0.1MB)\n",
            "🎞️ 영상 속도 0.5배 느리게: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "✅ 완료: /content/benchmark_results/frame_blending_60fps_0.5x.mp4 (0.1MB)\n",
            "🎞️ 영상 속도 1.0배 느리게: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "✅ 완료: /content/benchmark_results/frame_blending_60fps_1.0x.mp4 (0.2MB)\n",
            "🎞️ 영상 속도 2.0배 빠르게: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "✅ 완료: /content/benchmark_results/frame_blending_60fps_2.0x.mp4 (0.3MB)\n",
            "🎞️ 영상 속도 4.0배 빠르게: /content/benchmark_results/frame_blending_60fps.mp4\n",
            "✅ 완료: /content/benchmark_results/frame_blending_60fps_4.0x.mp4 (0.4MB)\n"
          ]
        }
      ]
    }
  ]
}