{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01star01ek/01star01ek/blob/main/%EC%96%BC%EA%B5%B4%EB%B0%94%EA%BE%B8%EA%B3%A0%20%EC%98%81%EC%83%81%EA%B9%8C%EC%A7%80%20%EB%8C%80%EC%8B%A0%20%EA%B0%84%EB%8B%A8%ED%95%98%EA%B2%8C_deepfake_small_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install dependency"
      ],
      "metadata": {
        "id": "An3Kh3m69Jqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.11\n",
        "!pip install opencv-contrib-python flatbuffers==23.5.26 sounddevice==0.4.6 attrs==23.1.0\n",
        "!pip install torch==2.1.0 torchvision==0.16.0\n",
        "!pip install dlib opencv-python scikit-image pillow matplotlib imageio gdown tqdm\n",
        "!pip install ninja tensorboard tensorboardX pyaml pyrallis ftfy\n",
        "!pip install face-alignment==1.3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ah4vUmMoLXIo",
        "outputId": "453e8322-121b-43ff-c817-45c36834f476"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.11\n",
            "  Downloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (2.6.0+cu124)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe==0.10.11) (4.11.0.86)\n",
            "Collecting protobuf<4,>=3.11 (from mediapipe==0.10.11)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.11)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.11) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe==0.10.11) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe==0.10.11) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->mediapipe==0.10.11)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->mediapipe==0.10.11) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->mediapipe==0.10.11) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.11) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.11) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mediapipe==0.10.11) (3.0.2)\n",
            "Downloading mediapipe-0.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.11 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 sounddevice-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "383fa87db10849e8939594932dd5a045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting flatbuffers==23.5.26\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting sounddevice==0.4.6\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting attrs==23.1.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice==0.4.6) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice==0.4.6) (2.22)\n",
            "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flatbuffers, attrs, sounddevice\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: sounddevice\n",
            "    Found existing installation: sounddevice 0.5.2\n",
            "    Uninstalling sounddevice-0.5.2:\n",
            "      Successfully uninstalled sounddevice-0.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 flatbuffers-23.5.26 sounddevice-0.4.6\n",
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.16.0\n",
            "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0)\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.0) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n",
            "Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 torchvision-0.16.0 triton-2.1.0\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.11/dist-packages (19.24.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pyaml\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyrallis\n",
            "  Downloading pyrallis-0.3.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml) (6.0.2)\n",
            "Collecting typing-inspect (from pyrallis)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyrallis)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyrallis) (4.14.0)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading pyrallis-0.3.1-py3-none-any.whl (33 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: tensorboardX, pyaml, ninja, mypy-extensions, ftfy, typing-inspect, pyrallis\n",
            "Successfully installed ftfy-6.3.1 mypy-extensions-1.1.0 ninja-1.11.1.4 pyaml-25.5.0 pyrallis-0.3.1 tensorboardX-2.6.4 typing-inspect-0.9.0\n",
            "Collecting face-alignment==1.3.5\n",
            "  Downloading face_alignment-1.3.5-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (1.15.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment==1.3.5) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment==1.3.5) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment==1.3.5) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment==1.3.5) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->face-alignment==1.3.5) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment==1.3.5) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->face-alignment==1.3.5) (1.3.0)\n",
            "Downloading face_alignment-1.3.5-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "j6kl565aMbdT",
        "outputId": "0daf9a89-a296-4f13-bb0e-fc165ff18cd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires flatbuffers>=24.3.25, but you have flatbuffers 23.5.26 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ede1098fec8d43d58e6ebecd1a114b24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/extract_frames\n",
        "!mkdir -p /content/input_videos\n",
        "!mkdir -p /content/alignmented_frame\n",
        "!mkdir -p /content/alignmented_frame_aligned\n",
        "!mkdir -p /content/alignmented_frame_croped\n",
        "!mkdir -p /content/alignmented_frame_transforms"
      ],
      "metadata": {
        "id": "UlYQQ1my-rL-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#git hub & model install"
      ],
      "metadata": {
        "id": "Io1UJS2j-HYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yuval-alaluf/stylegan3-editing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae5jdZJn-UUn",
        "outputId": "5c7f5eaa-f3f9-4f79-e4ad-10b24f916cd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stylegan3-editing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## models"
      ],
      "metadata": {
        "id": "8gQABgnW-aOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -P /content/pretrained_models/\n",
        "!bzip2 -d /content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBZNpi4s-HAa",
        "outputId": "c55e6472-2dc5-4991-b5a5-b367bcd3792a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-20 02:35:40--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 [following]\n",
            "--2025-06-20 02:35:40--  https://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  38.3MB/s    in 1.6s    \n",
            "\n",
            "2025-06-20 02:35:42 (38.3 MB/s) - ‘/content/pretrained_models/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "bzip2: Output file /content/pretrained_models/shape_predictor_68_face_landmarks.dat already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm -O /content/pretrained_models/restyle_e4e_sg3.pt\n",
        "!gdown --id 13q6m-bpe3Ws9en9y45JEx2PHQirStt8N -O /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
        "!gdown --id 1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn -O /content/pretrained_models/model_ir_se50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntmFmSfd-ZiO",
        "outputId": "472a1958-7a31-4237-fec3-72dcc9938604"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm\n",
            "From (redirected): https://drive.google.com/uc?id=1z_cB187QOc6aqVBdLvYvBjoc93-_EuRm&confirm=t&uuid=ded2c488-64ac-4813-bdfa-e326999a9cc1\n",
            "To: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "100% 809M/809M [00:11<00:00, 71.4MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N\n",
            "From (redirected): https://drive.google.com/uc?id=13q6m-bpe3Ws9en9y45JEx2PHQirStt8N&confirm=t&uuid=6288f3fa-5e19-4a33-89aa-efe6e7924f73\n",
            "To: /content/pretrained_models/stylegan3-ffhq-1024x1024.pt\n",
            "100% 60.4M/60.4M [00:00<00:00, 70.8MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn\n",
            "From (redirected): https://drive.google.com/uc?id=1KW7bjndL3QG3sxBbZxreGHigcCCpsDgn&confirm=t&uuid=ca07a27c-f5c9-4cce-8900-83c3ab9cf394\n",
            "To: /content/pretrained_models/model_ir_se50.pth\n",
            "100% 175M/175M [00:04<00:00, 40.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/stylegan3-editing/pretrained_models\n",
        "!cp /content/pretrained_models/shape_predictor_68_face_landmarks.dat /content/stylegan3-editing/pretrained_models/"
      ],
      "metadata": {
        "id": "aCa0uxct-mxb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess frames"
      ],
      "metadata": {
        "id": "PBElw7K4_zJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 단일 프로세스 프레임 추출 코드\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "video_dir = \"/content/input_videos\"  #@param {type:\"string\"}\n",
        "output_base = \"/content/extract_frames\"  #@param {type:\"string\"}\n",
        "extract_per_sec = 7  #@param {type:\"integer\"}\n",
        "\n",
        "os.makedirs(output_base, exist_ok=True)\n",
        "\n",
        "def extract_video_frames(video_path):\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    output_dir = os.path.join(output_base, video_name)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    interval = max(1, int(fps // extract_per_sec))\n",
        "\n",
        "    frame_idx = 0\n",
        "    frame_list = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_idx % interval == 0:\n",
        "            frame_list.append(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # 여기서 한 번에 저장!\n",
        "    for saved_idx, frame in enumerate(frame_list):\n",
        "        frame_path = os.path.join(output_dir, f\"key_{saved_idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    return f\"{video_name}: {len(frame_list)} frames saved\"\n",
        "\n",
        "# 실행\n",
        "video_paths = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "print(f\"🎬 총 {len(video_paths)}개의 영상 처리 시작\")\n",
        "\n",
        "for video_path in tqdm(video_paths, desc=\"📦 Processing videos\"):\n",
        "    msg = extract_video_frames(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U3XEaKpDfN2",
        "outputId": "0b281adf-1de4-43a6-f929-bf918295fcf6",
        "cellView": "code"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎬 총 4개의 영상 처리 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📦 Processing videos: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 피치 제한 강화 + 눈뜸 50% 기준 + KeyError 해결 코드\n",
        "import cv2, os, math, numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "FACE_MESH = mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.7,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "# 눈 좌표 인덱스\n",
        "LEFT_EYE_IDX = [\n",
        "    33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246,\n",
        "    33, 173, 157, 158, 159, 160, 161, 246, 33\n",
        "]\n",
        "RIGHT_EYE_IDX = [\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 263, 249, 390, 373, 374, 380, 381, 382,\n",
        "    362, 398, 384, 385, 386, 387, 388, 466, 362\n",
        "]\n",
        "\n",
        "CORE_LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "CORE_RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "LEFT_EYE_VERTICAL = [159, 145]\n",
        "RIGHT_EYE_VERTICAL = [386, 374]\n",
        "POSE_IDX = [1, 152, 33, 263, 61, 291]\n",
        "\n",
        "# 파라미터 설정 - 피치 제한 강화, 눈뜸 기준 완화\n",
        "YAW_T = 25\n",
        "PITCH_T = 25  # 35에서 25로 강화 (피치 관대하게 하지 않음)\n",
        "HEAD_DOWN_BONUS = 1  # 보너스 최소화\n",
        "ENABLE_ADAPTIVE_EAR = True\n",
        "EAR_PERCENTILE_HIGH = 37 # 상위 50%를 눈뜬 상태로 판정 (기존 40%에서 완화)\n",
        "EAR_PERCENTILE_LOW = 10\n",
        "\n",
        "model_points = np.array([\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (0.0, -330.0, -65.0),\n",
        "    (-225.0, 170.0, -135.0),\n",
        "    (225.0, 170.0, -135.0),\n",
        "    (-150.0, -150.0, -125.0),\n",
        "    (150.0, -150.0, -125.0)\n",
        "], dtype=\"double\")\n",
        "\n",
        "def get_mediapipe_landmarks(img):\n",
        "    h, w = img.shape[:2]\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = FACE_MESH.process(rgb)\n",
        "    if not res.multi_face_landmarks:\n",
        "        return None\n",
        "    lm = res.multi_face_landmarks[0]\n",
        "    coords = np.array([[p.x * w, p.y * h] for p in lm.landmark])\n",
        "    return coords\n",
        "\n",
        "def estimate_pose_mediapipe(landmarks, img_shape):\n",
        "    image_points = landmarks[POSE_IDX]\n",
        "    focal = img_shape[1]\n",
        "    center = (img_shape[1]/2, img_shape[0]/2)\n",
        "    cam = np.array([[focal, 0, center[0]], [0, focal, center[1]], [0, 0, 1]], dtype=\"double\")\n",
        "    dist = np.zeros((4,1))\n",
        "    success, rv, _ = cv2.solvePnP(model_points, image_points, cam, dist)\n",
        "    return rv if success else None\n",
        "\n",
        "def rotation_vector_to_euler(rv):\n",
        "    rmat, _ = cv2.Rodrigues(rv)\n",
        "    proj = np.hstack((rmat, np.zeros((3,1))))\n",
        "    angles = cv2.decomposeProjectionMatrix(proj)[6]\n",
        "    pitch = math.degrees(math.asin(math.sin(math.radians(angles[1][0]))))\n",
        "    yaw   = math.degrees(math.asin(math.sin(math.radians(angles[2][0]))))\n",
        "    roll  = -math.degrees(math.asin(math.sin(math.radians(angles[0][0]))))\n",
        "    return pitch, yaw, roll\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "    A = np.linalg.norm(eye[1] - eye[5])\n",
        "    B = np.linalg.norm(eye[2] - eye[4])\n",
        "    C = np.linalg.norm(eye[0] - eye[3])\n",
        "    return (A + B) / (2.0 * C)\n",
        "\n",
        "def enhanced_eye_aspect_ratio(landmarks, is_left=True):\n",
        "    if is_left:\n",
        "        outer = landmarks[33]\n",
        "        inner = landmarks[133]\n",
        "        v1 = np.linalg.norm(landmarks[159] - landmarks[145])\n",
        "        v2 = np.linalg.norm(landmarks[158] - landmarks[153])\n",
        "        v3 = np.linalg.norm(landmarks[160] - landmarks[144])\n",
        "    else:\n",
        "        outer = landmarks[362]\n",
        "        inner = landmarks[263]\n",
        "        v1 = np.linalg.norm(landmarks[386] - landmarks[374])\n",
        "        v2 = np.linalg.norm(landmarks[385] - landmarks[373])\n",
        "        v3 = np.linalg.norm(landmarks[387] - landmarks[380])\n",
        "\n",
        "    horizontal = np.linalg.norm(outer - inner)\n",
        "    avg_vertical = (v1 + v2 + v3) / 3.0\n",
        "    return avg_vertical / horizontal\n",
        "\n",
        "def calculate_adaptive_ear_thresholds(all_ear_values):\n",
        "    \"\"\"영상별 적응형 EAR 임계값 계산 - 50% 기준 적용\"\"\"\n",
        "    if len(all_ear_values) < 5:\n",
        "        return {\n",
        "            'high_threshold': 0.23,\n",
        "            'medium_threshold': 0.18,\n",
        "            'low_threshold': 0.15,\n",
        "            'min_threshold': 0.12\n",
        "        }\n",
        "\n",
        "    ear_array = np.array(all_ear_values)\n",
        "\n",
        "    # 50% 기준으로 임계값 설정\n",
        "    high_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH)  # 상위 50%\n",
        "    medium_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.2)  # 상위 60%\n",
        "    low_threshold = np.percentile(ear_array, 100 - EAR_PERCENTILE_HIGH * 1.5)  # 상위 75%\n",
        "    min_threshold = np.percentile(ear_array, EAR_PERCENTILE_LOW)  # 하위 10%\n",
        "\n",
        "    # 최소값 보장\n",
        "    high_threshold = max(high_threshold, 0.16)  # 더 관대하게\n",
        "    medium_threshold = max(medium_threshold, 0.13)\n",
        "    low_threshold = max(low_threshold, 0.10)\n",
        "    min_threshold = max(min_threshold, 0.07)\n",
        "\n",
        "    return {\n",
        "        'high_threshold': high_threshold,\n",
        "        'medium_threshold': medium_threshold,\n",
        "        'low_threshold': low_threshold,\n",
        "        'min_threshold': min_threshold,\n",
        "        'ear_stats': {\n",
        "            'mean': np.mean(ear_array),\n",
        "            'std': np.std(ear_array),\n",
        "            'min': np.min(ear_array),\n",
        "            'max': np.max(ear_array),\n",
        "            'count': len(ear_array)\n",
        "        }\n",
        "    }\n",
        "\n",
        "def is_eye_open_adaptive(landmarks, thresholds, pitch_angle=0):\n",
        "    \"\"\"적응형 EAR 기반 눈뜸 판정 - 피치 조정 최소화\"\"\"\n",
        "\n",
        "    left_eye_basic = landmarks[CORE_LEFT_EYE]\n",
        "    right_eye_basic = landmarks[CORE_RIGHT_EYE]\n",
        "\n",
        "    basic_left_ear = eye_aspect_ratio(left_eye_basic)\n",
        "    basic_right_ear = eye_aspect_ratio(right_eye_basic)\n",
        "    basic_avg_ear = (basic_left_ear + basic_right_ear) / 2.0\n",
        "\n",
        "    enhanced_left_ear = enhanced_eye_aspect_ratio(landmarks, True)\n",
        "    enhanced_right_ear = enhanced_eye_aspect_ratio(landmarks, False)\n",
        "    enhanced_avg_ear = (enhanced_left_ear + enhanced_right_ear) / 2.0\n",
        "\n",
        "    ear_difference = abs(basic_left_ear - basic_right_ear)\n",
        "\n",
        "    # 피치 조정 최소화 (관대하게 하지 않음)\n",
        "    pitch_factor = 1.0\n",
        "    if pitch_angle > 20:  # 20도 이상에서만 최소 조정\n",
        "        pitch_factor = max(0.95, 1.0 - (pitch_angle - 20) * 0.005)  # 최대 5%만 완화\n",
        "\n",
        "    # 적응형 임계값 적용\n",
        "    adj_high = thresholds['high_threshold'] * pitch_factor\n",
        "    adj_medium = thresholds['medium_threshold'] * pitch_factor\n",
        "    adj_low = thresholds['low_threshold'] * pitch_factor\n",
        "    adj_min = thresholds['min_threshold'] * pitch_factor\n",
        "\n",
        "    # 4단계 눈뜸 판정\n",
        "    level_1 = (basic_avg_ear > adj_high and\n",
        "               enhanced_avg_ear > adj_high * 0.9 and\n",
        "               basic_left_ear > adj_medium and\n",
        "               basic_right_ear > adj_medium and\n",
        "               ear_difference < 0.08)\n",
        "\n",
        "    level_2 = (basic_avg_ear > adj_medium and\n",
        "               enhanced_avg_ear > adj_medium * 0.8 and\n",
        "               basic_left_ear > adj_low and\n",
        "               basic_right_ear > adj_low and\n",
        "               ear_difference < 0.12)\n",
        "\n",
        "    level_3 = (basic_avg_ear > adj_low and\n",
        "               basic_left_ear > adj_min and\n",
        "               basic_right_ear > adj_min and\n",
        "               ear_difference < 0.15)\n",
        "\n",
        "    level_4 = (basic_avg_ear > adj_min and\n",
        "               basic_left_ear > adj_min * 0.8 and\n",
        "               basic_right_ear > adj_min * 0.8)\n",
        "\n",
        "    # 레벨별 점수 부여\n",
        "    if level_1:\n",
        "        eye_level = 4\n",
        "    elif level_2:\n",
        "        eye_level = 3\n",
        "    elif level_3:\n",
        "        eye_level = 2\n",
        "    elif level_4:\n",
        "        eye_level = 1\n",
        "    else:\n",
        "        eye_level = 0\n",
        "\n",
        "    return eye_level, {\n",
        "        'basic_ear': basic_avg_ear,\n",
        "        'enhanced_ear': enhanced_avg_ear,\n",
        "        'left_ear': basic_left_ear,\n",
        "        'right_ear': basic_right_ear,\n",
        "        'ear_diff': ear_difference,\n",
        "        'eye_level': eye_level,\n",
        "        'pitch_factor': pitch_factor,\n",
        "        'thresholds_used': {\n",
        "            'high': adj_high,\n",
        "            'medium': adj_medium,\n",
        "            'low': adj_low,\n",
        "            'min': adj_min\n",
        "        }\n",
        "    }\n",
        "\n",
        "def frontal_score_strict_pitch(c):\n",
        "    \"\"\"피치 제한 강화된 정면성 평가 함수\"\"\"\n",
        "\n",
        "    yaw_angle = abs(c['yaw'])\n",
        "    pitch_angle = c['pitch']\n",
        "\n",
        "    # 엄격한 각도 제한 (피치 관대하게 하지 않음)\n",
        "    if yaw_angle > YAW_T:  # 25도\n",
        "        return -1000\n",
        "    if abs(pitch_angle) > PITCH_T:  # ±25도 (엄격)\n",
        "        return -1000\n",
        "\n",
        "    # 기본 페널티 (피치에 더 큰 가중치)\n",
        "    yaw_penalty = yaw_angle * 0.8\n",
        "    pitch_penalty = abs(pitch_angle) * 1.2  # 피치 페널티 증가\n",
        "\n",
        "    # 고개 숙임 보너스 최소화\n",
        "    head_down_bonus = 0\n",
        "    if -15 <= pitch_angle <= -5:  # 아주 제한적인 범위에서만\n",
        "        head_down_bonus = HEAD_DOWN_BONUS * 0.5  # 보너스도 절반으로\n",
        "\n",
        "    # 눈뜸 레벨 보너스\n",
        "    eye_level = c.get('eye_level', 0)\n",
        "    eye_bonus = eye_level * 12  # 눈뜸이 더 중요\n",
        "\n",
        "    bonus = eye_bonus + (head_down_bonus if pitch_angle < 0 else 0)\n",
        "\n",
        "    return -(0.5 * yaw_penalty + 0.5 * pitch_penalty) + bonus\n",
        "\n",
        "def calculate_final_quality_score(pitch, yaw, eye_level, ear_details):\n",
        "    \"\"\"최종 품질 점수 계산 - 피치 페널티 강화\"\"\"\n",
        "\n",
        "    # 각도 점수 (피치에 더 큰 페널티)\n",
        "    yaw_score = max(0, 100 - abs(yaw) * 2.0)\n",
        "    pitch_score = max(0, 100 - abs(pitch) * 2.5)  # 피치 페널티 증가\n",
        "    angle_score = (yaw_score + pitch_score) / 2\n",
        "\n",
        "    # 눈뜸 레벨 점수 (50% 기준이므로 더 관대)\n",
        "    eye_score = eye_level * 25\n",
        "\n",
        "    # EAR 품질 점수\n",
        "    ear_quality = min(100, ear_details['basic_ear'] * 300)\n",
        "\n",
        "    # 종합 점수 (눈뜸 비중 증가)\n",
        "    total_score = (\n",
        "        angle_score * 0.3 +    # 각도 30%\n",
        "        eye_score * 0.5 +      # 눈뜸 50% (증가)\n",
        "        ear_quality * 0.2      # EAR 품질 20%\n",
        "    )\n",
        "\n",
        "    return total_score\n",
        "\n",
        "# 경로 설정\n",
        "INPUT_ROOT = \"/content/extract_frames\"\n",
        "OUTPUT_ROOT = \"/content/alignmented_frame\"\n",
        "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
        "\n",
        "file_ext = \".jpg\"\n",
        "video_dirs = [d for d in os.listdir(INPUT_ROOT) if os.path.isdir(os.path.join(INPUT_ROOT, d))]\n",
        "missing_videos = []\n",
        "detailed_log = []\n",
        "best_images = []\n",
        "best_names = []\n",
        "\n",
        "print(f\"📦 총 {len(video_dirs)}개 영상 처리 시작\")\n",
        "print(f\"🎯 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (50% 기준으로 완화)\")\n",
        "print(f\"📐 각도 제한: Yaw ±{YAW_T}°, Pitch ±{PITCH_T}° (피치 제한 강화)\")\n",
        "print(f\"🎁 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소화)\")\n",
        "\n",
        "for video_name in tqdm(video_dirs, desc=\"🎯 Strict pitch + 50% eye threshold\"):\n",
        "    input_dir = os.path.join(INPUT_ROOT, video_name)\n",
        "\n",
        "    # 1단계: 모든 프레임의 EAR 값 수집\n",
        "    all_ear_values = []\n",
        "    frame_data = []\n",
        "\n",
        "    for f in sorted(os.listdir(input_dir)):\n",
        "        if not f.lower().endswith(file_ext):\n",
        "            continue\n",
        "\n",
        "        full_path = os.path.join(input_dir, f)\n",
        "        img = cv2.imread(full_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        lm = get_mediapipe_landmarks(img)\n",
        "        if lm is None:\n",
        "            continue\n",
        "\n",
        "        rv = estimate_pose_mediapipe(lm, img.shape)\n",
        "        if rv is None:\n",
        "            continue\n",
        "\n",
        "        pitch, yaw, _ = rotation_vector_to_euler(rv)\n",
        "\n",
        "        # 엄격한 각도 제한\n",
        "        if abs(yaw) > YAW_T * 1.5 or abs(pitch) > PITCH_T * 1.5:\n",
        "            continue\n",
        "\n",
        "        # EAR 계산\n",
        "        left_eye = lm[CORE_LEFT_EYE]\n",
        "        right_eye = lm[CORE_RIGHT_EYE]\n",
        "        left_ear = eye_aspect_ratio(left_eye)\n",
        "        right_ear = eye_aspect_ratio(right_eye)\n",
        "        avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "        all_ear_values.append(avg_ear)\n",
        "\n",
        "        # 프레임 데이터 저장\n",
        "        x1, y1 = lm[:,0].min(), lm[:,1].min()\n",
        "        x2, y2 = lm[:,0].max(), lm[:,1].max()\n",
        "        face_area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "        frame_data.append({\n",
        "            'img': img,\n",
        "            'filename': f,\n",
        "            'landmarks': lm,\n",
        "            'pitch': pitch,\n",
        "            'yaw': yaw,\n",
        "            'avg_ear': avg_ear,\n",
        "            'cx': cx,\n",
        "            'cy': cy,\n",
        "            'face_area': face_area\n",
        "        })\n",
        "\n",
        "    if not all_ear_values:\n",
        "        missing_videos.append(video_name)\n",
        "        detailed_log.append({\n",
        "            'video_name': video_name,\n",
        "            'total_frames': 0,\n",
        "            'selected': False,\n",
        "            'selection_level': 0,  # KeyError 방지를 위해 추가\n",
        "            'reason': 'No valid frames found'\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 2단계: 적응형 임계값 계산 (50% 기준)\n",
        "    thresholds = calculate_adaptive_ear_thresholds(all_ear_values)\n",
        "\n",
        "    # 3단계: 4단계 후보 분류\n",
        "    level_4_candidates = []\n",
        "    level_3_candidates = []\n",
        "    level_2_candidates = []\n",
        "    level_1_candidates = []\n",
        "\n",
        "    for frame in frame_data:\n",
        "        # 엄격한 피치 제한 적용\n",
        "        if abs(frame['pitch']) > PITCH_T:\n",
        "            continue\n",
        "\n",
        "        eye_level, eye_details = is_eye_open_adaptive(\n",
        "            frame['landmarks'], thresholds, abs(frame['pitch'])\n",
        "        )\n",
        "\n",
        "        if eye_level == 0:\n",
        "            continue\n",
        "\n",
        "        candidate = {\n",
        "            'img': frame['img'],\n",
        "            'filename': frame['filename'],\n",
        "            'pitch': frame['pitch'],\n",
        "            'yaw': frame['yaw'],\n",
        "            'cx': frame['cx'],\n",
        "            'cy': frame['cy'],\n",
        "            'face_area': frame['face_area'],\n",
        "            'w': frame['img'].shape[1],\n",
        "            'h': frame['img'].shape[0],\n",
        "            'eye_level': eye_level,\n",
        "            'eye_details': eye_details,\n",
        "            'quality_score': calculate_final_quality_score(\n",
        "                frame['pitch'], frame['yaw'], eye_level, eye_details\n",
        "            )\n",
        "        }\n",
        "\n",
        "        if eye_level == 4:\n",
        "            level_4_candidates.append(candidate)\n",
        "        elif eye_level == 3:\n",
        "            level_3_candidates.append(candidate)\n",
        "        elif eye_level == 2:\n",
        "            level_2_candidates.append(candidate)\n",
        "        else:\n",
        "            level_1_candidates.append(candidate)\n",
        "\n",
        "    # 4단계: 최적 프레임 선택\n",
        "    best_img = None\n",
        "    best_filename = None\n",
        "    selection_reason = \"No suitable frames\"\n",
        "    selection_level = 0\n",
        "\n",
        "    if level_4_candidates:\n",
        "        best = max(level_4_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 4: Selected from {len(level_4_candidates)} highest quality candidates\"\n",
        "        selection_level = 4\n",
        "\n",
        "    elif level_3_candidates:\n",
        "        best = max(level_3_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 3: Selected from {len(level_3_candidates)} high quality candidates\"\n",
        "        selection_level = 3\n",
        "\n",
        "    elif level_2_candidates:\n",
        "        best = max(level_2_candidates, key=frontal_score_strict_pitch)\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 2: Selected from {len(level_2_candidates)} medium quality candidates\"\n",
        "        selection_level = 2\n",
        "\n",
        "    elif level_1_candidates:\n",
        "        best = max(level_1_candidates, key=lambda x: x['quality_score'])\n",
        "        best_img = best['img']\n",
        "        best_filename = best['filename']\n",
        "        selection_reason = f\"Level 1: Selected from {len(level_1_candidates)} minimum quality candidates\"\n",
        "        selection_level = 1\n",
        "\n",
        "    elif frame_data:\n",
        "        # 최후의 수단: 가장 품질 좋은 프레임 무조건 선택\n",
        "        best_frame = max(frame_data, key=lambda x: x['avg_ear'])\n",
        "        best_img = best_frame['img']\n",
        "        best_filename = best_frame['filename']\n",
        "        selection_reason = f\"Emergency: Selected best EAR frame ({best_frame['avg_ear']:.3f})\"\n",
        "        selection_level = 0\n",
        "\n",
        "    # KeyError 방지를 위한 안전한 로그 기록\n",
        "    detailed_log.append({\n",
        "        'video_name': video_name,\n",
        "        'total_frames': len(frame_data),\n",
        "        'level_4_candidates': len(level_4_candidates),\n",
        "        'level_3_candidates': len(level_3_candidates),\n",
        "        'level_2_candidates': len(level_2_candidates),\n",
        "        'level_1_candidates': len(level_1_candidates),\n",
        "        'selected': best_filename is not None,\n",
        "        'selection_level': selection_level,  # 항상 포함\n",
        "        'best_filename': best_filename,\n",
        "        'reason': selection_reason,\n",
        "        'ear_thresholds': thresholds,\n",
        "        'quality_score': best.get('quality_score', 0) if 'best' in locals() else 0\n",
        "    })\n",
        "\n",
        "    # 프레임 저장\n",
        "    if best_img is not None:\n",
        "        save_path = os.path.join(OUTPUT_ROOT, f\"{video_name}.jpg\")\n",
        "        cv2.imwrite(save_path, best_img)\n",
        "\n",
        "        if selection_level <= 1:\n",
        "            print(f\"⚠️  {video_name}: Low quality selection (Level {selection_level})\")\n",
        "    else:\n",
        "        missing_videos.append(video_name)\n",
        "\n",
        "# 결과 저장\n",
        "if missing_videos:\n",
        "    df_missing = pd.DataFrame(missing_videos, columns=[\"video_name\"])\n",
        "    df_missing.to_csv(\"no_frame_found.csv\", index=False)\n",
        "    print(f\"❗ {len(missing_videos)}개 영상에서 프레임을 찾지 못함\")\n",
        "\n",
        "df_log = pd.DataFrame(detailed_log)\n",
        "df_log.to_csv(\"strict_pitch_50percent_eye_log.csv\", index=False)\n",
        "print(f\"📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\")\n",
        "\n",
        "# KeyError 방지된 안전한 통계 출력\n",
        "success_rate = (len(video_dirs) - len(missing_videos)) / len(video_dirs) * 100 if video_dirs else 0\n",
        "\n",
        "# .get() 메서드 사용으로 KeyError 방지\n",
        "level_4_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 4)\n",
        "level_3_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 3)\n",
        "level_2_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 2)\n",
        "level_1_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 1)\n",
        "emergency_usage = sum(1 for log in detailed_log if log.get('selection_level', 0) == 0)\n",
        "\n",
        "print(f\"✅ 성공률: {success_rate:.1f}% ({len(video_dirs) - len(missing_videos)}/{len(video_dirs)})\")\n",
        "print(f\"🏆 Level 4 (최고품질): {level_4_usage}개\")\n",
        "print(f\"🥈 Level 3 (고품질): {level_3_usage}개\")\n",
        "print(f\"🥉 Level 2 (중품질): {level_2_usage}개\")\n",
        "print(f\"📉 Level 1 (최소품질): {level_1_usage}개\")\n",
        "print(f\"🚨 Emergency (강제선택): {emergency_usage}개\")\n",
        "\n",
        "print(f\"\\n📈 품질 분포:\")\n",
        "print(f\"   - 고품질 이상 (Level 3+): {(level_4_usage + level_3_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 중품질 이상 (Level 2+): {(level_4_usage + level_3_usage + level_2_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "print(f\"   - 최소품질 이상 (Level 1+): {(len(video_dirs) - emergency_usage) / len(video_dirs) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\n🎯 설정 요약:\")\n",
        "print(f\"   - 피치 제한: ±{PITCH_T}° (엄격)\")\n",
        "print(f\"   - 눈뜸 기준: 상위 {EAR_PERCENTILE_HIGH}% (관대)\")\n",
        "print(f\"   - 고개 숙임 보너스: {HEAD_DOWN_BONUS}점 (최소)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlELfbUkEFea",
        "outputId": "9c9c1f4f-5081-4749-ed03-bd3aa59743c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 총 4개 영상 처리 시작\n",
            "🎯 눈뜸 기준: 상위 37% (50% 기준으로 완화)\n",
            "📐 각도 제한: Yaw ±25°, Pitch ±25° (피치 제한 강화)\n",
            "🎁 고개 숙임 보너스: 1점 (최소화)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🎯 Strict pitch + 50% eye threshold: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 처리 결과 저장: strict_pitch_50percent_eye_log.csv\n",
            "✅ 성공률: 100.0% (4/4)\n",
            "🏆 Level 4 (최고품질): 2개\n",
            "🥈 Level 3 (고품질): 1개\n",
            "🥉 Level 2 (중품질): 1개\n",
            "📉 Level 1 (최소품질): 0개\n",
            "🚨 Emergency (강제선택): 0개\n",
            "\n",
            "📈 품질 분포:\n",
            "   - 고품질 이상 (Level 3+): 75.0%\n",
            "   - 중품질 이상 (Level 2+): 100.0%\n",
            "   - 최소품질 이상 (Level 1+): 100.0%\n",
            "\n",
            "🎯 설정 요약:\n",
            "   - 피치 제한: ±25° (엄격)\n",
            "   - 눈뜸 기준: 상위 37% (관대)\n",
            "   - 고개 숙임 보너스: 1점 (최소)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "id": "H_23qUpRqSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f9d460-1df3-4c90-c294-ba908b57186f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image crop"
      ],
      "metadata": {
        "id": "22A2atJxxcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stylegan3-editing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W19HlMQIxcMs",
        "outputId": "5435e1d9-acf2-46ff-98c6-d980496fef11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stylegan3-editing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/stylegan3-editing')"
      ],
      "metadata": {
        "id": "UE0wMtQ79bS1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "base_raw_root = \"/content/alignmented_frame\"\n",
        "aligned_root = f\"{base_raw_root}_aligned\"\n",
        "cropped_root = f\"{base_raw_root}_croped\"\n",
        "transform_root = f\"{base_raw_root}_transforms\"\n",
        "\n",
        "print(\"🚀 Aligning all images...\")\n",
        "# 실행 명령어에 PYTHONPATH를 추가하여 모듈을 찾을 경로를 알려줍니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode align \\\n",
        "    --root_path \"{base_raw_root}\"\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Cropping all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/preparing_faces_parallel.py \\\n",
        "    --mode crop \\\n",
        "    --root_path \"{base_raw_root}\" \\\n",
        "    --random_shift 0.05\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "print(\"🔁 Computing transforms for all images...\")\n",
        "# 여기도 동일하게 추가합니다.\n",
        "!PYTHONPATH=/content/stylegan3-editing python /content/stylegan3-editing/prepare_data/compute_landmarks_transforms.py \\\n",
        "    --raw_root \"{base_raw_root}\" \\\n",
        "    --aligned_root \"{aligned_root}\" \\\n",
        "    --cropped_root \"{cropped_root}\" \\\n",
        "    --output_root \"{transform_root}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kzg1k-FxgA2",
        "outputId": "5c80188e-68d4-45b3-8ae4-d5ce0fd796d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Aligning all images...\n",
            "1\n",
            "Running on 4 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #4 images\n",
            "\tDone!\n",
            "Mischief managed in -2.8514950275421143s\n",
            "🔁 Cropping all images...\n",
            "1\n",
            "Running on 4 paths\n",
            "Here we goooo\n",
            "\tForkPoolWorker-1 is starting to extract on #4 images\n",
            "\tDone!\n",
            "Mischief managed in -2.6253082752227783s\n",
            "🔁 Computing transforms for all images...\n",
            "Computing landmarks transforms...\n",
            "100% 4/4 [00:08<00:00,  2.13s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 디렉토리 설정\n",
        "input_root = \"/content/alignmented_frame_croped\"\n",
        "transforms_root = \"/content/alignmented_frame_transforms/landmarks_transforms.npy\"\n",
        "output_root = \"/content/experiments/restyle_e4e_sg3\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "\n",
        "# output 디렉토리 생성\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "print(\"🚀 Inverting video\")\n",
        "\n",
        "!python {script_path} \\\n",
        "    --output_path \"{output_root}\" \\\n",
        "    --checkpoint_path \"{ckpt_path}\" \\\n",
        "    --data_path \"{input_root}\" \\\n",
        "    --test_batch_size 4 \\\n",
        "    --test_workers 4 \\\n",
        "    --n_iters_per_batch 3 \\\n",
        "    --landmarks_transforms_path \"{transforms_root}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdozUaBz7ja",
        "outputId": "90f95981-82ca-4085-e1fb-381c862e2f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Inverting video\n",
            "Loading ReStyle e4e from checkpoint: /content/pretrained_models/restyle_e4e_sg3.pt\n",
            "Loading StyleGAN3 generator from path: None\n",
            "Done!\n",
            "Model successfully loaded!\n",
            "Loading dataset for ffhq_encode\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save CSV"
      ],
      "metadata": {
        "id": "BAaQSZUwoGsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load latent dictionary\n",
        "latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "latent_dict = np.load(latent_path, allow_pickle=True).item()\n",
        "\n",
        "# 2. 정렬된 파일 리스트 확보\n",
        "filenames = sorted(latent_dict.keys())\n",
        "\n",
        "# 3. 각 latent에서 마지막 step → 평균 → (512,)\n",
        "latents = []\n",
        "for key in filenames:\n",
        "    latent = latent_dict[key][-1]  # 마지막 step (18, 512)\n",
        "    mean_latent = latent.mean(axis=0).astype('float32')  # (512,)\n",
        "    latents.append(mean_latent)\n",
        "\n",
        "latents = np.stack(latents)  # shape: (N, 512)\n",
        "\n",
        "# 4. cosine similarity matrix\n",
        "sim_matrix = cosine_similarity(latents)  # shape: (N, N)\n",
        "\n",
        "# 5. 각 query 파일마다 top-3 유사한 match + score 저장\n",
        "rows = []\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    sims = sim_matrix[i].copy()\n",
        "    sims[i] = -np.inf  # 자기 자신 제외\n",
        "    top3_idx = np.argsort(sims)[::-1][:3]\n",
        "    row = {\n",
        "        \"query\": filenames[i],\n",
        "        \"top1\": filenames[top3_idx[0]],\n",
        "        \"top2\": filenames[top3_idx[1]],\n",
        "        \"top3\": filenames[top3_idx[2]],\n",
        "        \"top1val\": round(float(sims[top3_idx[0]]), 6),\n",
        "        \"top2val\": round(float(sims[top3_idx[1]]), 6),\n",
        "        \"top3val\": round(float(sims[top3_idx[2]]), 6),\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "# 6. Save to CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"video_similarity_top3_compact.csv\", index=False)\n",
        "\n",
        "print(\"✅ Saved to video_similarity_top3_compact.csv\")\n"
      ],
      "metadata": {
        "id": "WjMFJ5i2oE78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938567b2-d9f4-49ab-c357-f4e5c0f88435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved to video_similarity_top3_compact.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import subprocess\n",
        "\n",
        "# === 경로 설정 ===\n",
        "original_latent_path = \"/content/experiments/restyle_e4e_sg3/latents.npy\"\n",
        "generated_image_dir = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "temp_input_dir = \"/content/temp_comparison/generated_input\"\n",
        "temp_output_dir = \"/content/temp_comparison/generated_output\"\n",
        "generated_latent_path = os.path.join(temp_output_dir, \"latents.npy\")\n",
        "script_path = \"/content/stylegan3-editing/inversion/scripts/inference_iterative.py\"\n",
        "ckpt_path = \"/content/pretrained_models/restyle_e4e_sg3.pt\"\n",
        "\n",
        "# === Step 1. 원본 latent 불러오기 ===\n",
        "print(\"📂 Loading original latent vectors...\")\n",
        "orig_latent_raw = np.load(original_latent_path, allow_pickle=True).item()\n",
        "original_latents = {}\n",
        "for k, v in orig_latent_raw.items():\n",
        "    key = os.path.splitext(os.path.basename(k))[0]\n",
        "    final_latent = v[-1]\n",
        "    original_latents[key] = {\n",
        "        \"mean\": final_latent.mean(axis=0).astype(\"float32\"),\n",
        "        \"full\": final_latent\n",
        "    }\n",
        "\n",
        "# === Step 2. Generated 이미지 latent 재추출 ===\n",
        "print(\"📁 Preparing input images for inversion...\")\n",
        "os.makedirs(temp_input_dir, exist_ok=True)\n",
        "os.makedirs(temp_output_dir, exist_ok=True)\n",
        "\n",
        "# 이미지 복사\n",
        "from glob import glob\n",
        "import shutil\n",
        "for path in glob(os.path.join(generated_image_dir, \"*.jpg\")):\n",
        "    fname = os.path.basename(path)\n",
        "    new_name = f\"0_{fname}\"  # prefix 붙이기 (중복 방지)\n",
        "    shutil.copy(path, os.path.join(temp_input_dir, new_name))\n",
        "\n",
        "# 인버전 실행\n",
        "print(\"🚀 Running inversion on generated images...\")\n",
        "subprocess.run([\n",
        "    \"python\", script_path,\n",
        "    \"--output_path\", temp_output_dir,\n",
        "    \"--checkpoint_path\", ckpt_path,\n",
        "    \"--data_path\", temp_input_dir,\n",
        "    \"--test_batch_size\", \"4\",\n",
        "    \"--test_workers\", \"2\",\n",
        "    \"--n_iters_per_batch\", \"3\"\n",
        "], check=True)\n",
        "\n",
        "# === Step 3. Generated latent 불러오기 및 비교 ===\n",
        "print(\"🔍 Comparing latents...\")\n",
        "gen_latent_dict = np.load(generated_latent_path, allow_pickle=True).item()\n",
        "results = []\n",
        "\n",
        "for gen_fname, latent_seq in gen_latent_dict.items():\n",
        "    _, clean = gen_fname.split(\"_\", 1) if \"_\" in gen_fname else (\"\", gen_fname)\n",
        "    base_name = os.path.splitext(clean)[0]\n",
        "\n",
        "    if base_name not in original_latents:\n",
        "        print(f\"⚠️ 원본 latent 없음: {base_name}\")\n",
        "        continue\n",
        "\n",
        "    gen_final = latent_seq[-1]\n",
        "    gen_mean = gen_final.mean(axis=0).astype(\"float32\")\n",
        "    orig = original_latents[base_name]\n",
        "\n",
        "    layer_sims = [cosine_similarity([orig[\"full\"][i]], [gen_final[i]])[0][0]\n",
        "                  for i in range(gen_final.shape[0])]\n",
        "\n",
        "    results.append({\n",
        "        \"filename\": base_name,\n",
        "        \"cosine_similarity\": cosine_similarity([orig[\"mean\"]], [gen_mean])[0][0],\n",
        "        \"euclidean_distance\": np.linalg.norm(orig[\"mean\"] - gen_mean),\n",
        "        \"dot_product\": np.dot(orig[\"mean\"], gen_mean),\n",
        "        \"coarse_similarity\": np.mean(layer_sims[:4]),\n",
        "        \"middle_similarity\": np.mean(layer_sims[4:8]),\n",
        "        \"fine_similarity\": np.mean(layer_sims[8:]),\n",
        "        \"overall_layer_similarity\": np.mean(layer_sims),\n",
        "    })\n",
        "\n",
        "# === Step 4. 저장 ===\n",
        "df = pd.DataFrame(results)\n",
        "csv_path = \"/content/original_vs_generated_latent_comparison.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(f\"✅ 비교 결과 저장 완료: {csv_path}\")\n",
        "\n",
        "# === Step 5. 시각화 ===\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(df[\"cosine_similarity\"], bins=10, edgecolor='black')\n",
        "plt.title(\"Cosine Similarity Distribution\")\n",
        "plt.xlabel(\"Cosine Similarity\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "6Sugcp8d_WFi",
        "outputId": "14f3946e-065b-4e74-89ba-6d25a57672eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Loading original latent vectors...\n",
            "📁 Preparing input images for inversion...\n",
            "🚀 Running inversion on generated images...\n",
            "🔍 Comparing latents...\n",
            "✅ 비교 결과 저장 완료: /content/original_vs_generated_latent_comparison.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHqCAYAAACZcdjsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASUNJREFUeJzt3Xd4VGX+/vF7EpJJAgkBAgklJCGgVGEVRVApS1cU1BUQkF5UEAQVQZcuS1FZihRxleKCuCCI4NJEikoHQRcQ6aA0qQESkpB5fn/4ZX4MCSHDmTAZ8n5dVy45z3nmnM8555kxd04ZmzHGCAAAAAAs8PN2AQAAAAB8H8ECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgBuwWazafDgwd4uI1OxsbFq3769R5d543ZPnz5dNptNhw4d8uh6ateurdq1a3t0mZ7Svn17xcbG3pF13XgMr+3vLVu23JH15+TjAMA3ECwA+JT9+/erW7duKlWqlIKCghQWFqZHHnlE48aNU1JSkrfL87iff/5Zf/vb3xQTE6OgoCAVL15c9evX14QJE7xdWrY5duyYBg8erO3bt3t0uYMHD5bNZnP+hISEqGTJknryySc1bdo0JScne2Q9u3bt0uDBgz0ewDwhJ9cGwPfl8XYBAJBVX3/9tZ577jnZ7Xa1bdtWFStWVEpKir7//nu98cYb2rlzp6ZOnerx9SYlJSlPnjv/cblu3TrVqVNHJUuWVJcuXRQVFaWjR49qw4YNGjdunF555RVn3z179sjPz7N/K7pT2718+XKX6WPHjmnIkCGKjY1VlSpVPL6+yZMnK1++fEpOTtbvv/+uZcuWqWPHjho7dqwWL16s6OhoZ9+PPvpIDofDreXv2rVLQ4YMUe3atd0625Edx/BGmdV243EAAHcRLAD4hIMHD6ply5aKiYnRt99+q6JFizrnde/eXfv27dPXX3+dLesOCgrKluXeyvDhw5U/f35t3rxZ4eHhLvNOnTrlMm232z2+/uze7sTERIWEhCgwMDBb13Ojv/3tb4qIiHBODxw4ULNmzVLbtm313HPPacOGDc55AQEB2VqLMUZXrlxRcHBwthxDd9zp4wDg7sOlUAB8wujRo3Xp0iV9/PHHLqHimtKlS6tXr17O6atXr2rYsGGKj4+X3W5XbGys3nrrrXSXu2zZskUNGzZURESEgoODFRcXp44dO7r0ufFeg2uX1Ozbt0/t27dXeHi48ufPrw4dOigxMTFdbf/+97/1wAMPKDg4WAULFlTLli119OjRW27z/v37VaFChXShQpKKFCniMn2z6/O///579ezZU4ULF1Z4eLi6deumlJQUnT9/Xm3btlWBAgVUoEAB9e3bV8aYTLc7IwsXLtQTTzyhYsWKyW63Kz4+XsOGDVNaWppLv9q1a6tixYraunWratasqZCQEL311lvOedeu7V+9erUefPBBSVKHDh2cly1Nnz5dgwYNUkBAgP744490dXTt2lXh4eG6cuVKpvXeTOvWrdW5c2dt3LhRK1ascLZndI/FnDlz9MADDyg0NFRhYWGqVKmSxo0bJ+nP/f7cc89JkurUqeOsf/Xq1ZL+PE5NmjTRsmXLVLVqVQUHB+vDDz90zsvoPpnExER169ZNhQoVUlhYmNq2batz58659LnZsbp+mbeqLaN7LE6dOqVOnTopMjJSQUFBqly5smbMmOHS59ChQ7LZbHrvvfc0depU53vuwQcf1ObNmzPc3wDuTpyxAOATFi1apFKlSqlGjRpZ6t+5c2fNmDFDf/vb3/Taa69p48aNGjFihHbv3q0FCxZI+vOXpgYNGqhw4cLq16+fwsPDdejQIc2fPz9L62jevLni4uI0YsQIbdu2Tf/6179UpEgRjRo1ytln+PDhGjBggJo3b67OnTvrjz/+0IQJE1SzZk39+OOPGYaGa2JiYrR+/Xr973//U8WKFbNU041eeeUVRUVFaciQIdqwYYOmTp2q8PBwrVu3TiVLltQ//vEP/fe//9W7776rihUrqm3btm4tf/r06cqXL5/69OmjfPny6dtvv9XAgQOVkJCgd99916XvmTNn1LhxY7Vs2VJt2rRRZGRkuuWVK1dOQ4cO1cCBA9W1a1c99thjkqQaNWro0Ucf1dChQ/X555+rR48eztekpKRo3rx5evbZZy2dZXnhhRc0depULV++XPXr18+wz4oVK/T888+rbt26zuO8e/du/fDDD+rVq5dq1qypnj17avz48XrrrbdUrlw553Zds2fPHj3//PPq1q2bunTponvvvTfTunr06KHw8HANHjxYe/bs0eTJk3X48GGtXr1aNpsty9uXldqul5SUpNq1a2vfvn3q0aOH4uLiNHfuXLVv317nz593CfKSNHv2bF28eFHdunWTzWbT6NGj9cwzz+jAgQPZfuYHQA5hACCHu3DhgpFkmjZtmqX+27dvN5JM586dXdpff/11I8l8++23xhhjFixYYCSZzZs3Z7o8SWbQoEHO6UGDBhlJpmPHji79nn76aVOoUCHn9KFDh4y/v78ZPny4S7+ff/7Z5MmTJ137jZYvX278/f2Nv7+/qV69uunbt69ZtmyZSUlJSdc3JibGtGvXzjk9bdo0I8k0bNjQOBwOZ3v16tWNzWYzL774orPt6tWrpkSJEqZWrVqZbve1ZR48eNDZlpiYmK6Wbt26mZCQEHPlyhVnW61atYwkM2XKlHT9a9Wq5bLuzZs3G0lm2rRp6fpWr17dVKtWzaVt/vz5RpJZtWpVuv7Xu3bc/vjjjwznnzt3zkgyTz/9tLOtXbt2JiYmxjndq1cvExYWZq5evXrT9cydO/em9cTExBhJZunSpRnOy+gYPvDAAy7HfPTo0UaSWbhwobPtxmN1s2VmVtuNx2Hs2LFGkvn3v//tbEtJSTHVq1c3+fLlMwkJCcYYYw4ePGgkmUKFCpmzZ886+y5cuNBIMosWLUq3LgB3Jy6FApDjJSQkSJJCQ0Oz1P+///2vJKlPnz4u7a+99pokOe/FuHa2YPHixUpNTXW7rhdffNFl+rHHHtOZM2ec9c6fP18Oh0PNmzfX6dOnnT9RUVEqU6aMVq1aleny69evr/Xr1+upp57Sjh07NHr0aDVs2FDFixfXV199laUaO3Xq5PJX7WrVqskYo06dOjnb/P39VbVqVR04cCCrm+4UHBzs/PfFixd1+vRpPfbYY0pMTNQvv/zi0tdut6tDhw5ur+N6bdu21caNG7V//35n26xZsxQdHa1atWpZWna+fPkk/bkdNxMeHq7Lly+7XC7lrri4ODVs2DDL/bt27eryF/+XXnpJefLkcY7z7PLf//5XUVFRev75551tAQEB6tmzpy5duqQ1a9a49G/RooUKFCjgnL52tul2xhUA30SwAJDjhYWFScr8F77rHT58WH5+fipdurRLe1RUlMLDw3X48GFJUq1atfTss89qyJAhioiIUNOmTd167GjJkiVdpq/9UnXt+ve9e/fKGKMyZcqocOHCLj+7d+9OdwN2Rh588EHNnz9f586d06ZNm9S/f39dvHhRf/vb37Rr1y63a8yfP78kuTz56Fr7jdftZ8XOnTv19NNPK3/+/AoLC1PhwoXVpk0bSdKFCxdc+hYvXtzyDcItWrSQ3W7XrFmznOtYvHixWrdu7dZlQRm5dOmSpMwD7Msvv6x77rlHjRs3VokSJdSxY0ctXbrUrfXExcW51b9MmTIu0/ny5VPRokWz/ZGxhw8fVpkyZdI9qerapVPX3kfX3Or9AODuxz0WAHK8sLAwFStWTP/73//cet2tftG02WyaN2+eNmzYoEWLFjkfO/r+++9rw4YNzr9g34y/v3+G7eb/boJ2OByy2WxasmRJhn1vtfzrBQYG6sEHH9SDDz6oe+65Rx06dNDcuXM1aNCg26oxo3Zzw83bt3L+/HnVqlVLYWFhGjp0qOLj4xUUFKRt27bpzTffTPeY1uvPbtyuAgUKqEmTJpo1a5YGDhyoefPmKTk52RlmrLg2vm4MpNcrUqSItm/frmXLlmnJkiVasmSJpk2bprZt26a7qflmPLEfsurGm+iz063eDwDufpyxAOATmjRpov3792v9+vW37BsTEyOHw6G9e/e6tJ88eVLnz59XTEyMS/vDDz+s4cOHa8uWLZo1a5Z27typOXPmWK45Pj5exhjFxcWpXr166X4efvjh21pu1apVJUnHjx+3XKMVq1ev1pkzZzR9+nT16tVLTZo0Ub169Vwuh7kdtwqEbdu21a+//qrNmzdr1qxZ+stf/qIKFSpYWqckffrpp5J0y8uUAgMD9eSTT2rSpEnOL2ycOXOm9u3bl6X63XXjOL506ZKOHz/u8rSqAgUK6Pz58y79UlJS0o0Rd2qLiYnR3r170wXEa5e43fg+AgCCBQCf0LdvX+XNm1edO3fWyZMn083fv3+/85Gfjz/+uCRp7NixLn3GjBkjSXriiSck/XmJxo1/Tb32hWye+BbmZ555Rv7+/hoyZEi69RhjdObMmUxfv2rVqgz/2nvt2vpbPU0ou137C/X1NaakpGjSpEmWlps3b15JSveL8jWNGzdWRESERo0apTVr1njkbMXs2bP1r3/9S9WrV1fdunVv2u/GY+bn56f77rtP0v8fM7eq311Tp051uQdo8uTJunr1qho3buxsi4+P19q1a9O97sYzFu7U9vjjj+vEiRP6/PPPnW1Xr17VhAkTlC9fPsv3tAC4+3ApFACfEB8fr9mzZ6tFixYqV66cyzdvr1u3zvkYTEmqXLmy2rVrp6lTpzov19m0aZNmzJihZs2aqU6dOpKkGTNmaNKkSXr66acVHx+vixcv6qOPPlJYWJgznFit+Z133lH//v116NAhNWvWTKGhoTp48KAWLFigrl276vXXX7/p61955RUlJibq6aefVtmyZZ3b+vnnnys2NtbyjdBW1ahRQwUKFFC7du3Us2dP2Ww2ffrpp5YvfYmPj1d4eLimTJmi0NBQ5c2bV9WqVXPemxAQEKCWLVvqgw8+kL+/v8vNxVkxb9485cuXTykpKc5v3v7hhx9UuXJlzZ07N9PXdu7cWWfPntVf//pXlShRQocPH9aECRNUpUoV570HVapUkb+/v0aNGqULFy7Ibrfrr3/9a7rvHsmqlJQU1a1bV82bN9eePXs0adIkPfroo3rqqadc6nrxxRf17LPPqn79+tqxY4eWLVvm8kWA7tbWtWtXffjhh2rfvr22bt2q2NhYzZs3Tz/88IPGjh2b5YcpAMg9CBYAfMZTTz2ln376Se+++64WLlyoyZMny26367777tP777+vLl26OPv+61//UqlSpTR9+nQtWLBAUVFR6t+/v8s9CdcCx5w5c3Ty5Enlz59fDz30kGbNmuX2DbY3069fP91zzz365z//qSFDhkj688bpBg0auPximJH33ntPc+fO1X//+19NnTpVKSkpKlmypF5++WX9/e9/z/Q7MO6EQoUKafHixXrttdf097//XQUKFFCbNm1Ut25dt556dKOAgADNmDFD/fv314svvqirV69q2rRpLsekbdu2+uCDD1S3bt0MvzAxMy+99JKkP79ZPCIiQlWqVNEnn3yiVq1a3fLbr9u0aaOpU6dq0qRJOn/+vKKiotSiRQsNHjzYeZNzVFSUpkyZohEjRqhTp05KS0vTqlWrbjtYfPDBB857SlJTU/X8889r/PjxLpc1denSRQcPHtTHH3+spUuX6rHHHtOKFSvSnX1xp7bg4GCtXr1a/fr104wZM5SQkKB7771X06ZNy/CL/ADAZrirCgDgY3bs2KEqVapo5syZeuGFF7xdDgBA3GMBAPBBH330kfLly6dnnnnG26UAAP4Pl0IBAHzGokWLtGvXLk2dOlU9evRw3owMAPA+LoUCAPiM2NhYnTx5Ug0bNtSnn37KDcQAkIMQLAAAAABYxj0WAAAAACwjWAAAAACw7K6/edvhcOjYsWMKDQ11eeY3AAAAgMwZY3Tx4kUVK1bM+X09N3PXB4tjx44pOjra22UAAAAAPuvo0aMqUaJEpn3u+mBx7YkhR48eVVhYmJeryb1SU1O1fPlyNWjQQAEBAd4uB17AGABjAIyB3I3j75sSEhIUHR2dpafw3fXB4trlT2FhYQQLL0pNTVVISIjCwsL4MMmlGANgDIAxkLtx/H1bVm4p4OZtAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZV4NFmvXrtWTTz6pYsWKyWaz6csvv3SZb4zRwIEDVbRoUQUHB6tevXrau3evd4oFAAAAcFNeDRaXL19W5cqVNXHixAznjx49WuPHj9eUKVO0ceNG5c2bVw0bNtSVK1fucKUAAAAAMpPHmytv3LixGjdunOE8Y4zGjh2rv//972ratKkkaebMmYqMjNSXX36pli1b3slSAQAAAGQix95jcfDgQZ04cUL16tVztuXPn1/VqlXT+vXrvVgZAAAAgBt59YxFZk6cOCFJioyMdGmPjIx0zstIcnKykpOTndMJCQmSpNTUVKWmpmZDpciKa/ueY5B7MQbAGABjIOt+++03nTlzxttleJTD4ZAk/fjjj/Lzu/XftgsVKqQSJUpkd1m4BXferzk2WNyuESNGaMiQIenaly9frpCQEC9UhOutWLHC2yXAyxgDYAyAMZC7HT9+PEv9fv/9d/3000/ZXA1uJTExMct9c2ywiIqKkiSdPHlSRYsWdbafPHlSVapUuenr+vfvrz59+jinExISFB0drQYNGigsLCzb6kXmUlNTtWLFCtWvX18BAQHeLgdewBgAYwCMgazZsWOHatasqYKNXlFAweLeLsdj7HlsGtW4pN5cckTJV02mfVPP/q6zSydo7dq1qly58h2qEBm5dvVPVuTYYBEXF6eoqCitXLnSGSQSEhK0ceNGvfTSSzd9nd1ul91uT9ceEBDAh1gOwHEAYwCMATAGMufn56ekpCSlhRVTnoh4b5fjMcbfSEqTKRQnk2bLtG/aVaOkpCT5+fkxVrzMnf3v1WBx6dIl7du3zzl98OBBbd++XQULFlTJkiX16quv6p133lGZMmUUFxenAQMGqFixYmrWrJn3igYAAACQjleDxZYtW1SnTh3n9LVLmNq1a6fp06erb9++unz5srp27arz58/r0Ucf1dKlSxUUFOStkgEAAABkwKvBonbt2jLm5tfY2Ww2DR06VEOHDr2DVQEAAABwV479HgsAAAAAvoNgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwLIcHSzS0tI0YMAAxcXFKTg4WPHx8Ro2bJiMMd4uDQAAAMB18ni7gMyMGjVKkydP1owZM1ShQgVt2bJFHTp0UP78+dWzZ09vlwcAAADg/+ToYLFu3To1bdpUTzzxhCQpNjZWn332mTZt2uTlygAAAABcL0dfClWjRg2tXLlSv/76qyRpx44d+v7779W4cWMvVwYAAADgejn6jEW/fv2UkJCgsmXLyt/fX2lpaRo+fLhat25909ckJycrOTnZOZ2QkCBJSk1NVWpqarbXjIxd2/ccg9yLMQDGABgDWeNwOBQcHKygPDYF+t8995Xa/YzLfzNjy2NTcHCwdu/eLYfDkd2l5WiFChVSiRIlvLZ+d96vNpOD74SeM2eO3njjDb377ruqUKGCtm/frldffVVjxoxRu3btMnzN4MGDNWTIkHTts2fPVkhISHaXDAAAANw1EhMT1apVK124cEFhYWGZ9s3RwSI6Olr9+vVT9+7dnW3vvPOO/v3vf+uXX37J8DUZnbGIjo7W6dOnb7kzkH1SU1O1YsUK1a9fXwEBAd4uB17AGABjAIyBrNmxY4dq1qypyFYjFRhZytvleIzdz2hYVYcGbPFTssOWad/Lu7/T2aUTVLDRKwooWPwOVZjzpJ79XWeXTtDatWtVuXJlr9SQkJCgiIiILAWLHH0pVGJiovz8XG8D8ff3z/SUmN1ul91uT9ceEBDAh1gOwHEAYwCMATAGMufn56ekpCRduWpk0jL/BdwXJTtsSr7Fdl1JTVNSUpLSwoopT0T8Haos50m7apSUlCQ/Pz+vvWfcWW+ODhZPPvmkhg8frpIlS6pChQr68ccfNWbMGHXs2NHbpQEAAAC4To4OFhMmTNCAAQP08ssv69SpUypWrJi6deumgQMHers0AAAAANfJ0cEiNDRUY8eO1dixY71dCgAAAIBM5OjvsQAAAADgGwgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMreDxdGjR/Xbb785pzdt2qRXX31VU6dO9WhhAAAAAHyH28GiVatWWrVqlSTpxIkTql+/vjZt2qS3335bQ4cO9XiBAAAAAHI+t4PF//73Pz300EOSpP/85z+qWLGi1q1bp1mzZmn69Omerg8AAACAD3A7WKSmpsput0uSvvnmGz311FOSpLJly+r48eOerQ4AAACAT3A7WFSoUEFTpkzRd999pxUrVqhRo0aSpGPHjqlQoUIeLxAAAABAzud2sBg1apQ+/PBD1a5dW88//7wqV64sSfrqq6+cl0gBAAAAyF3yuPuC2rVr6/Tp00pISFCBAgWc7V27dlVISIhHiwMAAADgG27reyyMMdq6das+/PBDXbx4UZIUGBhIsAAAAAByKbfPWBw+fFiNGjXSkSNHlJycrPr16ys0NFSjRo1ScnKypkyZkh11AgAAAMjB3D5j0atXL1WtWlXnzp1TcHCws/3pp5/WypUrPVocAAAAAN/g9hmL7777TuvWrVNgYKBLe2xsrH7//XePFQYAAADAd7h9xsLhcCgtLS1d+2+//abQ0FCPFAUAAADAt7gdLBo0aKCxY8c6p202my5duqRBgwbp8ccf92RtAAAAAHyE25dCvf/++2rYsKHKly+vK1euqFWrVtq7d68iIiL02WefZUeNAAAAAHI4t4NFiRIltGPHDs2ZM0c//fSTLl26pE6dOql169YuN3MDAAAAyD3cDhaSlCdPHrVp08bTtQAAAADwUVkKFl999VWWF/jUU0/ddjEAAAAAfFOWgkWzZs2ytDCbzZbhE6MAAAAA3N2yFCwcDkd21wEAAADAh7n9uFkAAAAAuNFtBYuVK1eqSZMmio+PV3x8vJo0aaJvvvnG07UBAAAA8BFuB4tJkyapUaNGCg0NVa9evdSrVy+FhYXp8ccf18SJE7OjRgAAAAA5nNuPm/3HP/6hf/7zn+rRo4ezrWfPnnrkkUf0j3/8Q927d/dogQAAAAByPrfPWJw/f16NGjVK196gQQNduHDBI0UBAAAA8C1uB4unnnpKCxYsSNe+cOFCNWnSxCNFAQAAAPAtbl8KVb58eQ0fPlyrV69W9erVJUkbNmzQDz/8oNdee03jx4939u3Zs6fnKgUAAACQY7kdLD7++GMVKFBAu3bt0q5du5zt4eHh+vjjj53TNpuNYAEAAADkEm4Hi4MHD2ZHHQAAAAB8GF+QBwAAAMAyt89YGGM0b948rVq1SqdOnZLD4XCZP3/+fI8VBwAAAMA3uB0sXn31VX344YeqU6eOIiMjZbPZsqMuAAAAAD7E7WDx6aefav78+Xr88cezox4AAAAAPsjteyzy58+vUqVKZUctAAAAAHyU28Fi8ODBGjJkiJKSkrKjHgAAAAA+yO1g0bx5c507d05FihRRpUqVdP/997v8eNrvv/+uNm3aqFChQgoODlalSpW0ZcsWj68HAAAAwO1z+x6Ldu3aaevWrWrTpk2237x97tw5PfLII6pTp46WLFmiwoULa+/evSpQoEC2rRMAAACA+9wOFl9//bWWLVumRx99NDvqcTFq1ChFR0dr2rRpzra4uLhsXy8AAAAA97h9KVR0dLTCwsKyo5Z0vvrqK1WtWlXPPfecihQpor/85S/66KOP7si6AQAAAGSd22cs3n//ffXt21dTpkxRbGxsNpT0/x04cECTJ09Wnz599NZbb2nz5s3q2bOnAgMD1a5duwxfk5ycrOTkZOd0QkKCJCk1NVWpqanZWi9u7tq+5xjkXowBMAbAGMgah8Oh4OBgBeWxKdDfeLscj7H7GZf/ZuZqgP9duQ/cZctjU3BwsBwOh9feN+6s12aMcetoFShQQImJibp69apCQkIUEBDgMv/s2bPuLC5TgYGBqlq1qtatW+ds69mzpzZv3qz169dn+JprT6260ezZsxUSEuKx2gAAAIC7XWJiolq1aqULFy7c8qolt89YjB079nbrclvRokVVvnx5l7Zy5crpiy++uOlr+vfvrz59+jinExISFB0drQYNGtyxS7iQXmpqqlasWKH69eunC6PIHRgDYAyAMZA1O3bsUM2aNRXZaqQCI++e7w6z+xkNq+rQgC1+SnZk/vCfy7u/09mlE+66feCulJMHdHJ2P61du1aVK1f2Sg3Xrv7Jitt6KtSd8sgjj2jPnj0ubb/++qtiYmJu+hq73S673Z6uPSAggA+xHIDjAMYAGANgDGTOz89PSUlJunLVyKRl39M3vSXZYVPyLbbrSmraXb0Psir5qlFSUpL8/Py89p5xZ71uB4vrXblyRSkpKS5tnjwr0Lt3b9WoUUP/+Mc/1Lx5c23atElTp07V1KlTPbYOAAAAANa5/VSoy5cvq0ePHipSpIjy5s2rAgUKuPx40oMPPqgFCxbos88+U8WKFTVs2DCNHTtWrVu39uh6AAAAAFjj9hmLvn37atWqVZo8ebJeeOEFTZw4Ub///rs+/PBDjRw50uMFNmnSRE2aNPH4cgEAAAB4jtvBYtGiRZo5c6Zq166tDh066LHHHlPp0qUVExOjWbNmcTYBAAAAyIXcvhTq7NmzKlXqz7vzw8LCnI+XffTRR7V27VrPVgcAAADAJ7gdLEqVKqWDBw9KksqWLav//Oc/kv48kxEeHu7R4gAAAAD4BreDRYcOHbRjxw5JUr9+/TRx4kQFBQWpd+/eeuONNzxeIAAAAICcz+17LHr37u38d7169bR7925t27ZNpUuX1n333efR4gAAAAD4BkvfYyFJsbGxio2N9UApAAAAAHxVli+FWr9+vRYvXuzSNnPmTMXFxalIkSLq2rWrkpOTPV4gAAAAgJwvy8Fi6NCh2rlzp3P6559/VqdOnVSvXj3169dPixYt0ogRI7KlSAAAAAA5W5aDxfbt21W3bl3n9Jw5c1StWjV99NFH6tOnj8aPH+98QhQAAACA3CXLweLcuXOKjIx0Tq9Zs0aNGzd2Tj/44IM6evSoZ6sDAAAA4BOyHCwiIyOd31+RkpKibdu26eGHH3bOv3jxogICAjxfIQAAAIAcL8vB4vHHH1e/fv303XffqX///goJCdFjjz3mnP/TTz8pPj4+W4oEAAAAkLNl+XGzw4YN0zPPPKNatWopX758mjFjhgIDA53zP/nkEzVo0CBbigQAAACQs2U5WERERGjt2rW6cOGC8uXLJ39/f5f5c+fOVb58+TxeIAAAAICcz+0vyMufP3+G7QULFrRcDAAAAADflOV7LAAAAADgZggWAAAAACwjWAAAAACwLEvB4v7779e5c+ckSUOHDlViYmK2FgUAAADAt2QpWOzevVuXL1+WJA0ZMkSXLl3K1qIAAAAA+JYsPRWqSpUq6tChgx599FEZY/Tee+/d9NGyAwcO9GiBAAAAAHK+LAWL6dOna9CgQVq8eLFsNpuWLFmiPHnSv9RmsxEsAAAAgFwoS8Hi3nvv1Zw5cyRJfn5+WrlypYoUKZKthQEAAADwHW5/QZ7D4ciOOgAAAAD4MLeDhSTt379fY8eO1e7duyVJ5cuXV69evRQfH+/R4gAAAAD4Bre/x2LZsmUqX768Nm3apPvuu0/33XefNm7cqAoVKmjFihXZUSMAAACAHM7tMxb9+vVT7969NXLkyHTtb775purXr++x4gAAAAD4BrfPWOzevVudOnVK196xY0ft2rXLI0UBAAAA8C1uB4vChQtr+/bt6dq3b9/Ok6IAAACAXMrtS6G6dOmirl276sCBA6pRo4Yk6YcfftCoUaPUp08fjxcIAAAAIOdzO1gMGDBAoaGhev/999W/f39JUrFixTR48GD17NnT4wUCAAAAyPncDhY2m029e/dW7969dfHiRUlSaGioxwsDAAAA4Dtu63ssriFQAAAAAJBu4+ZtAAAAALgRwQIAAACAZQQLAAAAAJa5FSxSU1NVt25d7d27N7vqAQAAAOCD3AoWAQEB+umnn7KrFgAAAAA+yu1Lodq0aaOPP/44O2oBAAAA4KPcftzs1atX9cknn+ibb77RAw88oLx587rMHzNmjMeKAwAAAOAb3A4W//vf/3T//fdLkn799VeXeTabzTNVAQAAAPApbgeLVatWZUcdAAAAAHzYbT9udt++fVq2bJmSkpIkScYYjxUFAAAAwLe4HSzOnDmjunXr6p577tHjjz+u48ePS5I6deqk1157zeMFAgAAAMj53A4WvXv3VkBAgI4cOaKQkBBne4sWLbR06VKPFgcAAADAN7h9j8Xy5cu1bNkylShRwqW9TJkyOnz4sMcKAwAAAOA73D5jcfnyZZczFdecPXtWdrvdI0UBAAAA8C1uB4vHHntMM2fOdE7bbDY5HA6NHj1aderU8WhxAAAAAHyD25dCjR49WnXr1tWWLVuUkpKivn37aufOnTp79qx++OGH7KgRAAAAQA7n9hmLihUr6tdff9Wjjz6qpk2b6vLly3rmmWf0448/Kj4+PjtqBAAAAJDDuX3GQpLy58+vt99+29O1AAAAAPBRtxUszp07p48//li7d++WJJUvX14dOnRQwYIFPVocAAAAAN/g9qVQa9euVWxsrMaPH69z587p3LlzGj9+vOLi4rR27drsqBEAAABADuf2GYvu3burRYsWmjx5svz9/SVJaWlpevnll9W9e3f9/PPPHi8SAAAAQM7m9hmLffv26bXXXnOGCkny9/dXnz59tG/fPo8WBwAAAMA3uB0s7r//fue9FdfbvXu3Kleu7JGiAAAAAPiWLF0K9dNPPzn/3bNnT/Xq1Uv79u3Tww8/LEnasGGDJk6cqJEjR2ZPlQAAAABytCwFiypVqshms8kY42zr27dvun6tWrVSixYtPFcdAAAAAJ+QpWBx8ODB7K4DAAAAgA/LUrCIiYnJ7joAAAAA+LDb+oK8Y8eO6fvvv9epU6fkcDhc5vXs2dMjhQEAAADwHW4Hi+nTp6tbt24KDAxUoUKFZLPZnPNsNhvBAgAAAMiF3A4WAwYM0MCBA9W/f3/5+bn9tFoAAAAAdyG3k0FiYqJatmxJqAAAAADg5HY66NSpk+bOnZsdtQAAAADwUW5fCjVixAg1adJES5cuVaVKlRQQEOAyf8yYMR4rDgAAAIBvcPuMxYgRI7Rs2TKdPHlSP//8s3788Ufnz/bt27OhxP9v5MiRstlsevXVV7N1PQAAAADc4/YZi/fff1+ffPKJ2rdvnw3l3NzmzZv14Ycf6r777ruj6wUAAABwa26fsbDb7XrkkUeyo5abunTpklq3bq2PPvpIBQoUuKPrBgAAAHBrbgeLXr16acKECdlRy011795dTzzxhOrVq3dH1wsAAAAga9y+FGrTpk369ttvtXjxYlWoUCHdzdvz58/3WHGSNGfOHG3btk2bN2/OUv/k5GQlJyc7pxMSEiRJqampSk1N9WhtyLpr+55jkHsxBsAYAGMgaxwOh4KDgxWUx6ZAf+PtcjzG7mdc/puZqwH+d+U+cJctj03BwcFyOBxee9+4s16bMcato9WhQ4dM50+bNs2dxWXq6NGjqlq1qlasWOG8t6J27dqqUqWKxo4dm+FrBg8erCFDhqRrnz17tkJCQjxWGwAAAHC3S0xMVKtWrXThwgWFhYVl2tftYHEnffnll3r66afl7+/vbEtLS5PNZpOfn5+Sk5Nd5kkZn7GIjo7W6dOnb7kzkH1SU1O1YsUK1a9fP91ZLuQOjAEwBsAYyJodO3aoZs2aimw1UoGRpbxdjsfY/YyGVXVowBY/JTtsmfa9vPs7nV064a7bB+5KOXlAJ2f309q1a1W5cmWv1JCQkKCIiIgsBQu3L4W6k+rWrauff/7Zpa1Dhw4qW7as3nzzzXShQvrz5nK73Z6uPSAggA+xHIDjAMYAGANgDGTOz89PSUlJunLVyKRl/gu4L0p22JR8i+26kpp2V++DrEq+apSUlCQ/Pz+vvWfcWa/bwSIuLk42280P8IEDB9xd5E2FhoaqYsWKLm158+ZVoUKF0rUDAAAA8B63g8WNX06XmpqqH3/8UUuXLtUbb7zhqboAAAAA+BC3g0WvXr0ybJ84caK2bNliuaBbWb16dbavAwAAAIB73P4ei5tp3LixvvjiC08tDgAAAIAP8ViwmDdvngoWLOipxQEAAADwIW5fCvWXv/zF5eZtY4xOnDihP/74Q5MmTfJocQAAAAB8g9vBolmzZi7Tfn5+Kly4sGrXrq2yZct6qi4AAAAAPsTtYDFo0KDsqAMAAACAD/PYPRYAAAAAcq8sn7Hw8/PL9IvxJMlms+nq1auWiwIAAADgW7IcLBYsWHDTeevXr9f48ePlcDg8UhQAAAAA35LlYNG0adN0bXv27FG/fv20aNEitW7dWkOHDvVocQAAAAB8w23dY3Hs2DF16dJFlSpV0tWrV7V9+3bNmDFDMTExnq4PAAAAgA9wK1hcuHBBb775pkqXLq2dO3dq5cqVWrRokSpWrJhd9QEAAADwAVm+FGr06NEaNWqUoqKi9Nlnn2V4aRQAAACA3CnLwaJfv34KDg5W6dKlNWPGDM2YMSPDfvPnz/dYcQAAAAB8Q5aDRdu2bW/5uFkAAAAAuVOWg8X06dOzsQwAAAAAvoxv3gYAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACW5ehgMWLECD344IMKDQ1VkSJF1KxZM+3Zs8fbZQEAAAC4QY4OFmvWrFH37t21YcMGrVixQqmpqWrQoIEuX77s7dIAAAAAXCePtwvIzNKlS12mp0+friJFimjr1q2qWbOml6oCAAAAcKMcfcbiRhcuXJAkFSxY0MuVAAAAALhejj5jcT2Hw6FXX31VjzzyiCpWrHjTfsnJyUpOTnZOJyQkSJJSU1OVmpqa7XUiY9f2Pccg92IMgDGQud9++01nzpzxdhnZyuFwSJJ+/PFH+fll/LfNQoUKqUSJEneyrBzH4XAoODhYQXlsCvQ33i7HY+x+xuW/mbka4H9X7gN32fLYFBwcLIfD4bXPTnfWazPG+MTReumll7RkyRJ9//33mX7gDB48WEOGDEnXPnv2bIWEhGRniQAAAMBdJTExUa1atdKFCxcUFhaWaV+fCBY9evTQwoULtXbtWsXFxWXaN6MzFtHR0Tp9+vQtdwayT2pqqlasWKH69esrICDA2+XACxgDYAzc3I4dO1SzZk0VbPSKAgoW93Y52caex6ZRjUvqzSVHlHw1/a8fqWd/19mlE7R27VpVrlzZCxXmDNfGQ2SrkQqMLOXtcjzG7mc0rKpDA7b4Kdlhy7Tv5d3f6ezSCXfdPnBXyskDOjm7n1ffEwkJCYqIiMhSsMjRl0IZY/TKK69owYIFWr169S1DhSTZ7XbZ7fZ07QEBAfyPLAfgOIAxAMZAen5+fkpKSlJaWDHliYj3djnZxvgbSWkyheJk0tL/Ypl21SgpKUl+fn65eoxcGw9XrpoM95OvS3bYlHyL7bqSmnZX74OsSs4B7wl31pujg0X37t01e/ZsLVy4UKGhoTpx4oQkKX/+/AoODvZydQAAAACuydFPhZo8ebIuXLig2rVrq2jRos6fzz//3NulAQAAALhOjj5j4QO3fwAAAABQDj9jAQAAAMA3ECwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYFkebxeQWxw5ckSnT5/2dhle43A4JEmbNm1ScHCwl6vxruTkZNntdm+XccddGwM7duyQn59frt0PN4qIiFDJkiW9XYZX5fbPR0navXu3t0vIUXL7/sjt2w/fRbC4A44cOaJ7y5bTlaREb5fiNcHBwfrss89Uv0FDJSVe9nY53mXzk4zD21XccdfGQM2aNZWUlJRr98ONgoJDtOeX3bk2XPD5iOulXTon2Wxq06aNt0sBcBsIFnfA6dOndSUpUYWavKaAQtHeLscrgvLY/vyHceTq/ZB0YIsufPfvXLkPro2ByFYjde7Xzbl2P1wv9cxRnVn8vk6fPp1rgwWfj3+69tmQ2zmSL0nGMB4YD/BRBIs7KKBQtOxRpb1dhlcE+htJaZJy935IPXNUUu7cB9fGQGBkKeU5eURS7twPyFhuHwvXPhvwJ8YD4wG+iZu3AQAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZT4RLCZOnKjY2FgFBQWpWrVq2rRpk7dLAgAAAHCdHB8sPv/8c/Xp00eDBg3Stm3bVLlyZTVs2FCnTp3ydmkAAAAA/k+ODxZjxoxRly5d1KFDB5UvX15TpkxRSEiIPvnkE2+XBgAAAOD/5OhgkZKSoq1bt6pevXrONj8/P9WrV0/r16/3YmUAAAAArpfH2wVk5vTp00pLS1NkZKRLe2RkpH755ZcMX5OcnKzk5GTn9IULFyRJZ8+eVWpqavYVm4mEhAQFBQXJduagjCP51i+4CznySImJ0bl+P/hdPJ5r98G1MeA4fjRX74fr2c4dU1BQkLZu3aqEhARvl5PtHA6HEhMT9d1338nP78+/a+3du5exoNzz2XD954C5mn5+btkPt3K37odbHf/r3a37wF3X/j+RkJCgM2fOeKWGixcvSpKMMbfsazNZ6eUlx44dU/HixbVu3TpVr17d2d63b1+tWbNGGzduTPeawYMHa8iQIXeyTAAAAOCudvToUZUoUSLTPjn6jEVERIT8/f118uRJl/aTJ08qKioqw9f0799fffr0cU47HA6dPXtWhQoVks1my9Z6cXMJCQmKjo7W0aNHFRYW5u1y4AWMATAGwBjI3Tj+vskYo4sXL6pYsWK37Jujg0VgYKAeeOABrVy5Us2aNZP0Z1BYuXKlevTokeFr7Ha77Ha7S1t4eHg2V4qsCgsL48Mkl2MMgDEAxkDuxvH3Pfnz589SvxwdLCSpT58+ateunapWraqHHnpIY8eO1eXLl9WhQwdvlwYAAADg/+T4YNGiRQv98ccfGjhwoE6cOKEqVapo6dKl6W7oBgAAAOA9OT5YSFKPHj1ueukTfIPdbtegQYPSXaaG3IMxAMYAGAO5G8f/7pejnwoFAAAAwDfk6C/IAwAAAOAbCBYAAAAALCNYAAAAALCMYIEsmzhxomJjYxUUFKRq1app06ZNN+2bmpqqoUOHKj4+XkFBQapcubKWLl3q0ic2NlY2my3dT/fu3Z19rly5ou7du6tQoULKly+fnn322XRfmIg7wxvHv3bt2unmv/jii9m2jcicp8dAWlqaBgwYoLi4OAUHBys+Pl7Dhg3T9bf+GWM0cOBAFS1aVMHBwapXr5727t2bbduIzHljDLRv3z7d50CjRo2ybRtxc54+/hcvXtSrr76qmJgYBQcHq0aNGtq8ebNLHz4DfIwBsmDOnDkmMDDQfPLJJ2bnzp2mS5cuJjw83Jw8eTLD/n379jXFihUzX3/9tdm/f7+ZNGmSCQoKMtu2bXP2OXXqlDl+/LjzZ8WKFUaSWbVqlbPPiy++aKKjo83KlSvNli1bzMMPP2xq1KiR3ZuLG3jr+NeqVct06dLFpd+FCxeye3ORgewYA8OHDzeFChUyixcvNgcPHjRz5841+fLlM+PGjXP2GTlypMmfP7/58ssvzY4dO8xTTz1l4uLiTFJSUrZvM1x5awy0a9fONGrUyOVz4OzZs9m+vXCVHce/efPmpnz58mbNmjVm7969ZtCgQSYsLMz89ttvzj58BvgWggWy5KGHHjLdu3d3TqelpZlixYqZESNGZNi/aNGi5oMPPnBpe+aZZ0zr1q1vuo5evXqZ+Ph443A4jDHGnD9/3gQEBJi5c+c6++zevdtIMuvXr7eyOXCTN46/MX8Gi169elkrHh6RHWPgiSeeMB07drxpH4fDYaKiosy7777rnH/+/Hljt9vNZ599Znmb4B5vjAFj/gwWTZs29cAWwApPH//ExETj7+9vFi9e7NLn/vvvN2+//bYxhs8AX8SlULillJQUbd26VfXq1XO2+fn5qV69elq/fn2Gr0lOTlZQUJBLW3BwsL7//vubruPf//63OnbsKJvNJknaunWrUlNTXdZbtmxZlSxZ8qbrhed56/hfM2vWLEVERKhixYrq37+/EhMTLW4R3JVdY6BGjRpauXKlfv31V0nSjh079P3336tx48aSpIMHD+rEiRMu682fP7+qVavGZ8Ad5q0xcM3q1atVpEgR3XvvvXrppZd05swZT20asiA7jv/Vq1eVlpaWaR8+A3yPT3xBHrzr9OnTSktLS/dt55GRkfrll18yfE3Dhg01ZswY1axZU/Hx8Vq5cqXmz5+vtLS0DPt/+eWXOn/+vNq3b+9sO3HihAIDAxUeHp5uvSdOnLC0Tcg6bx1/SWrVqpViYmJUrFgx/fTTT3rzzTe1Z88ezZ8/3yPbhqzJrjHQr18/JSQkqGzZsvL391daWpqGDx+u1q1bS5LzfZ7RevkMuLO8NQYkqVGjRnrmmWcUFxen/fv366233lLjxo21fv16+fv7Z88Gw0V2HP/Q0FBVr15dw4YNU7ly5RQZGanPPvtM69evV+nSpSXxGeCLOGOBbDFu3DiVKVNGZcuWVWBgoHr06KEOHTrIzy/jIffxxx+rcePGKlas2B2uFNnBU8e/a9euatiwoSpVqqTWrVtr5syZWrBggfbv338nNgMWZGUM/Oc//9GsWbM0e/Zsbdu2TTNmzNB7772nGTNmeLFyeIqnxkDLli311FNPqVKlSmrWrJkWL16szZs3a/Xq1V7YKmRVVo7/p59+KmOMihcvLrvdrvHjx+v555+/6f8rkPNx5HBLERER8vf3T/c0ppMnTyoqKirD1xQuXFhffvmlLl++rMOHD+uXX35Rvnz5VKpUqXR9Dx8+rG+++UadO3d2aY+KilJKSorOnz+f5fXC87x1/DNSrVo1SdK+fftuY0twu7JrDLzxxhvq16+fWrZsqUqVKumFF15Q7969NWLECElyLtud9SJ7eGsMZKRUqVKKiIjgc+AOyq7jHx8frzVr1ujSpUs6evSoNm3apNTUVGcfPgN8D8ECtxQYGKgHHnhAK1eudLY5HA6tXLlS1atXz/S1QUFBKl68uK5evaovvvhCTZs2Tddn2rRpKlKkiJ544gmX9gceeEABAQEu692zZ4+OHDlyy/XCc7x1/DOyfft2SVLRokXd2whYkl1jIDExMd1fJv39/eVwOCRJcXFxioqKcllvQkKCNm7cyGfAHeatMZCR3377TWfOnOFz4A7K7v8P5M2bV0WLFtW5c+e0bNkyZx8+A3yQt+8eh2+YM2eOsdvtZvr06WbXrl2ma9euJjw83Jw4ccIYY8wLL7xg+vXr5+y/YcMG88UXX5j9+/ebtWvXmr/+9a8mLi7OnDt3zmW5aWlppmTJkubNN9/McL0vvviiKVmypPn222/Nli1bTPXq1U316tWzbTuRMW8c/3379pmhQ4eaLVu2mIMHD5qFCxeaUqVKmZo1a2brtiJj2TEG2rVrZ4oXL+581Oj8+fNNRESE6du3r7PPyJEjTXh4uFm4cKH56aefTNOmTXnUpJd4YwxcvHjRvP7662b9+vXm4MGD5ptvvjH333+/KVOmjLly5cod3f7cLjuO/9KlS82SJUvMgQMHzPLly03lypVNtWrVTEpKirMPnwG+hWCBLJswYYIpWbKkCQwMNA899JDZsGGDc16tWrVMu3btnNOrV6825cqVM3a73RQqVMi88MIL5vfff0+3zGXLlhlJZs+ePRmuMykpybz88sumQIECJiQkxDz99NPm+PHjHt823NqdPv5HjhwxNWvWNAULFjR2u92ULl3avPHGG3yPhRd5egwkJCSYXr16mZIlS5qgoCBTqlQp8/bbb5vk5GRnH4fDYQYMGGAiIyON3W43devWvennBbLfnR4DiYmJpkGDBqZw4cImICDAxMTEmC5dujh/mcWd5enj//nnn5tSpUqZwMBAExUVZbp3727Onz/v0ofPAN9iM+a6r7cEAAAAgNvAPRYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAJDLTZ8+XeHh4d4uQ4cOHZLNZtP27dstLad27dp69dVXndOxsbEaO3aspWVKUvv27dWsWTPLywGAuxXBAgByuBMnTuiVV15RqVKlZLfbFR0drSeffFIrV670yPJbtGihX3/91SPLyszBgwfVqlUrFStWTEFBQSpRooSaNm2qX375RZIUHR2t48ePq2LFipbWM3/+fA0bNswTJbsYN26cpk+f7py+McAAQG6Xx9sFAABu7tChQ3rkkUcUHh6ud999V5UqVVJqaqqWLVum7t27O38ptyI4OFjBwcEeqPbmUlNTVb9+fd17772aP3++ihYtqt9++01LlizR+fPnJUn+/v6KioqyvK6CBQtaXsb10tLSZLPZlD9/fo8uFwDuNpyxAIAc7OWXX5bNZtOmTZv07LPP6p577lGFChXUp08fbdiwwdnvyJEjatq0qfLly6ewsDA1b95cJ0+edM7fsWOH6tSpo9DQUIWFhemBBx7Qli1bJKW/FGrw4MGqUqWKPv30U8XGxip//vxq2bKlLl686OzjcDg0YsQIxcXFKTg4WJUrV9a8efNuuh07d+7U/v37NWnSJD388MOKiYnRI488onfeeUcPP/ywpPSXQq1evVo2m03Lli3TX/7yFwUHB+uvf/2rTp06pSVLlqhcuXIKCwtTq1atlJiY6FzXrc4kjBkzRpUqVVLevHkVHR2tl19+WZcuXXLOv7Y/vvrqK5UvX152u11HjhxxuRSqffv2WrNmjcaNGyebzSabzaaDBw+qdOnSeu+991zWt337dtlsNu3bt++mNQHA3YBgAQA51NmzZ7V06VJ1795defPmTTf/WhhwOBxq2rSpzp49qzVr1mjFihU6cOCAWrRo4ezbunVrlShRQps3b9bWrVvVr18/BQQE3HTd+/fv15dffqnFixdr8eLFWrNmjUaOHOmcP2LECM2cOVNTpkzRzp071bt3b7Vp00Zr1qzJcHmFCxeWn5+f5s2bp7S0NLf2w+DBg/XBBx9o3bp1Onr0qJo3b66xY8dq9uzZ+vrrr7V8+XJNmDAhy8vz8/PT+PHjtXPnTs2YMUPffvut+vbt69InMTFRo0aN0r/+9S/t3LlTRYoUcZk/btw4Va9eXV26dNHx48d1/PhxlSxZUh07dtS0adNc+k6bNk01a9ZU6dKl3dpuAPA5BgCQI23cuNFIMvPnz8+03/Lly42/v785cuSIs23nzp1Gktm0aZMxxpjQ0FAzffr0DF8/bdo0kz9/fuf0oEGDTEhIiElISHC2vfHGG6ZatWrGGGOuXLliQkJCzLp161yW06lTJ/P888/ftM4PPvjAhISEmNDQUFOnTh0zdOhQs3//fuf8gwcPGknmxx9/NMYYs2rVKiPJfPPNN84+I0aMMJJcXtetWzfTsGFD53StWrVMr169nNMxMTHmn//8503rmjt3rilUqJDL/pBktm/f7tKvXbt2pmnTpjddjzHG/P7778bf399s3LjRGGNMSkqKiYiIuOm+B4C7CWcsACCHMsZkqd/u3bsVHR2t6OhoZ1v58uUVHh6u3bt3S5L69Omjzp07q169eho5cqT279+f6TJjY2MVGhrqnC5atKhOnTolSdq3b58SExNVv3595cuXz/kzc+bMTJfbvXt3nThxQrNmzVL16tU1d+5cVahQQStWrMi0lvvuu8/578jISIWEhKhUqVIubddqy4pvvvlGdevWVfHixRUaGqoXXnhBZ86ccbmcKjAw0GW9WVWsWDE98cQT+uSTTyRJixYtUnJysp577jm3lwUAvoZgAQA5VJkyZWSz2Txyg/bgwYO1c+dOPfHEE/r2229Vvnx5LViw4Kb9b7xMymazyeFwSJLzfoSvv/5a27dvd/7s2rUr0/ssJCk0NFRPPvmkhg8frh07duixxx7TO++8k+lrrq/FZrNlWtutHDp0SE2aNNF9992nL774Qlu3btXEiRMlSSkpKc5+wcHBstlsWVrmjTp37qw5c+YoKSlJ06ZNU4sWLRQSEnJbywIAX0KwAIAcqmDBgmrYsKEmTpyoy5cvp5t/7WlK5cqV09GjR3X06FHnvF27dun8+fMqX768s+2ee+5R7969tXz5cj3zzDPp7gXIqutvaC5durTLz/VnTW7FZrOpbNmyGW5bdtm6dascDofef/99Pfzww7rnnnt07Nix21pWYGBghveLPP7448qbN68mT56spUuXqmPHjlbLBgCfQLAAgBxs4sSJSktL00MPPaQvvvhCe/fu1e7duzV+/HhVr15dklSvXj1VqlRJrVu31rZt27Rp0ya1bdtWtWrVUtWqVZWUlKQePXpo9erVOnz4sH744Qdt3rxZ5cqVu62aQkND9frrr6t3796aMWOG9u/fr23btmnChAmaMWNGhq/Zvn27mjZtqnnz5mnXrl3at2+fPv74Y33yySdq2rTpbe8fd5UuXVqpqamaMGGCDhw4oE8//VRTpky5rWXFxsZq48aNOnTokE6fPu08a+Lv76/27durf//+KlOmjPM4AcDdjmABADlYqVKltG3bNtWpU0evvfaaKlasqPr162vlypWaPHmypD//8r9w4UIVKFBANWvWVL169VSqVCl9/vnnkv78RffMmTNq27at7rnnHjVv3lyNGzfWkCFDbruuYcOGacCAARoxYoTKlSunRo0a6euvv1ZcXFyG/UuUKKHY2FgNGTJE1apV0/33369x48ZpyJAhevvtt2+7DndVrlxZY8aM0ahRo1SxYkXNmjVLI0aMuK1lvf766/L391f58uVVuHBhHTlyxDmvU6dOSklJUYcOHTxVOgDkeDaT1bsDAQBAlnz33XeqW7eujh49qsjISG+XAwB3BMECAAAPSU5O1h9//KF27dopKipKs2bN8nZJAHDHcCkUAAAe8tlnnykmJkbnz5/X6NGjvV0OANxRnLEAAAAAYBlnLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWPb/AEtfXWvcjBGaAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지 설치\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"필요한 패키지들을 설치합니다.\"\"\"\n",
        "    packages = [\n",
        "        \"insightface\",\n",
        "        \"onnxruntime\",\n",
        "        \"opencv-python\",\n",
        "        \"tqdm\"\n",
        "    ]\n",
        "\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "            print(f\"✅ {package} 설치 완료\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(f\"❌ {package} 설치 실패\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# 패키지 설치 실행\n",
        "print(\"필요한 패키지들을 설치합니다...\")\n",
        "if not install_packages():\n",
        "    print(\"패키지 설치에 실패했습니다. 수동으로 설치해주세요.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 패키지 임포트\n",
        "import requests\n",
        "import os\n",
        "import cv2\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "from glob import glob\n",
        "import re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "class AutoFaceSwapPipeline:\n",
        "    def __init__(self):\n",
        "        self.app = None\n",
        "        self.swapper = None\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"모델 다운로드 및 초기화\"\"\"\n",
        "        if not self.download_inswapper():\n",
        "            raise Exception(\"모델 다운로드에 실패했습니다.\")\n",
        "\n",
        "        print(\"얼굴 분석 및 교체 모델 준비 중...\")\n",
        "        self.app = FaceAnalysis()\n",
        "        self.app.prepare(ctx_id=0, det_size=(320, 320))\n",
        "        self.swapper = insightface.model_zoo.get_model('inswapper_128.onnx')\n",
        "        print(\"모델 준비 완료!\")\n",
        "\n",
        "    def download_inswapper(self):\n",
        "        \"\"\"인스왑퍼 모델 다운로드\"\"\"\n",
        "        url = \"https://civitai.com/api/download/models/85159\"\n",
        "        model_name = 'inswapper_128.onnx'\n",
        "\n",
        "        if os.path.exists(model_name):\n",
        "            print(f\"'{model_name}' 모델이 이미 존재합니다.\")\n",
        "            return True\n",
        "\n",
        "        print(f\"'{model_name}' 모델 다운로드 중...\")\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            if response.status_code == 200:\n",
        "                with open(model_name, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                print(\"모델 다운로드 완료!\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"다운로드 실패: {response.status_code}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"다운로드 중 오류: {e}\")\n",
        "            return False\n",
        "\n",
        "    def extract_number_from_filename(self, filename):\n",
        "        \"\"\"파일명에서 숫자 추출 (영상과 이미지 매칭용)\"\"\"\n",
        "        # 파일명에서 숫자 패턴 찾기\n",
        "        numbers = re.findall(r'\\d+', os.path.splitext(filename)[0])\n",
        "        if numbers:\n",
        "            return int(numbers[0])  # 첫 번째 숫자 사용\n",
        "        return None\n",
        "\n",
        "    def get_video_image_pairs(self, video_dir, image_dir):\n",
        "        \"\"\"영상과 이미지 파일들을 번호로 매칭\"\"\"\n",
        "        video_files = glob(os.path.join(video_dir, \"*.mp4\"))\n",
        "        image_files = glob(os.path.join(image_dir, \"*.jpg\")) + glob(os.path.join(image_dir, \"*.png\"))\n",
        "\n",
        "        # 파일명에서 번호 추출하여 딕셔너리 생성\n",
        "        video_dict = {}\n",
        "        for video_path in video_files:\n",
        "            filename = os.path.basename(video_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                video_dict[number] = video_path\n",
        "\n",
        "        image_dict = {}\n",
        "        for image_path in image_files:\n",
        "            filename = os.path.basename(image_path)\n",
        "            number = self.extract_number_from_filename(filename)\n",
        "            if number is not None:\n",
        "                image_dict[number] = image_path\n",
        "\n",
        "        # 매칭되는 쌍 찾기\n",
        "        pairs = []\n",
        "        for number in sorted(set(video_dict.keys()) & set(image_dict.keys())):\n",
        "            pairs.append({\n",
        "                'number': number,\n",
        "                'video_path': video_dict[number],\n",
        "                'image_path': image_dict[number],\n",
        "                'video_name': os.path.splitext(os.path.basename(video_dict[number]))[0],\n",
        "                'image_name': os.path.splitext(os.path.basename(image_dict[number]))[0]\n",
        "            })\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def process_single_pair(self, video_path, source_image_path, output_dir, frame_interval=5):\n",
        "        \"\"\"단일 영상-이미지 쌍 처리\"\"\"\n",
        "        # 소스 이미지에서 얼굴 추출\n",
        "        source_img = cv2.imread(source_image_path)\n",
        "        if source_img is None:\n",
        "            print(f\"소스 이미지를 읽을 수 없습니다: {source_image_path}\")\n",
        "            return False, None, None\n",
        "\n",
        "        source_faces = self.app.get(source_img)\n",
        "        if not source_faces:\n",
        "            print(f\"소스 이미지에서 얼굴을 찾을 수 없습니다: {source_image_path}\")\n",
        "            return False, None, None\n",
        "\n",
        "        source_face = source_faces[0]\n",
        "\n",
        "        # 타겟 비디오 처리\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"타겟 비디오를 열 수 없습니다: {video_path}\")\n",
        "            return False, None, None\n",
        "\n",
        "        # 비디오 정보\n",
        "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        new_fps = original_fps / frame_interval\n",
        "\n",
        "        print(f\"  원본 FPS: {original_fps:.1f} → 새 FPS: {new_fps:.1f}\")\n",
        "        print(f\"  총 프레임: {total_frames}, 예상 저장: {total_frames // frame_interval}개\")\n",
        "\n",
        "        # 출력 디렉토리 생성\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "\n",
        "        print(\"  프레임 처리 중...\")\n",
        "        with tqdm(total=total_frames, desc=\"  진행률\") as pbar:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                if frame_count % frame_interval == 0:\n",
        "                    target_faces = self.app.get(frame)\n",
        "                    if len(target_faces) > 0:\n",
        "                        try:\n",
        "                            result_frame = self.swapper.get(frame, target_faces[0], source_face, paste_back=True)\n",
        "                            cv2.imwrite(os.path.join(output_dir, f'frame_{saved_count:04d}.png'), result_frame)\n",
        "                            saved_count += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"  프레임 {frame_count} 처리 중 오류: {e}\")\n",
        "\n",
        "                frame_count += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"  저장된 이미지: {saved_count}개\")\n",
        "        return True, original_fps, new_fps\n",
        "\n",
        "    def create_video_from_images(self, image_dir, output_video_path, fps):\n",
        "        \"\"\"이미지들로 비디오 생성\"\"\"\n",
        "        image_files = sorted(glob(os.path.join(image_dir, 'frame_*.png')))\n",
        "\n",
        "        if len(image_files) == 0:\n",
        "            print(f\"  이미지 파일이 없습니다: {image_dir}\")\n",
        "            return False\n",
        "\n",
        "        first_img = cv2.imread(image_files[0])\n",
        "        if first_img is None:\n",
        "            return False\n",
        "\n",
        "        height, width, _ = first_img.shape\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        if not out.isOpened():\n",
        "            print(f\"  비디오 라이터를 열 수 없습니다: {output_video_path}\")\n",
        "            return False\n",
        "\n",
        "        print(f\"  {len(image_files)}개 이미지로 {fps:.1f}FPS 비디오 생성 중...\")\n",
        "        for img_path in tqdm(image_files, desc=\"  비디오 생성\"):\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                out.write(img)\n",
        "\n",
        "        out.release()\n",
        "        print(f\"  비디오 생성 완료: {output_video_path}\")\n",
        "        return True\n",
        "\n",
        "    def interpolate_video(self, input_video, output_video, target_fps):\n",
        "        \"\"\"FFmpeg를 사용한 프레임 보간\"\"\"\n",
        "        print(f\"  보간 시작: {target_fps:.1f}FPS로 변환 중...\")\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg', '-i', input_video,\n",
        "            '-filter:v', f'minterpolate=fps={target_fps}:mi_mode=mci:mc_mode=aobmc:vsbmc=1',\n",
        "            '-y', output_video\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "            if result.returncode == 0:\n",
        "                print(f\"  보간 완료: {output_video}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"  보간 실패: {result.stderr}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"  보간 중 오류: {e}\")\n",
        "            return False\n",
        "\n",
        "    def process_all_pairs(self, video_dir=\"/content/input_videos\",\n",
        "                         image_dir=\"/content/experiments/restyle_e4e_sg3/inference_results/0\",\n",
        "                         output_base_dir=\"/content/face_swap_results\",\n",
        "                         frame_interval=5, use_interpolation=True):\n",
        "        \"\"\"모든 영상-이미지 쌍 자동 처리\"\"\"\n",
        "\n",
        "        # 매칭되는 쌍 찾기\n",
        "        pairs = self.get_video_image_pairs(video_dir, image_dir)\n",
        "\n",
        "        if not pairs:\n",
        "            print(\"매칭되는 영상-이미지 쌍을 찾을 수 없습니다!\")\n",
        "            print(f\"영상 디렉토리: {video_dir}\")\n",
        "            print(f\"이미지 디렉토리: {image_dir}\")\n",
        "            return\n",
        "\n",
        "        print(f\"총 {len(pairs)}개의 매칭 쌍을 찾았습니다!\")\n",
        "\n",
        "        # 기본 출력 디렉토리 생성\n",
        "        os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "        success_count = 0\n",
        "\n",
        "        for i, pair in enumerate(pairs, 1):\n",
        "            print(f\"\\n[{i}/{len(pairs)}] 처리 중...\")\n",
        "            print(f\"  영상: {os.path.basename(pair['video_path'])}\")\n",
        "            print(f\"  이미지: {os.path.basename(pair['image_path'])}\")\n",
        "\n",
        "            # 개별 출력 디렉토리 생성\n",
        "            pair_name = f\"pair_{pair['number']:03d}_{pair['video_name']}\"\n",
        "            pair_output_dir = os.path.join(output_base_dir, pair_name)\n",
        "            images_dir = os.path.join(pair_output_dir, \"frames\")\n",
        "\n",
        "            try:\n",
        "                # 1. 얼굴 교체 및 이미지 저장\n",
        "                success, original_fps, base_fps = self.process_single_pair(\n",
        "                    pair['video_path'],\n",
        "                    pair['image_path'],\n",
        "                    images_dir,\n",
        "                    frame_interval\n",
        "                )\n",
        "\n",
        "                if not success:\n",
        "                    print(f\"  쌍 {pair['number']} 처리 실패\")\n",
        "                    continue\n",
        "\n",
        "                # 2. 기본 비디오 생성\n",
        "                base_video_path = os.path.join(pair_output_dir, f\"{pair_name}_base.mp4\")\n",
        "                if not self.create_video_from_images(images_dir, base_video_path, base_fps):\n",
        "                    print(f\"  기본 비디오 생성 실패\")\n",
        "                    continue\n",
        "\n",
        "                # 3. 보간된 비디오 생성 (선택사항)\n",
        "                if use_interpolation:\n",
        "                    final_video_path = os.path.join(pair_output_dir, f\"{pair_name}_final.mp4\")\n",
        "                    if self.interpolate_video(base_video_path, final_video_path, original_fps):\n",
        "                        print(f\"  최종 결과: {final_video_path}\")\n",
        "                    else:\n",
        "                        print(f\"  보간 실패, 기본 비디오 사용: {base_video_path}\")\n",
        "                else:\n",
        "                    print(f\"  최종 결과: {base_video_path}\")\n",
        "\n",
        "                success_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  쌍 {pair['number']} 처리 중 오류: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\n🎉 처리 완료! {success_count}/{len(pairs)}개 성공\")\n",
        "        print(f\"결과 저장 위치: {output_base_dir}\")\n",
        "\n",
        "# 사용 예시\n",
        "if __name__ == \"__main__\":\n",
        "    # 파이프라인 초기화\n",
        "    pipeline = AutoFaceSwapPipeline()\n",
        "\n",
        "    # 설정\n",
        "    VIDEO_DIR = \"/content/input_videos\"\n",
        "    IMAGE_DIR = \"/content/experiments/restyle_e4e_sg3/inference_results/0\"\n",
        "    OUTPUT_DIR = \"/content/face_swap_results\"\n",
        "    FRAME_INTERVAL = 5  # 5프레임마다 샘플링\n",
        "    USE_INTERPOLATION = True  # 프레임 보간 사용 여부\n",
        "\n",
        "    print(\"=== 자동 Face Swap 파이프라인 시작 ===\")\n",
        "    print(f\"영상 디렉토리: {VIDEO_DIR}\")\n",
        "    print(f\"이미지 디렉토리: {IMAGE_DIR}\")\n",
        "    print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
        "    print(f\"프레임 간격: {FRAME_INTERVAL}\")\n",
        "    print(f\"보간 사용: {'예' if USE_INTERPOLATION else '아니오'}\")\n",
        "\n",
        "    # 모든 쌍 자동 처리\n",
        "    pipeline.process_all_pairs(\n",
        "        video_dir=VIDEO_DIR,\n",
        "        image_dir=IMAGE_DIR,\n",
        "        output_base_dir=OUTPUT_DIR,\n",
        "        frame_interval=FRAME_INTERVAL,\n",
        "        use_interpolation=USE_INTERPOLATION\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNMktnrF3t3y",
        "outputId": "b6b572e7-6a68-4f3b-f217-bf563fe58d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "필요한 패키지들을 설치합니다...\n",
            "✅ insightface 설치 완료\n",
            "✅ onnxruntime 설치 완료\n",
            "✅ opencv-python 설치 완료\n",
            "✅ tqdm 설치 완료\n",
            "'inswapper_128.onnx' 모델 다운로드 중...\n",
            "모델 다운로드 완료!\n",
            "얼굴 분석 및 교체 모델 준비 중...\n",
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 281857/281857 [00:03<00:00, 92999.03KB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (320, 320)\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "inswapper-shape: [1, 3, 128, 128]\n",
            "모델 준비 완료!\n",
            "=== 자동 Face Swap 파이프라인 시작 ===\n",
            "영상 디렉토리: /content/input_videos\n",
            "이미지 디렉토리: /content/experiments/restyle_e4e_sg3/inference_results/0\n",
            "출력 디렉토리: /content/face_swap_results\n",
            "프레임 간격: 5\n",
            "보간 사용: 예\n",
            "총 26개의 매칭 쌍을 찾았습니다!\n",
            "\n",
            "[1/26] 처리 중...\n",
            "  영상: 0004.mp4\n",
            "  이미지: 0004.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 529, 예상 저장: 105개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 529/529 [06:50<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 106개\n",
            "  106개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 106/106 [00:01<00:00, 89.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_004_0004/pair_004_0004_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_004_0004/pair_004_0004_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_004_0004/pair_004_0004_final.mp4\n",
            "\n",
            "[2/26] 처리 중...\n",
            "  영상: 0005.mp4\n",
            "  이미지: 0005.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 326, 예상 저장: 65개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 326/326 [04:12<00:00,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 66개\n",
            "  66개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 66/66 [00:00<00:00, 79.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_005_0005/pair_005_0005_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_005_0005/pair_005_0005_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_005_0005/pair_005_0005_final.mp4\n",
            "\n",
            "[3/26] 처리 중...\n",
            "  영상: 0006.mp4\n",
            "  이미지: 0006.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 459, 예상 저장: 91개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 459/459 [05:48<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 92개\n",
            "  92개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 92/92 [00:01<00:00, 70.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_006_0006/pair_006_0006_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_006_0006/pair_006_0006_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_006_0006/pair_006_0006_final.mp4\n",
            "\n",
            "[4/26] 처리 중...\n",
            "  영상: 0007.mp4\n",
            "  이미지: 0007.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 534, 예상 저장: 106개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 534/534 [07:04<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 107개\n",
            "  107개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 107/107 [00:01<00:00, 68.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_007_0007/pair_007_0007_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_007_0007/pair_007_0007_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_007_0007/pair_007_0007_final.mp4\n",
            "\n",
            "[5/26] 처리 중...\n",
            "  영상: 0008.mp4\n",
            "  이미지: 0008.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 479, 예상 저장: 95개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 479/479 [06:22<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 96개\n",
            "  96개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 96/96 [00:01<00:00, 74.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_008_0008/pair_008_0008_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_008_0008/pair_008_0008_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_008_0008/pair_008_0008_final.mp4\n",
            "\n",
            "[6/26] 처리 중...\n",
            "  영상: 0009.mp4\n",
            "  이미지: 0009.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 464, 예상 저장: 92개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 464/464 [06:10<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 93개\n",
            "  93개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 93/93 [00:01<00:00, 74.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_009_0009/pair_009_0009_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_009_0009/pair_009_0009_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_009_0009/pair_009_0009_final.mp4\n",
            "\n",
            "[7/26] 처리 중...\n",
            "  영상: 0010.mp4\n",
            "  이미지: 0010.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 520, 예상 저장: 104개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 520/520 [06:48<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 104개\n",
            "  104개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 104/104 [00:01<00:00, 55.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_010_0010/pair_010_0010_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_010_0010/pair_010_0010_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_010_0010/pair_010_0010_final.mp4\n",
            "\n",
            "[8/26] 처리 중...\n",
            "  영상: 0011.mp4\n",
            "  이미지: 0011.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 371, 예상 저장: 74개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 371/371 [04:50<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 73개\n",
            "  73개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 73/73 [00:00<00:00, 151.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_011_0011/pair_011_0011_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_011_0011/pair_011_0011_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_011_0011/pair_011_0011_final.mp4\n",
            "\n",
            "[9/26] 처리 중...\n",
            "  영상: 0012.mp4\n",
            "  이미지: 0012.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 276, 예상 저장: 55개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 276/276 [03:50<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 56개\n",
            "  56개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 56/56 [00:00<00:00, 139.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_012_0012/pair_012_0012_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_012_0012/pair_012_0012_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_012_0012/pair_012_0012_final.mp4\n",
            "\n",
            "[10/26] 처리 중...\n",
            "  영상: 0013.mp4\n",
            "  이미지: 0013.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 400, 예상 저장: 80개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 400/400 [05:21<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 80개\n",
            "  80개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 80/80 [00:00<00:00, 108.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_013_0013/pair_013_0013_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_013_0013/pair_013_0013_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_013_0013/pair_013_0013_final.mp4\n",
            "\n",
            "[11/26] 처리 중...\n",
            "  영상: 0087.mp4\n",
            "  이미지: 0087.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 269, 예상 저장: 53개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 269/269 [03:39<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 54개\n",
            "  54개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 54/54 [00:00<00:00, 74.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_087_0087/pair_087_0087_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_087_0087/pair_087_0087_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_087_0087/pair_087_0087_final.mp4\n",
            "\n",
            "[12/26] 처리 중...\n",
            "  영상: 0088.mp4\n",
            "  이미지: 0088.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 298, 예상 저장: 59개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 298/298 [04:04<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 60개\n",
            "  60개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 60/60 [00:01<00:00, 59.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_088_0088/pair_088_0088_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_088_0088/pair_088_0088_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_088_0088/pair_088_0088_final.mp4\n",
            "\n",
            "[13/26] 처리 중...\n",
            "  영상: 0089.mp4\n",
            "  이미지: 0089.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.8 → 새 FPS: 6.0\n",
            "  총 프레임: 327, 예상 저장: 65개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 327/327 [04:30<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 66개\n",
            "  66개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 66/66 [00:00<00:00, 99.55it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_089_0089/pair_089_0089_base.mp4\n",
            "  보간 시작: 29.8FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_089_0089/pair_089_0089_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_089_0089/pair_089_0089_final.mp4\n",
            "\n",
            "[14/26] 처리 중...\n",
            "  영상: 0090.mp4\n",
            "  이미지: 0090.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.6 → 새 FPS: 5.9\n",
            "  총 프레임: 335, 예상 저장: 67개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 335/335 [04:37<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 67개\n",
            "  67개 이미지로 5.9FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 67/67 [00:01<00:00, 63.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_090_0090/pair_090_0090_base.mp4\n",
            "  보간 시작: 29.6FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_090_0090/pair_090_0090_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_090_0090/pair_090_0090_final.mp4\n",
            "\n",
            "[15/26] 처리 중...\n",
            "  영상: 0091.mp4\n",
            "  이미지: 0091.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 320, 예상 저장: 64개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 320/320 [04:15<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 64개\n",
            "  64개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 64/64 [00:00<00:00, 152.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_091_0091/pair_091_0091_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_091_0091/pair_091_0091_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_091_0091/pair_091_0091_final.mp4\n",
            "\n",
            "[16/26] 처리 중...\n",
            "  영상: 0092.mp4\n",
            "  이미지: 0092.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.7 → 새 FPS: 5.9\n",
            "  총 프레임: 337, 예상 저장: 67개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 337/337 [04:31<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 68개\n",
            "  68개 이미지로 5.9FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 68/68 [00:00<00:00, 87.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_092_0092/pair_092_0092_base.mp4\n",
            "  보간 시작: 29.7FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_092_0092/pair_092_0092_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_092_0092/pair_092_0092_final.mp4\n",
            "\n",
            "[17/26] 처리 중...\n",
            "  영상: 0093.mp4\n",
            "  이미지: 0093.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.6 → 새 FPS: 5.9\n",
            "  총 프레임: 323, 예상 저장: 64개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 323/323 [04:14<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 65개\n",
            "  65개 이미지로 5.9FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 65/65 [00:00<00:00, 145.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_093_0093/pair_093_0093_base.mp4\n",
            "  보간 시작: 29.6FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_093_0093/pair_093_0093_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_093_0093/pair_093_0093_final.mp4\n",
            "\n",
            "[18/26] 처리 중...\n",
            "  영상: 0094.mp4\n",
            "  이미지: 0094.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.7 → 새 FPS: 5.9\n",
            "  총 프레임: 322, 예상 저장: 64개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 322/322 [04:16<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 65개\n",
            "  65개 이미지로 5.9FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 65/65 [00:00<00:00, 86.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_094_0094/pair_094_0094_base.mp4\n",
            "  보간 시작: 29.7FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_094_0094/pair_094_0094_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_094_0094/pair_094_0094_final.mp4\n",
            "\n",
            "[19/26] 처리 중...\n",
            "  영상: 0095.mp4\n",
            "  이미지: 0095.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 29.8 → 새 FPS: 6.0\n",
            "  총 프레임: 338, 예상 저장: 67개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 338/338 [04:24<00:00,  1.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 68개\n",
            "  68개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 68/68 [00:00<00:00, 105.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_095_0095/pair_095_0095_base.mp4\n",
            "  보간 시작: 29.8FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_095_0095/pair_095_0095_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_095_0095/pair_095_0095_final.mp4\n",
            "\n",
            "[20/26] 처리 중...\n",
            "  영상: 0096.mp4\n",
            "  이미지: 0096.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 30.0 → 새 FPS: 6.0\n",
            "  총 프레임: 328, 예상 저장: 65개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률: 100%|██████████| 328/328 [04:19<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  저장된 이미지: 66개\n",
            "  66개 이미지로 6.0FPS 비디오 생성 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  비디오 생성: 100%|██████████| 66/66 [00:00<00:00, 82.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  비디오 생성 완료: /content/face_swap_results/pair_096_0096/pair_096_0096_base.mp4\n",
            "  보간 시작: 30.0FPS로 변환 중...\n",
            "  보간 완료: /content/face_swap_results/pair_096_0096/pair_096_0096_final.mp4\n",
            "  최종 결과: /content/face_swap_results/pair_096_0096/pair_096_0096_final.mp4\n",
            "\n",
            "[21/26] 처리 중...\n",
            "  영상: 0097.mp4\n",
            "  이미지: 0097.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  원본 FPS: 28.8 → 새 FPS: 5.8\n",
            "  총 프레임: 324, 예상 저장: 64개\n",
            "  프레임 처리 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  진행률:  30%|██▉       | 96/324 [01:17<02:56,  1.29it/s]"
          ]
        }
      ]
    }
  ]
}